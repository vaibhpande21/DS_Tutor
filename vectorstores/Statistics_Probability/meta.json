[
  {
    "text": "Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Basic Terminologies Experiment Outcomes Sample space Events Mutually ex clusiv e Events (Disjoint E vents) Exhaustiv e Events Joint e vents Independent e vents Set oper ations Intersection Union Complement Addition Rule Cross tabContent Basic Terminologies îŒ“ It is basically an activity which I' m trying t o do. Let's say I ha ve this mathematical equation wher e: = 3 and = 4 = 49 We are 100% sur e that the r esult of this equation will be 49 only . It cannot be 50 or 48.1. ExperimentîŒ“ + +2ğ‘ğ‘ ğ‘2ğ‘2 ğ‘ ğ‘ + +2(3)(4) 3242 This type of experiment is called Deterministic Experiments wher e we can determine the exact output, lik e in this case. Now , let's see another f ew mor e examples: Flipping a coin When y ou ip a coin, ther e are two possible outcomes: it can land either heads or tails. Rolling a six-sided die When y ou roll the die, the outcome is uncer tain, and the die can land on any of",
    "source": "lec1.pdf::chunk0"
  },
  {
    "text": "the six faces. Crick et Match Suppose ther e is a match going on between 2 teams, we can 't determine the match result. In all of these abo ve examples, we can notice one common thing. Q. Can we determine the outcome of all these experiments? No, because the outcomes ar e uncer tain. These types of experiments ar e known as Probabilistic Experiments . Let's continue with the experiment of \"Rolling a six sided die \" and look at the possible r esults of an experiment. Experiment: Rolling a die Suppose we r oll a six sided die and we want t o know the possible Outcomes. We know that we could get any digit out of the 6 digits. So, an outcome could be : {1} or {2} or {3} or {4} or {5} or {6}2. Outcomes It is the collection of all the possible outcomes of the experiment. So the sample space for this experiment will be: {1, 2, 3, 4, 5, 6}3. Sample Space We know that sample space for die is {1,2,3,4,5,6}. If we sa y, An Even number is r olled / While r olling a die, an e ven number has occurr",
    "source": "lec1.pdf::chunk1"
  },
  {
    "text": "ed Then the possible outcomes will be: {2, 4, 6} This is known as an Event. Any subset of sample space is an e vent. {2, 4, 6} is a subset of sample space. \"An Even number is r olled \" is an e vent her e and its output is = {2, 4, 6}, wher e denotes an Event. Q1. What ar e the possible outcomes when a dice is r olled and a number gr eater than two has occurr ed? For this E vent, outcome will be = {3, 4, 5, 6}4. EventsîŒ“ ğ¸ ğ¸ ğ¸ Here is a gr aphical r epresentation of a sample space and e vents Here the sample space is represented b y a rectangle which is {1, 2, 3, 4, 5, 6} Outcomes are represented as points within the r ectangle which is {1}, {2}, {3}, {4}, {5}, {6} Events are represented as o vals that enclose the outcomes that compose them. we ha ve two e vents, : {2, 4, 6} which is an e vent for \"E ven number is r olled\" : {3, 4, 5, 6} which is an e vent for \" A number gr eater than",
    "source": "lec1.pdf::chunk2"
  },
  {
    "text": "2 r olled\"ğ‘† ğ¸1 ğ¸2 Now let' s see f ew experiments. Experiment 1: Tossing a single coin îŒ“ Q1. If we t oss a single coin then what can be the P ossible Outcomes for this experiment? Either we can get Heads Or we can get Tails Ther efore, our outcome becomes: {H}, {T} The Sample Space for this experiment will be = {H, T} Based on this sample space, what possible E vents can be dened? Getting Heads while t ossing a coin, then our e vent will be = {H} Getting Tails while t ossing a coin, then our e vent will be = {T}ğ‘† ğ¸ ğ¸ Q2. Suppose the giv en subset is itself {H,T}. Can we dene this as an E vent or not? Yes, It is an e vent. We discussed earlier that any subset of a Sample Space is an E vent. Also an entir e set is a subset of itself so this is a v alid e vent. Q3. So how can we fr ame this e vent? It is the \" Event of getting Either Heads or Tails\". Q4. Consider the empty set as the giv en subset denoted b",
    "source": "lec1.pdf::chunk3"
  },
  {
    "text": "y { }. Is it a v alid e vent? We know that, an empty set is a subset of e very set. An empty set is ther efore a subset of sample space It is a v alid subset So b y going with the denition of an E vent, we can conclude that this is a v alid e vent. This can be r epresented as the \"Event of getting neither Heads nor Tails\" . Q5. Is it possible if we t oss a coin and get nothing? No, it is not possible. Ther efore, we will ha ve an Empty set here As we know an empty set is a subset of sample space, ther efore it is an E vent. But, the probability of getting a Null Set (No outcome) is Z ero. As it is not possible t o toss the coin and don 't get any output. we will either gets a head or a tail. Q6. How many subsets can be formed fr om the sample space? Ther e is one formula t o nd the number of subsets : wher e N = number of elements in sample space For the abo",
    "source": "lec1.pdf::chunk4"
  },
  {
    "text": "ve experiment, number of elements in the sample sapace is 2 {H,T}, So N = 2 Ther efore the number of subsets will be 2ğ‘ =4 22 Subsets will be { {H}, {T}, {H,T}, { } } From this, we can conclude that an empty set is also consider ed as a v alid subset. Set Oper ations îŒ“ Let's recall the experiment \" Rolling a die \" for which the Sample space is We can also r epresent this as a Univ erse or Univ ersal Set in context of set oper ations Univ ersal set is the collection of all possible sets Now let' s dene some e vents : Mohit bets that he will get an odd number So the outcome of this Event will be Rakesh bets that he will get either 1, 5 OR 6 Abhishek bets that he will get an E ven number{1,2,3,4,5,6} ğ´={1,3,5} ğµ={1,5,6} ğ¶={2,4,6} Ther e are some some questions which can arise Q. In which condition, both Mohit and Rak esh will win their bets? We want a number which occurs in both of their e vents They will win their bets when we get a number 1 or 5",
    "source": "lec1.pdf::chunk5"
  },
  {
    "text": "on a die. Ther efore is the possible outcome such that both Mohit and Rak esh will win their bets This is known as an Intersection of two e vents. It is denoted as Intersection means members belonging t o both A AND B So, will consists only of the elements pr esent in both e vents, which in this case ar e IntersectionîŒ“ {1,5} ğ´âˆ©ğµ ğ´âˆ©ğµ {1,5} *Image sour ce: https:/ /www .desmos.com/calculat or/nynlqmtuu2 Now the next question, Q. When either Mohit or Rak esh will win their bets? If we get any number out of 1, 3, 5 or 6 Possible outcomes of this e vent: This is known as Union of Two e vents A and B It is denoted b y So, Union means members belonging t o either A OR B So, will combine their outcomes, which in this case will be UnionîŒ“ {1,3,5,6} ğ´âˆªğµ ğ´âˆªğµ {1,3,5,6} Q. When will Mohit lose his bet? Mohit will lose his bet if the outcome is This is known as complement of Event A, denoted b y or We can dene it as the set that contains all the elements ex cept the elements of A, denoted as",
    "source": "lec1.pdf::chunk6"
  },
  {
    "text": "While Rak esh will lose if the outcome is Hence Complement {2,4,6} ğ´â€²ğ´ğ‘ =ğ‘ˆâˆ’ğ´ ğ´â€² {2,3,4} ={2,3,4} ğµâ€² Q1. What will be the output of ? We will ha ve an empty set which can also be r epresented b y Because ther e are no common elements in Set and Set Or it implies that both the e vents can 't occur on the same time means we can 't get an Even number and a Odd number at the same time on the dice. So, when two e vents cannot occur at the same time or simultaneously then these types of events ar e known as Mutually Exclusive Events or Disjoint EventsMutually Ex clusiv e Events (Disjoint E vents) îŒ“ ğ´âˆ©ğ¶ { } âˆ… ğ´ ğ¶ Q. What will be the output of ? Our e vents ar e: , , Ther fore = combined elements of E vent A, B, C = {1, 2, 3, 4, 5, 6} This is nothing but the Sample Space of our experiment \"Rolling a die \" as these e vents when combined, giving the all possible outcomes. These types of e vents ar e known as Exhaustive EventsExhaustiv e Events ğ´âˆªğµâˆªğ¶",
    "source": "lec1.pdf::chunk7"
  },
  {
    "text": "ğ´={1,3,5}ğµ={1,5,6}ğ¶={2,4,6} ğ´âˆªğµâˆªğ¶ Suppose we dene one mor e Events: Event D : Rolling a number gr eater than 3 = (4, 5, or 6). Q. Can we sa y that E vents C (getting e ven) and D ar e mutually ex clusiv e?Non Mutually Ex clusiv e Events (Joint E vents) îŒ“ No, as we can get a number that is both e ven and gr eater than 3 , which means both events C and D can occur simultaneously . For instance, if the die shows a 4 or a 6, it fullls the criteria for both e vents C and D . This type of e vents ar e known as non-mutually exclusive or joint events While non-mutually ex clusiv e events allow for o verlap, wher e mor e than one e vent can occur , independent e vents focus on how the occurr ence of one e vent may or ma y not aff ect the likelihood or outcome of another e ventIndependent E vents îŒ“ Suppose we ha ve 2 two e vents: Event A : Rolling an e ven number (2, 4, or 6) Event B : Flipping a coin and getting heads",
    "source": "lec1.pdf::chunk8"
  },
  {
    "text": "Q. Ar e these two e vents Independent or not? YES, these e vents ar e independent Events because The outcome of r olling the die ( Event A ) does not affect the outcome of ipping the coin ( Event B ), and vice v ersa. They are unr elated e vents that ar e occurring independently . And if two e vents A and B ar e independent, then the pr obability of happening of both A and B is: In case of Disjoint e vents, = 0 , as A Intersect B = { } So, if the E vents ar e Independent the y cannot be Mutually Ex clusiv e or Disjoint and vice a versa In the upcoming lectur es, we will see how t o deriv e this formula and also pr ove this claim.ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğ´)âˆ—ğ‘ƒ(ğµ) ğ‘ƒ(ğ´âˆ©ğµ) Now if I want t o calculate the Pr obability of the par ticular e vent let' s say event A, then we can calculate using this.How t o calculate Pr obability îŒ“ ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦=ğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘œğ‘šğ‘’ğ‘  ğ‘–ğ‘› ğ‘ ğ‘’ğ‘¡ ğ´ ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘œğ‘šğ‘’ğ‘  ğ‘–ğ‘› ğ¸ğ‘›ğ‘¡ğ‘–ğ‘Ÿğ‘’ ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ ğ‘†ğ‘ğ‘ğ‘ğ‘’ Now , let's tak e a random Experiment whose outcome could be {1} or {2}",
    "source": "lec1.pdf::chunk9"
  },
  {
    "text": "or {3} or {4} or {5} or {6} , then the Sample Space will be {1, 2, 3, 4, 5, 6} Let's dene some e vents: 1. = {2, 4, 6} Q1. What will be the pr obability of E vent A ? By looking int o the formula = Possible outcomes of e vent A = 3 and t otal Outcome in sample space = 6 So, 2. = {1, 2} Similarly Probability of E vent B will be = 3. = {1, 4, 5, 6} and Probability of E vent C will be = ğ´ ğ‘ƒğ‘œğ‘ ğ‘ ğ‘–ğ‘ğ‘™ğ‘’ ğ‘œğ‘¢ğ‘ğ‘œğ‘šğ‘’ğ‘  ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘œğ‘¢ğ‘¡ğ‘ğ‘œğ‘šğ‘’ğ‘  ğ‘ƒ(ğ´)=3 6 ğµ ğ‘ƒ(ğµ)2 6 ğ¶ ğ‘ƒ(ğ¶)4 6 Q1. What will be the Pr obability of ? First we need t o nd which is {1, 2, 4, 6} So b y the formula of pr obability will be = = = Wher e, | | = Number of elements(car dinality) of ( ) set, and | | = Number of elements in Sample SpaceAddition RuleîŒ“ ğ‘ƒ(ğ´âˆªğµ) ğ´âˆªğµ ğ‘ƒ(ğ´âˆªğµ)|ğ´âˆªğµ| |ğ‘†||{1,2,4,6}| |{1,2,3,4,5,6}|4 6 ğ´âˆªğµ ğ´âˆªğµ ğ‘† If we want t o represent using v enn Diagr am: Q2. What will be Pr obability of ? will be {2} So b",
    "source": "lec1.pdf::chunk10"
  },
  {
    "text": "y the formula of pr obability will be = = ğ‘ƒ(ğ´âˆ©ğµ) ğ´âˆ©ğµ ğ‘ƒ(ğ´âˆ©ğµ)|{2}| |{1,2,3,4,5,6}|1 6 So b y looking int o Venn diagr am, we obser ve that A UB means addition of all the elements of Set A and Set B We can also notice in set A we ha ve {2, 4, 6} and in set B we ha ve {1, 2} While adding the outcomes of the sets, {2} is occuring twice, which is nothing but , so we ha ve to subtr act it once fr om our addition, as we want unique outcomes only (Since a set can only ha ve distinct elements). So the formula for can we written as: This is known as Addition Rule. This is for Joint E ventsğ´âˆ©ğµ ğ‘ƒ(ğ´âˆªğµ) ğ‘ƒ(ğ´âˆªğµ)=ğ‘ƒ(ğ´)+ğ‘ƒ(ğµ)âˆ’ğ‘ƒ(ğ´âˆ©ğµ) In case of Disjoint E vents the intersection of so, therefore, ğ´âˆ©ğµ={ } ğ‘ƒ(ğ´âˆ©ğµ)=0 ğ‘ƒ(ğ´âˆªğµ)=ğ‘ƒ(ğ´)+ğ‘ƒ(ğµ) Experiment 3: Sachin Tendulkar ODI r ecor ds for India îŒ“ We ha ve a dataset containing Sachin Tendulkar 's ODI crick et car eer stats, including v arious performance metrics and the outcomes of matches.Problem Statement:îŒ“ !wget --no-check-certificate https://drive.google.c om/uc?id= 1zBM3idCNWceBMLKMRBTN --2024-01-18 07:55:03-- https://drive.google.com/uc?id=1zBM3idCNWceBMLKMRBTN Resolving drive.google.com (drive.google.com)... 172.253.63.102, 172.253.63.1 Connecting to drive.google.com (drive.google.com)|172.253.63.102|:443... conn",
    "source": "lec1.pdf::chunk11"
  },
  {
    "text": "HTTP request sent, awaiting response... 303 See Other Location: https://drive.usercontent.google.com/download?id=1zBM3idCNWceBMLKMR --2024-01-18 07:55:03-- https://drive.usercontent.google.com/download?id=1zB Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172. Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172 HTTP request sent, awaiting response... 200 OK Length: 26440 (26K) [application/octet-stream] Saving to: 'Sachin_ODI.csv' Sachin_ODI.csv 100%[===================>] 25.82K --.-KB/s in 0s 2024-01-18 07:55:04 (82.1 MB/s) - 'Sachin_ODI.csv' saved [26440/26440] import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt df_sachin = pd.read_csv( \"Sachin_ODI.csv\" ) df_sachin.head() runsNotOut minsbffourssixes srInns OppGround DateW 0 13 0 30 15 3 0 86.66 1New ZealandNapier199502-16 Z 1 37 0 75 51 3 1 72.54 2South AfricaHamilton199502-18 2 47 0 65 40 7 0117.50 2 Australia Dunedin199502-22 3 48 0 37 30 9 1160 00 2B ldh Sh jh1995Each columns r epresents diff erent f eatur es and each r ow r epresents a par ticular match # shape of the dataset df_sachin.shape (360, 14) Q1. A match is r andomly chosen, what is the pr obability that India ha ve won that match?îŒ“ Solution: Let's calculate this using the formula of pr obability , we know: probability = Here we want the possible outcomes of India winning a match ( WON = True) Entir e sample space will be",
    "source": "lec1.pdf::chunk12"
  },
  {
    "text": "our entir e datasetğ‘ƒğ‘œğ‘ ğ‘ ğ‘–ğ‘ğ‘™ğ‘’ ğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘œğ‘šğ‘’ğ‘  ğ‘–ğ‘› ğ‘ğ‘› ğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘œğ‘šğ‘’ğ‘  ğ‘–ğ‘› ğ‘ğ‘› ğ¸ğ‘›ğ‘¡ğ‘–ğ‘Ÿğ‘’ ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ ğ‘†ğ‘ğ‘ğ‘ğ‘’ # find the rows where India have won and store int o new dataframe df_won=df_sachin.loc[df_sachin[ \"Won\"]==True] # calculate the number of True values which is our possible outcome df_won.shape[ 0] 184 # We can also look at the length using len() len(df_won) 184 So, pr obability = ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘šğ‘ğ‘¡ğ‘â„ğ‘’ğ‘  ğ‘¤ğ‘œğ‘› ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘šğ‘ğ‘¡ğ‘â„ğ‘’ğ‘  prob_winning= len(df_won)/ len(df_sachin) prob_winning 0.5111111111111111 Conclusion: : If a match is r andomly chosen, ther e is 51% chance that India ha ve won that match. Q2. A match is chosen at a r andom, what is the pr obability that Sachin has scor ed a Centur y in that match?îŒ“ Solution 2: Let's solv e this using v alue counts function. First let' s count the number of centuries , Sachin has scor ed # using value_counts() df_sachin[ \"century\" ].value_counts() False 314 True 46 Name: century, dtype: int64 Out of 360 matches, Sachin has scor ed 46 Centuries. so, pr obability of Sachin scoring a centur y will be: 46/360 0.12777777777777777 Conclusion: If you chose a r andom match, ther e is 12.77% chance that Sachin has scor ed",
    "source": "lec1.pdf::chunk13"
  },
  {
    "text": "a centur y in that match Now ,Cross Tab: îŒ“ Let's nd out how many matches India ha ve won when Sachin has scored a century and How many matches India ha ve won when sachin didn't score a century. Q. Can we achie ve this task and obtain all these v alues at once? df_sachin[[ \"century\" ,\"Won\"]].value_counts() century Won False False 160 True 154 True True 30 False 16 dtype: int64 Q. Do y ou remember piv ot table fr om D AV-1 Libr aries module?Cross Tab and contingency table îŒ“ Ther e is a function called pd.crosstab() , which accepts par ameters index and columns . WonFalseTrueAll century False 160 154 314 True 16 30 46 All 176 184 360pd.crosstab(index=df_sachin[ \"century\" ], columns=df_sachin[ \"Won\"], margins= True) What we did using .valuecounts() at abo ve, pd.crosstab() did the same thing but conv erted the output int o nice tabular format Centur y is tak en as the index and Won is tak en as columns When we do Margins = True we get All, both in r ows and columns, The v alues of All in a ROW r epresnts the Total V alue of each columns (F alse,",
    "source": "lec1.pdf::chunk14"
  },
  {
    "text": "True, All) The v alues of All in a COL UMN r epresents the Total V alue of each r ows (F alse, True, All) This table is also known as Contingency Table We can calculate pr obabilities using the contingency table. Q3. A match is chosen at a r andom. What is the pr obability that Sachin has scor ed a centur y in that match and India ha ve won that match?îŒ“ Solution 3: WonFalseTrueAll century False 160 154 314 True 16 30 46 All 176 184 360pd.crosstab(index=df_sachin[ \"century\" ], columns=df_sachin[ \"Won\"], margins= True) # prob of winning and century # Won -> True, century -> True 30/360 0.08333333333333333 Conclusion : Ther e is 8% chance that Sachin has scor ed a centur y and India ha ve won that match if we choose a r andom match This tells us, that contingency table is mor e conv enient t o calculate pr obabilities r ather than hard coded the e very single line Let's have a look how is Sachin 's batting can or cannot impact the winning chances of India 1. Out of the 360 matches that Sachin has pla yed, India ha ve won 184",
    "source": "lec1.pdf::chunk15"
  },
  {
    "text": "matches and Loose 176 matches. 2. So, if we choose any match at a r andom fr om Sachin 's ODI car eer, ther e is a 51% chance that India ha ve won that match.Conclusion of the Pr oblem statement: îŒ“ 3. Now , If we choose a r andom match fr om Sachin 's ODI car eer, ther e is 12.77% chance that Sachin has scor ed a centur y in that match. 4. We know if a r andom match is choosen, ther e is 12.77% chance that Sachin has scor ed a centur y but there is only 8% chance India ha ve won that match. we can conclude that the chances of India, Winning a match is mor e when Sachin didn 't scor e a centur y (what an amazing insight) Finally , We can conclude that, if we pick a r andom match wher e Sachin pla yed, India 's win per centage is 51%. Ther e is 12.77% chance of Sachin scoring a centur y in that match, and ther e is only 8% chance that in that match Sachin scor es a centur y as well as India ha ve won",
    "source": "lec1.pdf::chunk16"
  },
  {
    "text": "that match",
    "source": "lec1.pdf::chunk17"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Introduction Log Normal Distribution. Real lif e dataset Key Char acteristics of a Log-Normal Distribution Poisson Distribution Application Rules of P oisson Distribution Poisson appr oximation t o BinomialContent Imagine that you are a data scientist at Amazon/Swiggy/Zomato You've collected a bunch of data on delivery times. Gener ally how much time deliv ery tak es? Let's assume ar ound 30 mins, ma ybe sometimes less than 30 ma ybe mor e Now , if we tak e thousands of these deliv ery time data points and plot a hist ogram, It ma y be a bit sk ewed t o the right. Sometimes deliv eries ar e quick er than 30 minutes, and sometimes the y tak e a bit longer . The lognormal distribution is a continuous pr obability distribution that models this type of right-sk ewed data.Log Normal DistributionîŒ“ Suppose X is the actual data Now the beauty of log normal is when y ou tak e the logarithm (log) of the actual deliv ery time data and plot a",
    "source": "lec10.pdf::chunk0"
  },
  {
    "text": "new hist ogram, The new hist ogram tends t o be mor e symmetrical, lik e a bell cur ve. In simple terms, the Log-Normal Distribution tak es the original data, does some math (logarithm), and mak es it look mor e like a normal, symmetrical distribution . So, in the language of distributions, we sa y the \" original deliv ery time data (X) is log-normal \" It means if X follows a log-normal distribution, log(X) follows a normal (bell-shaped) distribution. You can exponentiate a normal distribution (exp (X)) t o obtain the lognormal distribution . In this manner , you can tr ansform back and for th between pairs of r elated log normal and normal distribution We can see in this image that the original data follows log normal distribution and if we tak e log of this distribution, it'll look mor e symmetrical like a bell shaped cur ve. We will implement this on a r eal lif e dataset Let's have a look int o the dataset which has waiting time r ecor dsReal Lif e dataset îŒ“ !wget --no-check-certificate https://drive.google.c om/uc?id= 1SIZC1FZvZAhVzRvnZ7IFWBUDavvzIafJ -O waiting_time.c sv --2024-01-18 10:35:32-- https://drive.google.com/uc?id=1SIZC1FZvZAhVzRvnZ7IFWBUDavvzIafJ Resolving drive.google.com (drive.google.com)... 74.125.31.113, 74.125.31.102, 74.125.31.138,",
    "source": "lec10.pdf::chunk1"
  },
  {
    "text": "... Connecting to drive.google.com (drive.google.com)|74.125.31.113|:443... connected. HTTP request sent, awaiting response... 303 See Other Location: https://drive.usercontent.google.com/download?id=1SIZC1FZvZAhVzRvnZ7IFWBUDavvzIafJ [following] --2024-01-18 10:35:32-- https://drive.usercontent.google.com/download?id=1SIZC1FZvZAhVzRvnZ7IFWBUDavvzIafJ Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.217.132, 2607:f8b0:400c:c12::84 Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.217.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1656272 (1.6M) [application/octet-stream] Saving to: 'waiting_time.csv' waiting_time.csv 100%[===================>] 1.58M --.-KB/s in 0.01s 2024-01-18 10:35:32 (140 MB/s) - 'waiting_time.csv' saved [1656272/1656272] Impor ting Libr aries import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from scipy.stats import poisson, binom time 0 184.003075 1 36.721521 2 29.970417 3 75.640285 4 61.489439data = pd.read_csv( \"/content/waiting_time.csv\" ) data.head() Let's plot this data <Axes: ylabel='Count'> sns.histplot(data,bins= 100) Obser vation We can obser ve that it is right sk ewed. Now , Q1. How can we answer questions r elated t o the data which is distributed in this wa y? We can tr ansform this data using a log and let' s see the distribution of tr ansformed data. As we know , the r andom v ariable for the original data is and after tr ansforming it using log, the r andom v ariable of tr ansformed data is . If you ha ve the mean ( ) and",
    "source": "lec10.pdf::chunk2"
  },
  {
    "text": "standar d de viation ( ) of the natur al logarithm of a r andom v ariable and y ou want t o nd the mean and standar d de viation of the original r andom v ariable (which follows a log-normal distribution), y ou can use the following r elationships:Log Normal Distribution P arameters îŒ“ ğ‘‹ ğ‘™ğ‘›(ğ‘¥) Î¼ Ïƒ ğ‘‹ ğ‘‹ Mean of original = ğ‘‹exp(ğœ‡+)ğœ2 2 Variance of original = . ğ‘‹[exp()âˆ’1]exp(2ğœ‡+ ) ğœ2ğœ2 Let's transform our original data: time 0 5.214952 1 3.603363 2 3.40021 1 3 4.325989 4 4.118865 ... ... 90041 4.911816 90042 2.722871 90043 5.336766 90044 4.945125 90045 3.92631 1 90046 rows Ã— 1 columnsdata_log = np.log(data) data_log <Axes: ylabel='Count'> sns.histplot(data_log, bins= 100) Obser vation We can obser ve that after applying logarithm t o the right sk ewed data, we get the distribution which is appr oximately normal. We conv erted our data in such a format such that we ar e able t o utiliz e the pr oper ties of gaussian distribution This is known as log normal tr ansformation Q1. Why did we specically choose log? 1. Symmetr y: Our original data is right-sk ewed, with a long tail on",
    "source": "lec10.pdf::chunk3"
  },
  {
    "text": "the right side indicating occasional v ery long deliv ery times. The logarithmic tr ansformation compr esses lar ger v alues mor e than smaller v alues. The extr eme right tail is pulled in, making the distribution mor e symmetric. 2. Stabilizing V ariance: In the original deliv ery time data, y ou might obser ve that the v ariance (spr ead) of deliv ery times incr eases as the mean deliv ery time increases. Taking the logarithm can stabiliz e the v ariance . We can obser ve that the spr ead of deliv ery times after the tr ansformation is mor e consistent acr oss diff erent independent variables. In summar y, Applying a logarithmic tr ansformation t o the right sk ewed data can mak e the distribution mor e symmetric and stabiliz e the v ariance, making it potentially mor e useful for cer tain statistical analyses. Let's understand this with the help of an example: Suppose we ha ve values lik e, X: 1, 10, 100, 1000, 10000 Now let' s tak e a log of all these v alues, we will get: - ln(1) = 0 - ln(10) = 2.30 - ln(100) =",
    "source": "lec10.pdf::chunk4"
  },
  {
    "text": "4.60 - ln(1000) = 6.90 - ln(10000) = 9.21 Obser vation : We can clearly obser ver that after taking log of all the v alues it compr esses lar ger v alues mor e than smaller v alues. 10,000 got tr ansformed int o 9.21 and we can clearly see how much compr essed the v alues got. This can bring symmetr y to the distribution. We can also obser ve that after applying the log, v ariance also got stabiliz ed. Example on stabilizing v ariance: We can also obser ve that after applying the log, v ariance also got stabiliz ed. Let's consider a simple example t o illustr ate this: Suppose y ou ha ve a set of positiv e numbers with incr easing v ariance: Original Data: If you obser ve the diff erences between consecutiv e values, y ou'll see that the diff erences incr ease: Differences: . Now , if you tak e the logarithm of the original data: Log-T ransformed Data: . The diff erences between the log-tr ansformed v alues ar e now constant ar ound Differences: This constant diff erence suggests a stabiliz ed variance, which can be benecial in",
    "source": "lec10.pdf::chunk5"
  },
  {
    "text": "statistical analyses.1,2,4,8,16,32,â€¦ 1,2,4,8,16,â€¦ ğ‘™ğ‘›(1),ğ‘™ğ‘›(2),ğ‘™ğ‘›(4),ğ‘™ğ‘›(8),ğ‘™ğ‘›(16),â€¦ 0.693 ğ‘™ğ‘›(2)âˆ’ğ‘™ğ‘›(1),ğ‘™ğ‘›(4)âˆ’ğ‘™ğ‘›(2),ğ‘™ğ‘›(8)âˆ’ğ‘™ğ‘›(4),ğ‘™ğ‘›(16)âˆ’ğ‘™ğ‘›(8),â€¦ Let's understand the k ey char acteristics of a log-normal distribution. 1. Positivity: All v alues in a log-normal distribution ar e positiv e because the logarithm of any positiv e number is alwa ys real. Eg. Let' s say the original v alue is -1.5 then the log normal distribution v alue will be which is , this comes out t o be positiv e. 2. Skewedness: If the original data is right-sk ewed, the log-normal tr ansformation can mak e it mor e symmetric and bell-shaped. 3. Multiplicativ e Processes: Log-normal distributions ar e suitable for modelling scenarios wher e the nal outcome is inuenced b y the pr oduct of independent factors. In our dataset, we ar e awar e that deliv ery times ma y get aff ected b y various independent fact ors lik e trac, or der pr ocessing time , etc. In summar y, a log-normal distribution is a good t for positiv ely sk ewed, ensuring positivity , and aligning with multiplicativ e processes often seen in r eal-world scenarios.Key Char acteristics of a Log-Normal Distribution ğ‘‹ ğ‘’ğ‘‹=0.223 ğ‘’1.5 Now , let's see what is poisson",
    "source": "lec10.pdf::chunk6"
  },
  {
    "text": "distribution Scenario: Trac at a Toll Booth Imagine you're at a toll booth on a highway, observing the number of vehicles passing through the toll booth in a given time period. The P oisson distribution comes int o pla y when we want t o model the number of e vents that occur in a x ed inter val of time or space . In this case, vehicles passing thr ough the t oll booth ar e our e vent.Poisson DistributionîŒ“ Explanation: The P oisson distribution is a discr ete pr obability distribution particularly useful when dealing with e vents that occur r andomly and independently , but with a known a verage r ate. In our t oll booth scenario, we can mak e a f ew k ey obser vations: 1. Fixed Inter val: Let's say we want t o study the number of v ehicles passing thr ough the t oll booth in a specic time period, say 1 hour . 2. Average Rate: We ha ve an a verage r ate of v ehicles passing thr ough the t oll booth, let's say 30 v ehicles per hour . It is denoted as (lambda), which r",
    "source": "lec10.pdf::chunk7"
  },
  {
    "text": "epresents the a verage r ate of occurr ence of the e vent within a giv en inter val. Î» Here, Î» is 30 v ehicles per hour . Now , the poisson distribution helps us answer some questions like: Q1. What is the pr obability of exactly 25 v ehicles passing thr ough the t oll booth in the next hour? Q2. What is the pr obability of mor e than 40 v ehicles passing thr ough the t oll booth in the next hour? This t oll booth scenario is just one example of how the P oisson distribution is applied in v arious elds. The gr aph below shows examples of P oisson distributions with diff erent v alues of Î» . When Î» is low , the distribution is much longer on the right side of its peak than on its left . As Î» incr eases, the spr ead of distribution also incr eases If you keep incr easing, the distribution looks mor e and mor e similar t o a normal distribution . If a r andom v ariable follows a P oisson distribution, then the pr obability that successes can be found b",
    "source": "lec10.pdf::chunk8"
  },
  {
    "text": "y the following formula: wher e: Î»: rate or mean number of successes that occur during a specic inter val k: number of successes e: a constant equal t o appr oximately 2.71828 This is also known as Probability Mass F unction (PMF) of poisson distribution as using this formula we can calculate the pr obability of exact events.Poisson Distribution F ormula ğ‘‹ ğ‘‹=ğ‘˜ ğ‘ƒ[ğ‘‹=ğ‘˜]= âˆ— Î»ğ‘˜ğ‘’âˆ’Î» ğ‘˜! suppose a particular hospital experiences an average of 2 births per hour. We can use the formula above to determine Calculate the probability of experiencing 0, 1, 2, 3 births, etc. in a given hour: Here, rate ( ) = 2 e = constant= 2.71828Example 1:îŒ“ Î» Here, we can also nd the pr obability using the function in p ython i.e. poisson.pmf() as it is asking for the pr obability of an exact v alue We ha ve to pass 2 par ameters in this function, k: number of e vents and mu: average or r ateğ‘ƒ[ğ‘‹=0]= =0.1353 âˆ— 20ğ‘’âˆ’2 0! ğ‘ƒ[ğ‘‹=1]= =0.2707 âˆ— 21ğ‘’âˆ’2 1! ğ‘ƒ[ğ‘‹=2]= =0.2707 âˆ— 22ğ‘’âˆ’2 2! ğ‘ƒ[ğ‘‹=3]= =0.1804 âˆ— 23ğ‘’âˆ’2 3! # P[x=0] poisson.pmf(k= 0, mu=2) 0.1353352832366127 # P[x=1] poisson.pmf(k= 1, mu=2) 0.2706705664732254 # P[x=2] poisson.pmf(k=",
    "source": "lec10.pdf::chunk9"
  },
  {
    "text": "2, mu=2) 0.2706705664732254 # P[x=3] poisson.pmf(k= 3, mu=2) 0.18044704431548356 Let's look int o mor e examples. 1) Football Match Goals Imagine we ha ve collected data for all the football matches e ver happened, now we want t o analyz e the distribution of goals. We obser ve that the a verage goal per 90 mins match is 2.5 So the r ate will be 2.5 goals per match ( Î» = 2.5). Q. If I want t o know the pr obability of getting 1 goal in last 30 mins? This is wher e poisson distribution comes int o pla y. Here, the r ate is 2.5 goal/ 90 mins (per match) which mean a verage number of goals in 90 mins What will be the a verage number of goals in 45 mins? 2.5 goals -> 90 mins Average goals for half of the time will be half of the t otal a verage r ate Rate: 2.5/2 = 1.25/45 mins (per 45 mins) Similarly , we can dene a r ange for 30 mins, 1.25 goals -> 45 mins x goals? -> 30 mins Applications: x = (30 * 1.25)/45 Rate = 0.833 goals/30 mins So, Q1.",
    "source": "lec10.pdf::chunk10"
  },
  {
    "text": "How long should y ou sta y to witness a goal on a verage? On a verage, staying at least 45 minutes incr eases the pr obability of witnessing a goal during a football match. Because sta ying at least 45 minutes aligns with the a verage goal r ate of 1.25 goals per 45 minutes. This dur ation maximiz es the lik elihood of experiencing a goal during a football match based on the obser ved rate of scoring. Next example, 2) Suppor t Phone Calls Think about a suppor t centr e that r eceiv es 100 calls per hour . So the a verage call r eceiv ed per minute will be, 100 calls -> 60 mins (1 hr) x calls -> 1 min Rate: 100/60 = 1.666 calls/min This allows us t o analyz e the pr obability of r eceiving a cer tain number of calls within a specic time fr ame. The call center management can use this r ate t o determine the optimal number of cust omer ser vice r epresentativ es to ha ve on duty during diff erent time periods. For instance, during peak times, when the call r ate",
    "source": "lec10.pdf::chunk11"
  },
  {
    "text": "is high, mor e staff ma y be r equir ed to handle the incr eased v olume. One mor e example 3) Hospital OPD P atients Consider a hospital' s Outpatient Depar tment (OPD) wher e, on a verage, 200 patients visit in a da y ( Î» = 200). The a verage hourly r ate of patient arriv als can be calculated b y dividing the daily r ate b y the number of working hours. For example, if the facility oper ates for 8 hours, the hourly r ate would be patients per hour . The facility can use this information for r esour ce planning, such as determining the optimal number of staff, doct ors, and examination rooms needed t o handle the expected patient load eciently . These ar e some r eal lif e examples wher e poisson distribution can help us understand the liklihood of an e vent occurring in a specic time inter val or space=25200 8 Key rules that go vern the P oisson distribution: 1. Counting: The P oisson distribution is tailor ed for counting the number of discr ete e vents happening within a x ed inter val The",
    "source": "lec10.pdf::chunk12"
  },
  {
    "text": "e vents can tak e on v alues lik e 0, 1, 2, 3, and so on. 2. Independence: The occurr ence of one e vent should not aff ect the occurr ence of another e vent. Events ar e consider ed to be independent if the pr obability of one e vent happening doesn 't change based on whether another e vent has occurr ed. For example , if an accident occurs in Delhi at 4 PM, it will ha ve no impact on the occurr ence of an accident in Mumbai at the same time .Rules of P oisson Distribution îŒ“ Each e vent is independent of the other , and the outcome in one location does not inuence or aff ect the outcome in the other location. 3. Rate ( Î» or Î¼ ): The distribution is dened b y a single par ameter often denoted as Î» (lambda) or Î¼ (mu), which r epresents the a verage r ate of occurr ence of the e vent within the giv en inter val. This r ate r emains constant thr oughout the inter val and doesn 't change based on the occurr ences. 4. No Simultaneous E",
    "source": "lec10.pdf::chunk13"
  },
  {
    "text": "vents: The P oisson distribution assumes that ther e cannot be mor e than one occurr ence of the e vent at exactly the same time or within an innitesimally small inter val of time or space. For instance, if a family of v e people enters a st ore, it's counted as a single e vent, not v e separ ate e vents. Another example, two goals can 't be scor ed at a same time Let's look at the some examples using P oisson distribution A city sees 3 accidents per day on average. Find the probability that there will be 5 accidents tomorrow. Solution: Given, The r ate is giv en as 3 accidents per da y on a verage, Let \" \" denote the number of accidents t omorr ow. We say \" \" is P oisson distributed with r ate ( ) = 3 So, the pr obability that ther e will be 5 accidents t omorr ow is By using the formula, . Using p ython,Example 2:îŒ“ Î»=3 ğ‘‹ ğ‘‹ Î» ğ‘ƒ[ğ‘‹=5] ğ‘ƒ[ğ‘‹=5]= = âˆ— Î»5ğ‘’âˆ’Î» 5! âˆ— 35ğ‘’âˆ’3 5! # P[X=5] poisson.pmf(k= 5, mu=3) 0.10081881344492458 Ther e is a 10% chance that ther",
    "source": "lec10.pdf::chunk14"
  },
  {
    "text": "e will be 5 accidents t omorr ow. Next question Q1. Find the pr obability that ther e will be 5 or f ewer accidents t omorr ow? Here we want t o calculate , We will use poisson.cdf() here as we want t o calculate cumulativ e probability . We can dir ectly nd it using poisson.cdf()ğ‘ƒ[ğ‘‹â‰¤5] ğ‘ƒ[ğ‘‹â‰¤5]=ğ‘ƒ[ğ‘‹=0]+ğ‘ƒ[ğ‘‹=1]+ğ‘ƒ[ğ‘‹=2]+ğ‘ƒ[ğ‘‹=3]+ğ‘ƒ[ğ‘‹=4]+ğ‘ƒ[ğ‘‹=5] # P[X â‰¤ 5] poisson.cdf(k= 5, mu=3) 0.9160820579686966 Let \"X\" be the number of typos in a page in a printed book, with mean of 3 typos per page. What is the probability that a randomly selected page has atmost 1 typo? Here, rate ( ) = 3 we want t o nd for atmost 1 type, so we need t o nd which will be . We can dir ectly use poisson.cdf() hereExample 3:îŒ“ Î» ğ‘ƒ[ğ‘‹â‰¤1] ğ‘ƒ[ğ‘‹=0]+ğ‘ƒ[ğ‘‹=1] # P[xâ‰¤1] poisson.cdf(k= 1, mu=3) 0.1991482734714558 prob = poisson.pmf(k= 0, mu=3) + poisson.pmf(k= 1, mu=3) prob 0.1991482734714558 Ther e is a 19% chance that a r andomly selected page has atmost 1 typo Poisson appr oximation t o Binomial îŒ“ There are 80 students in a kinder garden class. Each one of them has 0.015 probability of forgetting their lunch on any given",
    "source": "lec10.pdf::chunk15"
  },
  {
    "text": "day. (a) What is the average or expected number of students who forgot lunch in the class? (b) What is the probability that exactly 3 of them will forget their lunch today? Solution: First question, rate = 80*0.015 # total rate rate 1.2 Conclusion : This implies that, on a verage, ther e are 1.2 students who for get their lunch in a giv en period. (b) What is the pr obability that exactly 3 of them will for get their lunch t oday? here, k = 3 and lambda = 1.2 We can dir ectly use poisson.pmf() poisson.pmf(k= 3, mu=1.2) 0.08674393303071422 Ther e is 8.67% chance that exactly 3 of them will for get their lunch t oday Q. Can I model this question int o binomial distribution? We ha ve 80 students, we can dene two pr obabilites her e probability of success = student for got the lunch = probability of failur e = We want , we can r epresent it as out of 80 trials, I want 3 success Using binomial formula, it will be we just mak e this question of binomialğ‘ƒ(ğ‘ ) 0.015 ğ‘ƒ(ğ‘“)1=ğ‘ƒ(ğ‘ )=1âˆ’0.015 ğ‘ƒ[ğ‘‹=3] (0.015(1âˆ’0.01580ğ¶3 )3)77 binom.pmf(k= 3, n=80, p=0.015) # Large n,",
    "source": "lec10.pdf::chunk16"
  },
  {
    "text": "small p, np=mu 0.08660120920447557 We got the similar answers using both poisson and binomial. In binomial We are counting the number of successes in trials wher e = In poisson Counting number of occurr ences in a giv en time inter val. Now , for 1 success we ha ve probability p so for n success, the pr obability will be 1 success -> p n success -> ? for n success -> np Here, the for 1 student is . So for 80 students will be From this, we can obeser ve that This appr oximation is known as the Poisson appr oximation t o the binomial distributionğ‘› ğ‘ƒ(ğ‘ )ğ‘ ğ‘ƒ(ğ‘ ) 0.015 ğ‘ƒ(ğ‘ ) 80âˆ—0.015=1.2 Î»=ğ‘›ğ‘The binomial distribution conv erges t owar ds the P oisson distribution as the number of trials goes t o innity while the pr oduct conv erges t o a nite limit. Ther efore, the P oisson distribution with par ameter can be used as an appr oximation t o of the binomial distribution if n is suciently lar ge and p is suciently small For a r easonable appr oximation: This appr oximation is good if and such that , or if and such that",
    "source": "lec10.pdf::chunk17"
  },
  {
    "text": ", or if and . The concept of \"lar ge enough \" for the number of trials is not x ed Howe ver, a commonly used guideline is that should be such that If the abo ve conditions met the we can use the P oisson distribution t o estimate the pr obabilities of diff erent e vent counts. So, in the context of our pr oblem , and , the conditions and are satised. We can use the P oisson distribution with as an appr oximation t o the binomial distribution.Conditions for a r easonable appr oximation: îŒ“ (ğ‘›) ğ‘›ğ‘ Î»=ğ‘›ğ‘ ğµ(ğ‘›,ğ‘) ğ‘›â‰¥20 ğ‘â‰¤0.05 ğ‘›ğ‘â‰¤1 ğ‘›>50 ğ‘<0.1 ğ‘›ğ‘<5 ğ‘›â‰¥100 ğ‘›ğ‘â‰¤10 (ğ‘›) ğ‘› ğ‘›ğ‘â‰¤10 ğ‘›=80 ğ‘=0.015 ğ‘›ğ‘â‰¤10 ğ‘â‰¤0.1 Î»=80Ã—0.015",
    "source": "lec10.pdf::chunk18"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Exponential Distribution Box-co x transformation Geometric Distribution Mean of Geometric DistributionContentîŒ“ Impor ting Libr aries import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from scipy.stats import poisson, expon, geom Exponential DistributionîŒ“ Q1) What is the pr obability of ha ving no message in 10 seconds? In this case, we ar e looking for the pr obability of k = 0 e vents (z ero messages) in a P oisson distribution. average r ate of messages arriving in 10 seconds will be Using P oisson DistributionExample: Y ou receiv e 240 messages per hour on a verage - assume P oisson distributed. Rate of messages arriving per second is îŒ“.1 15 rate = 10*240/3600 # this is 10 * (lambda) = 10 * 1/15 only poisson.pmf(k= 0, mu=10/15) 0.513417119032592 Let's calculate this using poisson distribution formula We know the formula for poisson distribution is for , poisson will be = = Note : is rate per second. is rate per 10 seconds. Now let' s focus",
    "source": "lec11.pdf::chunk0"
  },
  {
    "text": "on the next question for the moment. Let me know what will be the answer of that questionğ‘ƒ[ğ‘‹=ğ‘˜]= âˆ— Î»ğ‘˜ğ‘’âˆ’Î» ğ‘˜! ğ‘ƒ[ğ‘‹=0] âˆ— Î»0ğ‘’âˆ’10Î» 0!ğ‘’âˆ’10Î» Î» 10Î» Q2. What is the pr obability of waiting for mor e than 10 seconds for the next message? If you can see this question and abo ve question is exact same. In abo ve question we calculated no messages in 10 seconds which also means waiting for mor e than 10 seconds t o get message. So, Let T -> denote time t o wait for next message Is T is discr ete or continuous? -> continuous We can r epresent this as , answer will be same as abo ve What if I ask, Q3. What is the pr obability of waiting less than or equal t o 10 seconds? We can r epresent it as It is complement of , so t o nd this we can simply subtr act it fr om 1. So, This equation is known as exponential equation , we just deriv e the formula b y solving some questions. Generic equation is , Or If a r andom v ariable follows an exponential distribution, then the",
    "source": "lec11.pdf::chunk1"
  },
  {
    "text": "cumulativ e distribution function (CDF) of X can be written as: Wher e, is rate par ameter . is a constant r oughly equal t o 2.718 The probability density function (PDF) of exponential distribution is giv en b y, Recipr ocal of the r ate par ameter is r eferred as scale which is calculated as ğ‘ƒ[ğ‘‡>10] ğ‘ƒ[ğ‘‡>10]=ğ‘’âˆ’10Î» ğ‘ƒ[ğ‘‡â‰¤10] ğ‘ƒ[ğ‘‡>10] ğ‘ƒ[ğ‘‡â‰¤10]=1âˆ’ğ‘’âˆ’10Î» ğ‘ƒ[ğ‘‡â‰¤ğ‘¥]=1âˆ’ğ‘’âˆ’Î»ğ‘¥ ğ‘‹ ğ‘“(ğ‘¥;ğœ†)=1âˆ’ğ‘’âˆ’Î»ğ‘¥ Î» ğ‘’ ğ‘“(ğ‘¥;ğœ†)=Î»ğ‘’âˆ’Î»ğ‘¥ (1/Î») In exponential distribution the scale par ameter is r efered as . Wher e, = So, Exponential distribution is also written as, Solving question number 2 and 3 using expon() functionScale P arameter îŒ“ Î² Î²1/Î» ğ‘“(ğ‘¥;ğœ†)=1âˆ’ğ‘’âˆ’ğ‘¥ Î² # Q2) P[T > 10], scale = 1/rate = 1/(1/15) = 15 1- expon.cdf(x= 10, scale= 15) 0.513417119032592 # Q3) P[T <= 10] expon.cdf(x= 10, scale= 15) 0.486582880967408 ConclusionîŒ“ Poisson Distribution: Use Case: Models the number of e vents in a x ed inter val of time or space. Example Question: \"How many cust omers will enter a st ore in the next hour?\" \"How many messages will y ou receiv e in next 15 mins?\" \"How many calls can the call center expect in the next 30 minutes?\" Parameter: Rate ( Î»",
    "source": "lec11.pdf::chunk2"
  },
  {
    "text": ") represents the a verage number of e vents in the specied inter val. Exponential Distribution: Use Case: Models the time between consecutiv e events. Example Question: \"How long do I ha ve to wait for the next message?\" \"On a verage, how much time will a cust omer spend waiting for ser vice in a queue?\" \"How long, on a verage, will passengers wait between consecutiv e bus arriv als?\" Parameter: Scale r epresents the a verage time between e vents. It' s the r ecipr ocal of the r ate. Relation: Rate and Scale ar e recipr ocals; as one incr eases, the other decr eases. Now , let's solv e some examples You are working as a data engineer who has to resolve any bugs/ failures of machine learning models in production. The time taken to debug is exponentially distributed with mean of 5 minutes Mean of 5 mins: Is it a or , how t o decide? 1 bug is solv ed -> 5 mins. So how many bugs will be solv ed in 1 mins? 1/5. This is nothing but the r ate ( ) per minute. Now , if , Here mean time is",
    "source": "lec11.pdf::chunk3"
  },
  {
    "text": "r epresenting = 5. Q1 Find the pr obability of debugging in 4 t o 5 minutes We can r epresent it as , by using expon.cdf() , the pr obability will beExample: exponential distributionîŒ“ Î» Î² Î» Î»=1/5Î²=1/Î»=5 Î² ğ‘ƒ[4<ğ‘¥<5] # P [4 < T < 5] = P [T <= 5] - P[T <= 4] prob = expon.cdf(x= 5, scale= 5) - expon.cdf(x= 4, scale= 5) prob 0.08144952294577923 Q2 Find the pr obability of needing mor e than 6 minutes t o debug Here we want t o nd ğ‘ƒ[ğ‘¥>6] prob = 1 - expon.cdf(x= 6, scale= 5) prob 0.3011942119122022 Q3. Giv en that y ou ha ve alr eady spent 3 minutes, what is the pr obability of needing mor e than 9 minutes It states that we ha ve alr eady spent 3 minutes tr ying t o solv e the bug and we want t o nd pr obability of needing t otal time mor e than 9 mins. We can r epresent it in this wa y: Means, giv en that we ha ve alr eady 3 minutes, nd the pr obability that it'll tak e mor e than 9 minutes. so, as if",
    "source": "lec11.pdf::chunk4"
  },
  {
    "text": "something is gr eater than 9 will be also gr eater than 3, so their intersection will r eturn gr eater than 9 only . Now , by using expon.cdf() we can calculate the pr obabilityğ‘ƒ[ğ‘‡>9|ğ‘‡>3] ğ‘ƒ[ğ‘‡>9|ğ‘‡>3]=ğ‘ƒ[(ğ‘‡>9)âˆ©(ğ‘‡>3)] ğ‘ƒ[ğ‘‡>3] ğ‘ƒ[ğ‘‡>9|ğ‘‡>3]=ğ‘ƒ[ğ‘‡>9] ğ‘ƒ[ğ‘‡>3] # P[T > 9 | T > 3] prob = ( 1 - expon.cdf(x= 9, scale= 5))/(1 - expon.cdf(x= 3, scale= 5)) prob 0.30119421191220214 Now , by conv entional formula we can write and in the pr evious question, So, Let's verify if we get the same answer for both the equation= =ğ‘ƒ[ğ‘‡>9] ğ‘ƒ[ğ‘‡>3]ğ‘’âˆ’9Î» ğ‘’âˆ’3Î» ğ‘’âˆ’6Î» ğ‘ƒ[ğ‘‡>6]=ğ‘’âˆ’6Î» ğ‘ƒ[ğ‘‡>9|ğ‘‡>3]=ğ‘ƒ[ğ‘‡>6] # P[T > 9 | T > 3] prob_1 = ( 1 - expon.cdf(x= 9, scale= 5))/(1 - expon.cdf(x= 3, scale= 5)) # P[T>6] prob_2 = 1-expon.cdf(x= 6, scale= 5) print(prob_1, prob_2) 0.30119421191220214 0.3011942119122022 Both the v alues ar e same. This is known as memor yless pr oper ty of exponential distribution. The fact that y ou took thr ee minutes so far does not aff ect how much mor e you might tak e to debug What is memor yless pr oper ty? The memor yless pr oper ty essentially means that the time y ou've alr eady spent on",
    "source": "lec11.pdf::chunk5"
  },
  {
    "text": "an e vent doesn 't aff ect the futur e waiting time. In the context of the exponential distribution, it means that the pr obability of needing mor e time in the futur e is the same, regar dless of how much time has alr eady passed. For example, in the rst question, we want t o nd the pr obability of needing mor e than 6 minutes t o debug. Let' s call this e vent A. In the second question, we 're inter ested in the pr obability of needing mor e than 9 minutes giv en that y ou've alr eady spent 3 minutes, which we 'll call e vent B. The memor yless pr oper ty tells us that the pr obability of e vent B, is the same as the pr obability of e vent A. This is because the exponential distribution tr eats each moment as if y ou're star ting anew , regar dless of the past.Memor yless pr oper ty of the Exponential distribution: Now , if you remember in the last lectur e we saw about log normal distribution wher e we wer e transforming non normal data int o normally",
    "source": "lec11.pdf::chunk6"
  },
  {
    "text": "distributed data using logarithmBox Co x transformation îŒ“ Is ther e any other techniques which can tr ansform non normally distributed data int o normally distributed data? In statistics, the Box-Co x transformation is another technique which is used t o stabiliz e the v ariance and mak e a dataset mor e closely appr oximate a normal distribution . It is par ticularly useful when dealing with data that has v arying le vels of spr ead and doesn 't follow a normal distribution. Formula for Bo x-Co x Transformation: The basic idea behind this method is to nd best v alue for Î» such that the tr ansformed data is as close t o normally distributed as possible , using the following formula: , if , if Here: is the tr ansformed v ariable. is the original v ariable. is the tr ansformation par ameter . Q. How t o nd the optimal v alue of : The challenge is t o nd the best v alue for that maximiz es the normality of the tr ansformed data. Ther e are some techniques t o nd optimal v alue of 1. maximum liklehood estimation (MLE) 2. Grid Sear",
    "source": "lec11.pdf::chunk7"
  },
  {
    "text": "ch 3. Q-Q Plot 4. Cross v alidation Commonly MLE is used t o nd the optimal value. In SciP y's bo xcox function also, the optimal Î» value is found using a maximum lik elihood estimation ( MLE ) appr oach. We will study this appr oach in later modules.ğ‘Œ(Î»)=âˆ’1 ğ‘ŒÎ» Î»Î»â‰ 0 ğ‘Œ(Î»)=ğ‘™ğ‘›(ğ‘Œ)Î»=0 ğ‘Œ(Î») ğ‘Œ Î» Î» Î» Î» Î» Suppose we gener ate a r andom set of 1,000 v alues that come fr om an exponential distribution:Example: Bo x cox transformation in p ython îŒ“ import numpy as np from scipy.stats import boxcox import seaborn as sns #make this example reproducible np.random.seed( 0) #generate dataset data = np.random.exponential(size= 1000) #plot the distribution of data values sns.distplot(data, hist= False, kde=True) <ipython-input-1-a10f852b3520>:12: UserWarning: `distplot` is a deprecated function and will be removed in seaborn v0.14.0. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots). For a guide to updating your code to use the new functions, please see https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751 sns.distplot(data, hist=False, kde=True) <Axes: ylabel='Density'> We can use the boxcox() function t o nd an optimal v alue of lambda that pr oduces a mor e",
    "source": "lec11.pdf::chunk8"
  },
  {
    "text": "normal distribution: #perform Box-Cox transformation on original data transformed_data, best_lambda = boxcox(data) #plot the distribution of the transformed data val ues sns.distplot(transformed_data, hist= False, kde=True) <ipython-input-2-c622ffd9e6b8>:5: UserWarning: `distplot` is a deprecated function and will be removed in seaborn v0.14.0. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots). For a guide to updating your code to use the new functions, please see https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751 sns.distplot(transformed_data, hist=False, kde=True) <Axes: ylabel='Density'> We can obser ve that the tr ansformed data follows mor e of a normal distribution. We can also nd the exact lambda v alue which is used t o per form the Bo x-Co x transformation: #display optimal lambda value print(best_lambda) 0.2420131978174143 The optimal lambda was found t o be r oughly 0.242. Thus, each data v alue was tr ansformed using the following equation: , if Putting the v alue of lambda in the equation, Transformed_data = We can conrm this b y looking at the v alues fr om the original data compar ed to the tr ansformed data:ğ‘Œ(Î»)=âˆ’1 ğ‘ŒÎ» Î»Î»â‰ 0 ğ‘œğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›ğ‘ğ‘™ âˆ’1 0.242 0.242 #view first five values of original dataset data[0:5] array([0.79587451, 1.25593076,",
    "source": "lec11.pdf::chunk9"
  },
  {
    "text": "0.92322315, 0.78720115, 0.55104849]) #view first five values of transformed dataset transformed_data[ 0:5] array([-0.22212062, 0.23427768, -0.07911706, -0.23247555, -0.55495228]) The rst v alue in the original dataset was 0.79587. Thus, we applied the following formula t o transform this v alue: Transformed_data = = We can conrm that the rst v alue in the tr ansformed dataset is indeed -0.222.â€“1 0.795870.242 0.242âˆ’0.222 Unlik e the log tr ansformation, the Bo x-Co x transformation is not limited t o handling right-sk ewed data . It is a family of power tr ansformations, and b y selecting an appr opriate par ameter (lambda), it can addr ess both positiv ely and negativ ely skewed data .Difference between bo x cox and log normal tr ansformation. Scenario: Imagine you're in a job search, and you're giving interviews until you land your first job. Q1. What ar e the possible outcomes in this situation? Either y ou succeed (s) or fail (f ) at each inter view . Now , Suppose y ou land a job in the rst inter view itself: Outcome will be {s} What if y ou fail in y our rst inter view , so y ou will giv e second inter",
    "source": "lec11.pdf::chunk10"
  },
  {
    "text": "view and land a job in y our 2nd inter view Outcome will be {fs} What if y ou fail in y our 2nd inter view but land a job in 3r d inter view Outcome will be {ffs} As we mentioned, y ou will k eep giving inter views till y ou land a job. So, The sample space for this situation is lik e a sequence of attempts will be S = {s, fs, ffs, fffs, ...}Geometric DistributionîŒ“ Here, we 'll use to represent the number of inter views, and is the success r ate, which is let' s say 0.1 So, success will be and failur e will be Now , let's nd the pr obability of diff erent v alues of X: : This is the pr obability of succeeding in the rst inter view So . : To get this, y ou'd fail in the rst inter view (1-p), then succeed in the second inter view (p) , So . : Similarly , you'd fail twice ((1-p) * (1-p)) and then succeed (p) So, It will k eep going on for X=4, X=5 ...ğ‘‹ ğ‘ ğ‘ 1âˆ’ğ‘ ğ‘ƒ(ğ‘‹=1) ğ‘ƒ(ğ‘‹=1)=ğ‘=0.1 ğ‘ƒ(ğ‘‹=2) ğ‘ƒ(ğ‘‹=2)=(1âˆ’ğ‘)âˆ—ğ‘=0.9âˆ—0.1 ğ‘ƒ(ğ‘‹=3) ğ‘ƒ(ğ‘‹=3)=(1âˆ’ğ‘)âˆ—(1âˆ’ğ‘)âˆ—ğ‘= âˆ—0.1 0.92",
    "source": "lec11.pdf::chunk11"
  },
  {
    "text": "Simplifying we ha ve, and so on.. We can see this pattern continues: Replacing with and with , we will getğ‘ƒ(ğ‘‹=1)=(0.9âˆ—(0.1) )0 ğ‘ƒ(ğ‘‹=2)=(0.9âˆ—(0.1) )1 ğ‘ƒ(ğ‘‹=3)=(0.9âˆ—(0.1) )2 ğ‘ƒ(ğ‘‹=4)=(0.9âˆ—(0.1) )3 ğ‘ƒ(ğ‘‹=ğ‘˜)=(0.9 âˆ—(0.1) )ğ‘˜âˆ’1 0.9 (1âˆ’ğ‘) 0.1 (ğ‘) ğ‘ƒ(ğ‘‹=ğ‘˜)=(1âˆ’ğ‘ âˆ—ğ‘ )ğ‘˜âˆ’1 This pr obability distribution is known as the Geometric Distribution. It tells us the pr obability of how many attempts it tak es to achie ve the rst success. In other wor ds, The geometric distribution is a discr ete pr obability distribution that calculates the pr obability of the rst success occurring during a bernoulli trial . This distribution is an example of a Pr obability Mass F unction (PMF) because it calculates lik elihood for discr ete r andom v ariable. Let's look int o code Imagine we ar e ipping a coin and we want t o achie ve heads on the coin. Let's see the pr obability of getting heads in each trials. # p = probability of success p = 0.1 # the number of trials x_vals = np.arange( 1, 20) # The k = the number of trials, and the p = the pr obability of success, # using geom.pmf() function we can calculate proba bility",
    "source": "lec11.pdf::chunk12"
  },
  {
    "text": "probs_geom = geom.pmf(x_vals, p=p) <Axes: > sns.barplot(x=x_vals, y=probs_geom) Here, each bar is r epresenting the pr obability of achie ving success (getting heads) in a specic number of trials . Since p is 0.1, the pr obability of success is r elativ ely low . In a geometric distribution, the mean (or expectation) is the a verage number of attempts needed t o achie ve success in a series of trials . Imagine a scenario: You are flipping a fair coin repeatedly until you get heads for the first time. You're interested in finding out, on average, how many times you need to flip the coin before you get that first heads.Geometric Distribution Mean (Expected V alue) This is wher e the geometric distribution comes int o pla y. The mean (or expectation) r epresents the a verage number of trials (coin ips, in this case) it tak es to achie ve the desir ed outcome (getting heads). To calculate the mean, y ou can use the following formula: Mean = Or, In this case, the \"Pr obability of Success\" is the pr obability of getting heads on a single coin ip, which is . So, for our example: Mean",
    "source": "lec11.pdf::chunk13"
  },
  {
    "text": "This means, on a verage, y ou would need t o ip the coin two times befor e you get heads for the rst time . Note: Keep in mind that this is just an a verage, and in r eality , you might get heads on y our rst ip or after se veral mor e ips.(Î¼)1 ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ ğ‘œğ‘“ ğ‘†ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘  ğ¸[ğ‘‹]=1/ğ‘ 1/2 (Î¼)= =21 1/2 Suppose we throw a dice till the first time we get 6. (a) What is the probability that we have to throw 4 times? (b) What is the expected number of throws to get the first 6? Solution: First, let' s dene the pr obabilities of success and failur e P(s) = 1/6 P(f) = 1 - P(s) = 5/6 (a) Pr obability that we ha ve to thr ow 4 times . This means, what is the pr obability that we will obtain 6 on 4th tr y?. In other wor ds, we failed on rst 3 tries and got success on 4th tr y. By using the geometric distribution formula, = We can implement this in p ython using geom.pmf() function.Example on geometric distributionîŒ“ ğ‘ƒ(ğ‘‹=4)=(5/6âˆ—(1/6) )3 0.0964 # probability that we have",
    "source": "lec11.pdf::chunk14"
  },
  {
    "text": "to throw 4 times is # k = no. of trials and p = success rate prob = geom.pmf(k= 4, p=1/6) print(\"Probability that we have to throw 4 times to obta in 6 is \" , prob) Probability that we have to throw 4 times to obtain 6 is 0.09645061728395063 Let's solv e the second question: (b) Expected number of thr ows t o get the rst 6? The expected number of thr ows can be calculated using this formula, E[X] = 1/p So, the expected number of thr ows t o get the rst 6 is: Conclusionğ¸[ğ‘‹]= =61 1/6 On a verage, y ou would need t o thr ow the die 6 times t o get the rst 6. Suppose you are playing a game where success rate of winning a prize is 0.7. (a) What is the probability of winning a prize on 4th attempt? (b) What is the probability that you don't win in 2 attempts? (c) What is the expected number of trials to get the first success? Solution: Given, p = 0.7 Let's use geom function t o answer questionsExample on geometric meanîŒ“ # (a) the probability of winning a prize on 4th at",
    "source": "lec11.pdf::chunk15"
  },
  {
    "text": "tempt prob = geom.pmf(k= 4, p=0.7) print(\"the probability of winning a prize on 4th attempt is \", prob) the probability of winning a prize on 4th attempt is 0.018900000000000007 (b) The pr obability that y ou don 't win in 2 attempts? To nd the pr obability of not winning in 2 attempts, we need t o calculate pr obability of needing mor e than 2 attempts. It ma y tak e 3 attempts, 4 attempts, 5 attempts or e ven mor e. Means, We need t o calculate the cumulativ e probability of all this attempts By doing, Total pr obability - (pr obability of 1st attempt + pr obability of 2nd attempt) , we will get cumulativ e probability of all the attempts other than 1 and 2. Now using geom.cdf we can calculate the cumulativ e probability of rst 2 e vents then subtr act it fr om 1ğ‘ƒ[ğ‘‹>2] # (b) the probability that you don't win in 2 atte mpts # Use the cumulative distribution function (CDF) t o find the probability of not winning in 2 attempt s prob = geom.cdf (k=2, p=0.7) not_winning_prob = 1 - prob print(\"the probability that you don't win in",
    "source": "lec11.pdf::chunk16"
  },
  {
    "text": "2 attempts is \", not_winning_prob ) the probability that you don't win in 2 attempts is 0.09000000000000008 # (c) the expected number of trials to get the fir st success will be E[X] = 1/p expected = 1/0.7 print(\"the expected number of trials to get the first su ccess is \" , expected ) î®¾the expected number of trials to get the first success is 1.4285714285714286",
    "source": "lec11.pdf::chunk17"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Conditional Pr obability Multiplication Rule Marginal and Joint Pr obability Law of Total Pr obability Baye's Theor em Prior , Posterior and Lik elihood Pr obabilitiesContentîŒ“ Conditional pr obability is a v ery impor tant concept t o understand. In our daily lif e, all of y ou see dir ect examples of conditional pr obability . Lets look at one of them. When typing a message on WhatsApp, we often encounter suggested wor ds after typing a f ew. For instance, after typing \"How are\", we might see suggestions lik e \"you\", \"things\" , and \"the\". While these suggestions ar en't guar anteed t o be the next wor d you'll type but the y're highly probable choices. Is that magic? How did the y know which wor ds you ma y want t o use next? Let's assign a simple notations Let represents the rst wor d Let represents the second wor d Let represents the thir d wor dWhatsA pp A utocomplete Example îŒ“ ğ‘¥1 ğ‘¥2 ğ‘¥3 Now , you",
    "source": "lec2.pdf::chunk0"
  },
  {
    "text": "ha ve giv en the following information t o the k eyboar d: = \"How\" = \"are\" Now internally , the algorithm needs t o compute the pr obability for a wor d that belongs in the dictionar y, given the information about wor ds and . Consider this structur e: Here, represents the e vent whose pr obability we ar e trying t o nd represents the e vents that ha ve alr eady happened / information giv en to us The v ertical line | represents conditional pr obability Ther efore, we can r epresent it as: Read it as: Probability of the wor d given that we ha ve seen the wor ds and . It then pr esents its ndings, i.e. the wor ds that ar e most lik ely to occur (ha ving maximum probability) giv en that we ha ve seen the wor ds and .ğ‘¥1 ğ‘¥2 ğ‘¤ ğ‘¥1 ğ‘¥2 ğ‘ƒ(ğ´|ğµ) ğ´ ğµ ğ‘ƒ( =ğ‘¤| =\"ğ»ğ‘œğ‘¤\" ğ‘ğ‘›ğ‘‘ =\"ğ‘ğ‘Ÿğ‘’\") ğ‘¥3 ğ‘¥1 ğ‘¥2 ğ‘¥3 ğ‘¥1 ğ‘¥2 ğ‘¥1 ğ‘¥2 Note: The sequence is also impor tant her e. you, things, the are the t op suggestions when \"How\" and \"are\". It would suggest diff erent wor ds",
    "source": "lec2.pdf::chunk1"
  },
  {
    "text": "if the case was \"are\" and \"How\" Since this is not a sequence of wor ds used v ery often, it might not giv e good suggestions her e. Auto complete is another example.=ğ‘¥1 =ğ‘¥2 =ğ‘¥1 =ğ‘¥2 Conditional Pr obability îŒ“ Probability of E vent A, giv en E vent B has alr eady happened, is equiv alent t o the pr obability of A âˆ©B , divided b y probability of e vent B i.e. This equation is known as the Conditional Pr obability F ormulağ‘ƒ(ğ´|ğµ)=ğ‘ƒ(ğ´âˆ©ğµ) ğ‘ƒ(ğµ) Multiplication RuleîŒ“ Let's analyse this fur ther, From the abo ve formula we will get: In pr obability and statistics, this is known as the Product / Multiplication Rule . Similarly , we can expand ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğ´|ğµ).ğ‘ƒ(ğµ) ğ‘ƒ(ğµâˆ©ğ´)=ğ‘ƒ(ğµ|ğ´).ğ‘ƒ(ğ´) Marginal and Joint Pr obabilities îŒ“ Experiment: Sachin Tendulkar batting for IndiaîŒ“ Let's dene the e vents happening her e: : Sachin 's team winning the match : Sachin scoring a centur yğ‘Š ğ¶ Let's answer a f ew questions based on this contingency table Q1.What is the pr obability that Sachin 's team wins the match? We need t o nd Q2.What is the pr obability of Sachin scoring a centur y? Similarly ,",
    "source": "lec2.pdf::chunk2"
  },
  {
    "text": "we can calculate and as well. All of these pr obability v alues ar e known as Marginal Pr obability It is the pr obability of an e vent irr espectiv e of the outcome of other v ariable. For instance, consider It denotes the t otal pr obability of Sachin 's team winning the match, considering both possibilities that Sachin ma y or ma y not scor e a centur y. It is not conditioned on another e vent. It ma y be thought of as an unconditional probability .1) Mar ginal Pr obability ğ‘ƒ(ğ‘Š)= =ğ‘ğ‘œ ğ‘œğ‘“ ğ‘šğ‘ğ‘¡ğ‘â„ğ‘’ğ‘  ğ‘¤ğ‘œğ‘› ğ‘ğ‘¦ ğ‘†ğ‘ğ‘â„ğ‘–ğ‘› ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘›ğ‘œ ğ‘œğ‘“ ğ‘šğ‘ğ‘¡ğ‘â„ğ‘’ğ‘ 184 360 ğ‘ƒ(ğ¶)= =ğ‘ğ‘œ ğ‘œğ‘“ ğ‘šğ‘ğ‘¡ğ‘â„ğ‘’ğ‘  ğ‘¤ğ‘–ğ‘¡â„ ğ‘ğ‘’ğ‘›ğ‘¡ğ‘¢ğ‘Ÿğ‘¦ ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘›ğ‘œ ğ‘œğ‘“ ğ‘šğ‘ğ‘¡ğ‘â„ğ‘’ğ‘ 46 360 ğ‘ƒ( )ğ‘Šğ¶ğ‘ƒ( )ğ¶ğ¶ ğ‘ƒ(ğ‘Š) Other example: Probability that a car d drawn is a 4 : P(four)=1/13. This includes the possibility of the 4 being a spades, hear t, club or diamond. Probability that a car d drawn is spades : P(spades)=1/4. Now let' s look at the second type of pr obability v alues, b y answering the following questions. Q1.What is the pr obability that Sachin 's team wins AND he scor es a centur y? We need t o",
    "source": "lec2.pdf::chunk3"
  },
  {
    "text": "nd Q2.What is the pr obability that Sachin scor ed a centur y AND his team wins? We need t o nd This will be the same as Q3.What is the pr obability that Sachin scor es a centur y AND his team loses? Similarly , we can nd and Note: Here we calculated the lik elihood of two e vents occurring together and at the same point in time. This type of pr obability v alue is known as Joint Pr obability . And it is r epresented as we saw: Wher e, A and B ar e 2 e vents. It is r ead as Probability that event A and B happen at same time. Other Example: the pr obability that a car d is a four and r ed = P(four and r ed) = 2/522) Joint Pr obability îŒ“ ğ‘ƒ(ğ‘Šâˆ©ğ¶)=30 360 ğ‘ƒ(ğ¶âˆ©ğ‘Š) ğ‘ƒ(ğ¶âˆ©ğ‘Š)=ğ‘ƒ(ğ‘Šâˆ©ğ¶)=30 360 ğ‘ƒ( âˆ©ğ¶)= ğ‘Šğ¶ 16 360 ğ‘ƒ( âˆ© ) ğ‘Šğ¶ğ¶ğ¶ğ‘ƒ(ğ‘Šâˆ© )ğ¶ğ¶ ğ‘ƒ(ğ´âˆ©ğµ) The thir d kind of pr obability v alue, we 've just studied, i.e. Conditional Pr obability . Let's answer a f ew questions on this also Q1.What is the pr obability that Sachin 's team wins the match giv en",
    "source": "lec2.pdf::chunk4"
  },
  {
    "text": "that he scor ed a centur y? Since it is giv en that he scor es a centur y, our subset r educes t o the second r ow. Now since we want t o nd the pr ob of team winning among these matches, our pr obability becomes: Q2.What is the pr obability that Sachin scor es a centur y, given that his team has won the match? As per the giv en extr a information, our subset r educes t o the second column. So among these 184 matches, wher e India won, Sachin scor ed a centur y in only 30 matches. Ther efore Similarly , we can be ask ed to calculate other conditional pr obabilities such as: , , , etc.ğ‘ƒ(ğ‘Š |ğ¶)=30 46 ğ‘ƒ(ğ¶|ğ‘Š)=30 184 ğ‘ƒ(ğ‘Š | )ğ¶ğ¶ ğ‘ƒ( |ğ¶) ğ‘Šğ¶ğ‘ƒ(ğ¶| )ğ‘Šğ¶ Q.How can we nd the v alues of Mar ginal Pr obability? If we r e-arr ange the formula of conditional pr obability , we will get get: This is known as Law of Total Pr obabilityLaw of Total Pr obability îŒ“ ğ‘ƒ(ğ´|ğµ)=ğ‘ƒ(ğ´âˆ©ğµ) ğ‘ƒ(ğµ) ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğ´|ğµ)âˆ—ğ‘ƒ(ğµ) Mathematically , The Law of Total Pr obability is stated as follows: Let's have a look int o",
    "source": "lec2.pdf::chunk5"
  },
  {
    "text": "example Example: Email Spam Detection The Law of Total Pr obability helps combines the information fr om multiple scenarios or conditions t o arriv e at a compr ehensiv e probability estimate, making it a v aluable t ool in v arious data science and machine learning applications.Total Pr obability Law Generic F ormula ğ‘ƒ(ğ´)= ğ‘ƒ(ğ´âˆ£ )ğ‘ƒ() âˆ‘ğ‘› ğ‘–=1ğµğ‘–ğµğ‘– Formulas learned so farîŒ“ 1) Conditional Pr obability: ğ‘ƒ(ğ´âˆ£ğµ)=ğ‘ƒ(ğ´âˆ©ğµ) ğ‘ƒ(ğµ) 2) Multiplication Rule: ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğ´âˆ£ğµ)â‹…ğ‘ƒ(ğµ) 3) Law of Total Pr obability: ğ‘ƒ(ğ´)= ğ‘ƒ(ğ´âˆ£ )ğ‘ƒ() âˆ‘ğ‘› ğ‘–=1ğµğ‘–ğµğ‘– Let's jump t o new concept This equation that we used her e is known as the Bayes Theor em.Baye's Theor em îŒ“ ğ‘ƒ(ğ´|ğµ)=ğ‘ƒ(ğµ|ğ´).ğ‘ƒ(ğ´) ğ‘ƒ(ğµ) From the questions we ha ve solv ed so far , Q1. Can we sa y that ? We know that and represent the same subset, i.e. the common elements between A and B. And, fr om the Multiplication Rule we can expand them as: Since the LHS of both these equations is same, we can equate the RHS also. Dividing both sides b y , This is exactly the equation of Ba ye's Theor em.Quick Deriv ation of Ba yes Theor em ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğµâˆ©ğ´) ğ´âˆ©ğµ ğµâˆ©ğ´ ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğ´|ğµ).ğ‘ƒ(ğµ) ğ‘ƒ(ğµâˆ©ğ´)=ğ‘ƒ(ğµ|ğ´).ğ‘ƒ(ğ´) ğ‘ƒ(ğ´|ğµ).ğ‘ƒ(ğµ)=ğ‘ƒ(ğµ|ğ´).ğ‘ƒ(ğ´) ğ‘ƒ(ğµ) ğ‘ƒ(ğ´|ğµ)=ğ‘ƒ(ğµ|ğ´).ğ‘ƒ(ğ´)",
    "source": "lec2.pdf::chunk6"
  },
  {
    "text": "ğ‘ƒ(ğµ) Let's tak e a closer look at the Ba yes equation. Prior , Posterior and Lik elihood Pr obabilities îŒ“ It consists of 4 par ts: Posterior pr obability (updated pr obability after the e vidence is consider ed) Prior pr obability (the pr obability befor e the e vidence is consider ed) Likelihood (probability of the e vidence, giv en the belief is true) Marginal pr obability (probability of the e vidence, under any cir cumstance) To understand this better , let's think in a diff erent context. Consider 2 e vents: Hypothesis (which can be true or false), and Evidence (which can be pr esent or absent). Ther efore, we can write ba yes theor em as follows: Let's understand the diff erent terms her e. Posterior pr obability The Ba yes' Theor em lets y ou calculate the posterior (or \"updated\") pr obability . It is the conditional pr obability of the hypothesis being true, if the e vidence is present. ğ‘ƒ(ğ»ğ‘¦ğ‘ğ‘œğ‘¡â„ğ‘’ğ‘ ğ‘–ğ‘ |ğ¸ğ‘£ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’) Prior Pr obability Can be per ceived as y our belief in the hypothesis befor e seeing the new e vidence. Ther efore, if we ha ve a str ong belief in the hypothesis",
    "source": "lec2.pdf::chunk7"
  },
  {
    "text": "alr eady , the prior pr obability will be lar ge. Likelihood The prior is multiplied b y a fr action. Think of this as the \" strength \" of the e vidence. The posterior pr obability is gr eater when the t op par t (numer ator) is big, and the bottom par t (denominat or) is small. The numer ator is the lik elihood. It is the conditional pr obability of the evidence being pr esent, giv en the hypothesis is true. This is not the same as the posterior!! Marginal Pr obability Notice the denominat or of this fr action. It is the mar ginal pr obability of the e vidence. That is, it is the probability of the e vidence being pr esent, whether the hypothesis is true or false. We can nd it using Total Pr obability Law The smaller the denominat or, the mor e \"convincing\" the e videnceğ‘ƒ(ğ»ğ‘¦ğ‘ğ‘œğ‘¡â„ğ‘’ğ‘ ğ‘–ğ‘ ) ğ‘ƒ(ğ¸ğ‘£ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’|ğ»ğ‘¦ğ‘ğ‘œğ‘¡â„ğ‘’ğ‘ ğ‘–ğ‘ )â‰ ğ‘ƒ(ğ»ğ‘¦ğ‘ğ‘œğ‘¡â„ğ‘’ğ‘ ğ‘–ğ‘ |ğ¸ğ‘£ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’) ğ‘ƒ(ğ¸ğ‘£ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’) î‰‚ î‰",
    "source": "lec2.pdf::chunk8"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Problem Solving Mini Case StudyContentîŒ“ Let's recall all the formulas that we ha ve learned so far , 1. Conditional pr obability: 2. From conditional pr obability we will get, which is known as Multiplication Rule 3. Bayes Theor em: 4. Law of t otal pr obability: 5. Independent E vents: Formulas learnt so far ğ‘ƒ[ğ´|ğµ]=ğ‘ƒ[ğ´âˆ©ğµ] ğ‘ƒ[ğµ] ğ‘ƒ[ğ´âˆ©ğµ]=ğ‘ƒ[ğ´|ğµ] âˆ— ğ‘ƒ[ğµ] ğ‘ƒ[ğ´|ğµ]=ğ‘ƒ[ğµ|ğ´] âˆ— ğ‘ƒ[ğµ] ğ‘ƒ[ğ´] ğ‘ƒ(ğ´)= ğ‘ƒ(ğ´âˆ£)ğ‘ƒ() âˆ‘ğ‘› ğ‘–=1ğµğ‘–ğµğ‘– ğ‘ƒ[ğ´âˆ©ğµ]=ğ‘ƒ[ğ´] âˆ— ğ‘ƒ[ğµ] Now let' s verify one claim. We know that if A and B ar e mutually ex clusiv e or Disjoint e vents: Note : is a null/empty set as A and B can 't occur at the same time So, But in the case of independent e vents: ( we just saw abo ve) In the case of mutually ex clusiv e events is not equal t o , as A and B ar e not independent. Ther efore, the claim is pr oven: If A and B ar e mutually ex clusiv e, then A and B ar e not",
    "source": "lec3.pdf::chunk0"
  },
  {
    "text": "independent. Alternate Method : Using the conditional pr obability formula: For Disjoint e vents: So, For independent E vents: So, As we can see in both the e vents is diff erent Hence, we can conclude that : If A and B ar e mutually Ex clusiv e then A and B ar e not independent.Claim: If A and B ar e mutually Ex clusiv e then A and B ar e not independent. îŒ“ ğ´âˆ©ğµ={} ğ´âˆ©ğµ ğ‘ƒ(ğ´âˆ©ğµ)=0 ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğ´)âˆ—ğ‘ƒ(ğµ) ğ‘ƒ(ğ´âˆ©ğµ) ğ‘ƒ(ğ´)âˆ—ğ‘ƒ(ğµ) ğ‘ƒ(ğ´|ğµ)=ğ‘ƒ(ğ´âˆ©ğµ) ğ‘ƒ(ğµ) ğ‘ƒ(ğ´âˆ©ğµ)=0 ğ‘ƒ(ğ´|ğµ)= =00 ğ‘ƒ(ğµ) ğ‘ƒ(ğ´âˆ©ğµ)=ğ‘ƒ(ğ´)âˆ—ğ‘ƒ(ğµ) ğ‘ƒ(ğ´|ğµ)= =ğ‘ƒ(ğ´)ğ‘ƒ(ğ´) âˆ— ğ‘ƒ(ğµ) ğ‘ƒ(ğµ) ğ‘ƒ(ğ´|ğµ) Double-click (or enter) t o edit In a university, 30% of faculty members are females. Of the female faculty members, 60% have a PHD. Of the male faculty members, 40% - What is the probability that a randomly chosen faculty member is a female and has PHD? - What is the probability that a randomly chosen faculty member is a male and has PHD? - What is the probability that a randomly chosen faculty member has a PHD? - What is the probability that a randomly chosen PHD holder is female? Explanation: Given, Female faculty members = 30% Out of this 30% members, 60% ha ve",
    "source": "lec3.pdf::chunk1"
  },
  {
    "text": "PHD Male faculty members = 100 - 30 = 70% Out of this 70% members, 40% ha ve PHD Let's dene pr obabilities: probability that a r andomly chosen faculty member is a f emale i.e. Given that faculty member is a F emale, the pr obability that she has a PHD is i.e probability that a r andomly chosen faculty member is a Male i.e. Given that faculty member is a Male, the pr obability that he has a PHD is i.e Answering questions: Q1. What is the pr obability that a r andomly chosen faculty member is a f emale and has PHD? We know AND means intersection, her e we want t o nd Using the formula of conditional pr obability , So, Adding v alues int o the equation Conclusion: The pr obability that a r andomly chosen faculty member is a f emale and has PHD is 0.18 Similarly , Q2. What is the pr obability that a r andomly chosen faculty member is a male and has PHD? Using the formula of conditional pr obability , so, Adding v alues int o the equation Conclusion: The pr obability that a r andomly chosen faculty",
    "source": "lec3.pdf::chunk2"
  },
  {
    "text": "member is a male and has PHD is 0.28 Q3. What is the pr obability that a r andomly chosen faculty member has a PHD? We ha ve 2 appr oaches t o solv e this question.Example: 1îŒ“ ğ‘ƒ(ğ¹)=0.3 ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹)=0.6 ğ‘ƒ(ğ‘€)=0.7 ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€)=0.4 ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹)=ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹) ğ‘ƒ(ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹)=ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹) âˆ— ğ‘ƒ(ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹)=0.6âˆ—0.3=0.18 ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€)=ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ‘€) ğ‘ƒ(ğ‘€) ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ‘€)=ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€) âˆ— ğ‘ƒ(ğ‘€) ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ‘€)=0.4âˆ—0.7=0.28 Approach 1: Here, we need t o nd the pr obability that If I choose a r andom person, then he/she ha ve a PHD , no matter whether the person is M ALE or FEM ALE. i.e. We can add as it'll giv e me adding v alues int o the equation Approach 2: As we know , we can write as a because, Here comes the Law of t otal pr obability in pictur e For Male also, we can write as a Replacing these v alues in the equation, = Conclusion: The pr obability that a r andomly chosen faculty member has a PHD is 0.46 Q4. What is the pr obability that a r andomly",
    "source": "lec3.pdf::chunk3"
  },
  {
    "text": "chosen PHD holder is f emale? Here, we ar e alr eady giv en that the r andomly chosen person is PHD holder and we need t o nd the pr obability of this person being F emale. W e need t o nd: Using the formula of conditional pr obability: Replace the with , and with Final forumla will be: Conclusion: The pr obability that a r andomly chosen PHD holder is f emale is 0.39 Ther e is an alternativ e appr oach t o solv e this question, called tree based appr oach Let's solv e this question with tr ee based appr oach.ğ‘ƒ(ğ‘â„ğ‘‘) ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹)+ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ‘€) ğ‘ƒ(ğ‘â„ğ‘‘) ğ‘ƒ(ğ‘â„ğ‘‘)=ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹)+ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ‘€) ğ‘ƒ(ğ‘â„ğ‘‘)=0.18+0.28=0.46 ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹) âˆ— ğ‘ƒ(ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹)=ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹) ğ‘ƒ(ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ‘€) ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€) âˆ— ğ‘ƒ(ğ‘€) ğ‘ƒ(ğ‘â„ğ‘‘)=[ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹) âˆ— ğ‘ƒ(ğ¹)]+[ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€) âˆ— ğ‘ƒ(ğ‘€)] ğ‘ƒ(ğ‘â„ğ‘‘)=[0.6âˆ—0.3]+[0.4âˆ—0.7] ğ‘ƒ(ğ‘â„ğ‘‘)=0.46 ğ‘ƒ(ğ¹ | ğ‘â„ğ‘‘) ğ‘ƒ(ğ¹ | ğ‘â„ğ‘‘)=ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘) ğ‘ƒ(ğ‘â„ğ‘‘ âˆ© ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹) âˆ— ğ‘ƒ(ğ¹) ğ‘ƒ(ğ‘â„ğ‘‘) [ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹) âˆ— ğ‘ƒ(ğ¹)]+[ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€) âˆ— ğ‘ƒ(ğ‘€)] ğ‘ƒ(ğ¹ | ğ‘â„ğ‘‘)=ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹) âˆ— ğ‘ƒ(ğ¹) [ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹) âˆ— ğ‘ƒ(ğ¹)] + [ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€) âˆ— ğ‘ƒ(ğ‘€)] ğ‘ƒ(ğ¹ | ğ‘â„ğ‘‘)=0.6âˆ—0.3",
    "source": "lec3.pdf::chunk4"
  },
  {
    "text": "[0.6âˆ—0.3]+[0.4âˆ—0.7] ğ‘ƒ(ğ¹ | ğ‘â„ğ‘‘)=0.39 Let's assume ther e are 100 faculty members. Now among these 100 faculty members, They can be divided int o two par ts, the y can be either male or f emale.Tree based appr oach: îŒ“ Explanation of the structur e of the Tree: Q1. How many of them ar e female and how many of them ar e Male? Female : 30% of 100 = 30 (as ) We can fur ther seggr egate the f emale par t into 2 par t: Female AND ha ving a PHD : 60% of 30 = 18 We can r epresent it as Female AND NO T having a PHD : 30 - 18 = 12 We can r epresent it as Same for the Male: Male : 70% of 100 = 70 (as ) Male AND ha ving a PHD : 40% of 70 = 28 We can r epresent it as Male AND NO T having a PHD : 70 - 28 = 42 We can r epresent it as The structur e of tr ee is r eady .ğ‘ƒ(ğ¹)=0.3 ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹)=0.6 ğ‘ƒ(ğ‘â„ | ğ¹)=1âˆ’ğ‘ƒ(ğ‘â„ğ‘‘ | ğ¹)=0.4 ğ‘‘â€² ğ‘ƒ(ğ‘€)=0.7 ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€)=0.4 ğ‘ƒ(ğ‘â„ |",
    "source": "lec3.pdf::chunk5"
  },
  {
    "text": "ğ‘€)=1âˆ’ğ‘ƒ(ğ‘â„ğ‘‘ | ğ‘€)=0.6 ğ‘‘â€² Now let' s solv e the questions Q1. What is the pr obability that a r andomly chosen faculty member is a f emale and has PHD? Let's see how we can easily solv e this using tr ee based appr oach We want faculty member and PHD From our tr ee diagr am, we can see that ther e are 18 faculty members who ar e Female and has PHD . So = 18/100 = 0.18 We can obser ve tha we ar e getting the same answer but how conviniently we ar e able t o solv e this pr oblem with this appr oach Q2. What is the pr obability that a r andomly chosen faculty member is a male and has PHD? Following the same appr oach as abo ve = 28/100 = 0.28 Q3. What is the pr obability that a r andomly chosen faculty member has a PHD? Here we want t o nd total number of faculties ha ving PHD , it doesn 't matter whether the member is male or f emale It will be (18 + 28)/100 = 0.46 Q4. What is the pr obability that a",
    "source": "lec3.pdf::chunk6"
  },
  {
    "text": "r andomly chosen PHD holder is f emale ? We ha ve 2 wa ys to reach the PHD , one thr ough FEM ALE and one thr ough M ALE Now , we need the member who alr eady has PHD but is a f emale . It'll be = 0.39 Q5. What is the pr obability that a r andomly chosen PHD holder is male? Following the same appr oach as abo ve = = 0.6 We can see how conviniently and easily we ar e able t o solv e all the questions using this Tree based appr oachğ‘ƒ(ğ¹âˆ©ğ‘â„ğ‘‘) ğ‘ƒ(ğ‘€âˆ©ğ‘â„ğ‘‘) 18 18+28 ğ‘ƒ(ğ‘€ | ğ‘â„ğ‘‘)28 18+28 The dataset contains the monthly r ainfall data fr om y ears 1901 t o 2018 for the Indian state of K erala. It contains the monthly r ainfall index of K erela and also r ecor d weather a ood t ook place that month or not.Kerala Flood Case StudyîŒ“ !wget --no-check-certificate https://drive.google.c om/uc?id= 1Mp2bQl5QJ6O2tcezb0ceBQIn8vW5us0N -O kerala.csv --2024-01-31 14:29:12-- https://drive.google.com/uc?id=1Mp2bQl5QJ6O2tcezb0ceBQIn8vW5us0N Resolving drive.google.com (drive.google.com)... 142.251.162.102, 142.251.162.113, 142.251.162.101, ... Connecting to drive.google.com (drive.google.com)|142.251.162.102|:443... connected. HTTP request sent, awaiting response... 303 See Other Location: https://drive.usercontent.google.com/download?id=1Mp2bQl5QJ6O2tcezb0ceBQIn8vW5us0N [following] --2024-01-31 14:29:12-- https://drive.usercontent.google.com/download?id=1Mp2bQl5QJ6O2tcezb0ceBQIn8vW5us0N Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.193.132,",
    "source": "lec3.pdf::chunk7"
  },
  {
    "text": "2607:f8b0:400c:c03::84 Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.193.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 10300 (10K) [application/octet-stream] Saving to: 'kerala.csv' kerala.csv 100%[===================>] 10.06K --.-KB/s in 0s 2024-01-31 14:29:12 (34.0 MB/s) - 'kerala.csv' saved [10300/10300] # Import libraries import numpy as np import pandas as pd SUBDIVISION YEARJANFEBMARAPRMAYJUNJULAUGSEPOCT 0 KERALA 1901 28.7 44.7 51.6 160.0 174.7 824.6 743.0 357.5 197.7 266.9 1 KERALA 1902 6.7 2.6 57.3 83.9 134.5 390.9 1205.0 315.8 491.6 358.4 2 KERALA 1903 3.2 18.6 3.1 83.6 249.7 558.6 1022.5 420.2 341.8 354.1 3 KERALA 1904 23.7 3.0 32.2 71.5 235.7 1098.2 725.5 351.8 222.7 328.1 4 KERALA 1905 1.2 22.3 9.4 105.9 263.3 850.2 520.5 293.6 217.2 383.5 5 KERALA 1906 26.7 7.4 9.9 59.4 160.8 414.9 954.2 442.8 131.2 251.7 6 KERALA 1907 18.8 4.8 55.7 170.8 101.4 770.9 760.4 981.5 225.0 309.7 7 KERALA 1908 8.0 20.8 38.2 102.9 142.6 592.6 902.2 352.9 175.9 253.3 8 KERALA 1909 54.1 1 1.8 61.3 93.8 473.2 704.7 782.3 258.0 195.4 212.1 9 KERALA 1910 2.7 25.7 23.3 124.5 148.8 680.0 484.1 473.8 248.6 356.6# Read the data df = pd.read_csv( \"kerala.csv\" ) df.head( 10) df.shape (118, 16) Let's calculate a verage r ainfall for each month",
    "source": "lec3.pdf::chunk8"
  },
  {
    "text": "o ver the y ears Q. What is the a verage r ainfall for each month o ver the y ears # Calculate the average rainfall for each month cols = [ 'JAN', 'FEB', 'MAR', 'APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'] monthly_avg = df[cols].mean() monthly_avg JAN 12.218644 FEB 15.633898 MAR 36.670339 APR 110.330508 MAY 228.644915 JUN 651.617797 JUL 698.220339 AUG 430.369492 SEP 246.207627 OCT 293.207627 NOV 162.311017 DEC 40.009322 dtype: float64 Let's visualise this data: import matplotlib.pyplot as plt import seaborn as sns x=monthly_avg.index y=monthly_avg plt.bar(x,y) <BarContainer object of 12 artists> We can mak e few conclusions here: The data r eveals signicant seasonal v ariation in r ainfall. June and July have the highest a verage r ainfall , while Januar y and F ebruar y are the driest months The r ainfall in August and September is still r elativ ely high but begins t o decline Surprisingly , October has a higher a verage r ainfall than September , which ma y seem counterintuitiv e. Ther e are two monsoon seasons in K erala, one during Jun-A ug, Other during Oct . the impor tant f eatur es in this dataset ar e \"JUN\", \"JUL \", \"OC T\" , \" ANN AUL_RAINF",
    "source": "lec3.pdf::chunk9"
  },
  {
    "text": "ALL\", \"FL OODS\" because in these months only we ha ve seen the peak of the r ainfall which can be one of the major sour ce of causing the ood As y ou can see ther e is an extr a space in the star t of column \" Annual r ainfall\". It is lik e this: ' ANNU AL RAINF ALL' Let's rename this column SUBDIVISION YEARJANFEBMARAPRMAYJUNJULAUGSEPOCT 0 KERALA 1901 28.7 44.7 51.6 160.0 174.7 824.6 743.0 357.5 197.7 266.9 1 KERALA 1902 6.7 2.6 57.3 83.9 134.5 390.9 1205.0 315.8 491.6 358.4 2 KERALA 1903 3.2 18.6 3.1 83.6 249.7 558.6 1022.5 420.2 341.8 354.1 3 KERALA 1904 23.7 3.0 32.2 71.5 235.7 1098.2 725.5 351.8 222.7 328.1 4 KERALA 1905 1.2 22.3 9.4 105.9 263.3 850.2 520.5 293.6 217.2 383.5df.columns = [c.replace( ' ANNUAL RAINFALL' , 'ANNUAL_RAINFALL' ) for c in df.columns] df.head() Impactful Columns df.columns Index(['SUBDIVISION', 'YEAR', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANNUAL_RAINFALL', 'FLOODS'], dtype='object') impactful_columns = [ 'YEAR', 'JUN', 'JUL', 'OCT', 'ANNUAL_RAINFALL' , 'FLOODS' ] impactful_columns ['YEAR', 'JUN', 'JUL', 'OCT', 'ANNUAL_RAINFALL', 'FLOODS'] Now , I want t o label the months column with 0 and 1 0:",
    "source": "lec3.pdf::chunk10"
  },
  {
    "text": "will r epresents low r ainfall 1: will r epresents hea vy rainfall Similarly for \" ANNU AL_RAINF ALL\" column: 0: will r epresents low r ainfall in that par ticular y ear 1: will r epresents hea vy rainfall in that par ticular y ear Q. But how much r ainfall index is consider ed as a hea vy ranifall? One of the par ameter is using the Median values of these columns. If their individual rainfall index v alue > median v alue then it'll we consider ed as heavy rainfall and vice a v ersa YEAR JUNJULOCTANNUAL_RAINFALL FLOODS 0 1901 824.6 743.0 266.9 3248.6 YES 1 1902 390.9 1205.0 358.4 3326.6 YES 2 1903 558.6 1022.5 354.1 3271.2 YES 3 1904 1098.2 725.5 328.1 3129.7 YES 4 1905 850.2 520.5 383.5 2741.6 NO# new dataset containing only impactful columns data = df[impactful_columns] data.head() # let's calculate the median of columns and set as their threshold value threshold_jun = data[ 'JUN'].median().astype( int) threshold_jul = data[ 'JUL'].median().astype( int) threshold_oct = data[ 'OCT'].median().astype( int) threshold_ar = data[ 'ANNUAL_RAINFALL' ].median().astype( int) threshold_jun, threshold_jul, threshold_oct, thres hold_ar (625, 691, 284, 2934) <ipython-input-21-ce625c741022>:10: SettingWithCopyWarning: A value is trying to be set on a",
    "source": "lec3.pdf::chunk11"
  },
  {
    "text": "copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/s data[col] = (data[col] > threshold).astype(int) YEARJUNJULOCTANNUAL_RAINFALL FLOODS 0 1901 1 1 0 1 YES 1 1902 0 1 1 1 YES 2 1903 0 1 1 1 YES 3 1904 1 1 1 1 YES 4 1905 1 0 1 0 NOthresholds = { 'JUN': 625, 'JUL': 691, 'OCT': 284, 'ANNUAL_RAINFALL' : 2934 } # Convert columns to binary based on thresholds for col, threshold in thresholds.items(): data[col] = (data[col] > threshold).astype( int) data.head() data['FLOODS' ].unique() array(['YES', 'NO'], dtype=object) Now our dataset is r eady , let's solv e some questions. Question Explanation : Let A r epresents : Flood B represents: hea vy rain in June We need t o calculate i.e. Q1. Calculate the Pr obability of ood giv en that r ainfall in June is gr eater than the median june r ainfall v alue (threshold for hea vy rainfall)îŒ“ ğ‘ƒ(ğ´|ğµ)ğ‘ƒ(ğ´âˆ©ğµ) ğ‘ƒ(ğµ) We can obtain these v alues using contingency table and put those v alues int o the formula. Here we need t o compar e \"FL OODS\" and \"JUN\" column.Solution A pproach 1: îŒ“ FLOODS",
    "source": "lec3.pdf::chunk12"
  },
  {
    "text": "NOYESTotal JUN 0 42 16 58 1 16 44 60 T otal 58 60 1 18pd.crosstab(data[ 'JUN'], data[ 'FLOODS' ], margins= True, margins_name= 'Total') Now , = Pr obability of Flood occuring AND hea vy rainfall in JUNE As we know in the contingency table, FL OODS = YES r epresents that ood has occur ed and JUN = 1 means hea vy rainfall. We need t o check v alue wher e FLOODS = YES and JUN = 1 which is 44 Then b y the formula of conditit onal pr obability we can f eed this datağ‘ƒ(ğ´âˆ©ğµ) # probability of high rainfall in June P(J) # P(J) = possible outcomes in june having heavy ra infall / total outcomes P_J = (16+44)/(42+16+16+44) # now, P(A and B) (Flood = YES and Jun = 1) P_F_and_J = 44/(42+16+16+44) #, so our probability of flood occurring given tha t the high rainfall occured in June will be P_F_J = P_F_and_J / P_J print(f'P(J) : {P_J}') print(f'P(F AND J) : {P_F_and_J} ') print(f'P(F|J): {P_F_J}') P(J) : 0.5084745762711864 P(F AND J) : 0.3728813559322034 P(F|J): 0.7333333333333334 Explanation of Normaliz e attribute: Rather putting all the v alues in the formula and then calculate",
    "source": "lec3.pdf::chunk13"
  },
  {
    "text": "the pr obability We can just pass one more attribute in pd.cr osstab() function which will divide all v alues b y the sum of v alues. This is the pr obability only , as in pr obability we divide possible outcome / total outcome (sum of all values) Parameter is : normaliz e = ' ' Without this attribute , the contingency table will show the r aw counts of occurr ences for each combination of v ariables. It will not be normaliz ed, and the v alues in the table will r epresent counts.Approach 2: using normaliz e attribute îŒ“ Here we can pass these strings in this attribute: normaliz e='index' or normaliz e='columns' : The normaliz e attribute species how the v alues in the contingency table should be normaliz ed. When set t o 'index' , it calculates conditional pr obabilities based on r ows, treating each r ow as a separ ate condition. When set t o 'columns' , it calculates conditional pr obabilities based on columns , treating each column as the condition we ar e focusing on. This means that each r ow in the table is divided b y the sum of",
    "source": "lec3.pdf::chunk14"
  },
  {
    "text": "its r ow, making each r ow's values sum up t o 1, r epresenting conditional probabilities. Same with the column In this case: By setting normaliz e='index' , the code calculates conditional pr obabilities within each r ow. Each v alue in the table r epresents the pr obability of the corr esponding e vent (FL OODS) giv en the v alue of 'JUN' in that r ow. The r ow sums up t o 1, ensuring that it r eects the conditional pr obabilities. In summar y, setting normaliz e='index' in pd.cr osstab allows y ou to calculate and visualiz e conditional pr obabilities based on the specied r ow v ariable ('JUN' in this case) , making it easier t o assess the impact of one v ariable on another . FLOODS NO YES JUN 0 0.724138 0.275862 1 0.266667 0.733333 All 0.491525 0.508475pd.crosstab(index = data[ 'JUN'], columns = data[ 'FLOODS' ], margins= True, normalize= 'index') The v alues in the table r epresent the conditional pr obabilities, wher e each cell contains the pr obability of the corr esponding outcome (FL OODS) given the condition in June (JUN). Then the pr obability of ood occurring giv",
    "source": "lec3.pdf::chunk15"
  },
  {
    "text": "en that the hea vy rainfall occur ed in June will be: In the cell at r ow 1, column 1, the v alue 0.73333 represents the conditional pr obability of ooding (FL OODS = YES) giv en that high r ainfall occurr ed in June (JUN = 1). So, there is 73.33% chance of Floods when there is a heavy rainfall in June As we can see b y calculating using formula also, we ar e getting the same answer as using dir ectly conditional pr obability using normaliz e = 'index' Now , let's jump int o the next questionConclusion: Q2. Giv en that ther e is a ooding, calculate the pr obability that hea vy rainfall has occurr ed in July (mor e than threshold v alue)?îŒ“ Here we want t o nd We are alr eady awar e of using formula based appr oach, so W e will solv e this using contingency tableğ‘ƒ(ğ½ğ‘¢ğ‘™ğ‘¦=1|ğ¹ğ‘™ğ‘œğ‘œğ‘‘=ğ‘Œğ¸ğ‘†) Befor e proceeding, Q. In this question, which string will be passed inside normaliz e=' ' attribute? 'index' or ' columns' In this question, we should normaliz e the contingency table along the columns As we want t o nd the conditional",
    "source": "lec3.pdf::chunk16"
  },
  {
    "text": "pr obability of high r ainfall in July (JUL = 1) giv en that ther e was ooding (FL OODS = YES) , We want t o see how the 'JUL ' column beha ves when ther e is ooding. Solution:îŒ“ FLOODS NOYESAll JUL 0 0.655172 0.35 0.5 1 0.344828 0.65 0.5pd.crosstab(index = data[ 'JUL'], columns = data[ 'FLOODS' ], margins= True, normalize= 'columns' ) The pr obability that high r ainfall occurr ed in July (JUL = 1) giv en ooding (FL OODS = YES) is 0.65 . This means that when ther e is ooding, ther e is a 65% chance of hea vy rainfall in July .Conclusion: Q3.Calculate the pr obability of ood giv en that june and july r ainfall was gr eater than their median r ainfall v alue? We want t o nd Here, we can pass multiple columns in the pd.cr osstab()Solution:îŒ“ ğ‘ƒ(ğ¹ğ‘™ğ‘œğ‘œğ‘‘=ğ‘Œğ‘’ğ‘ | ğ‘—ğ‘¢ğ‘›ğ‘’=1 ğ‘ğ‘›ğ‘‘ ğ½ğ‘¢ğ‘™=1) FLOODS NO YES JUN JUL 0 0 0.862069 0.137931 1 0.586207 0.413793 1 0 0.433333 0.566667 1 0.100000 0.900000 All 0.491525 0.508475pd.crosstab (index = [data['JUN'], data['JUL']], columns = data ['FLOODS' ], margins= True, normalize= 'index') Frequency (JUN = 1, JUL = 1, FL OODS = YES )",
    "source": "lec3.pdf::chunk17"
  },
  {
    "text": "= 0.9000000 Ther e is 90% chance of ood giv en that hea vy rainfall in both june and julyConclusionîŒ“",
    "source": "lec3.pdf::chunk18"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Combinat orics Permutations Permutation : Generic A pproach CombinationsContentîŒ“ Suppose we ha ve 2 True/F alse questions. In how many wa ys can the y be solv ed? For question 1, we ha ve two possible outcomes: True False Similarly , for question 2 as well. Since we need t o solv e both questions, will we add or multiply their number of possible outcomes? We will multiply since we ha ve to solv e question 1 AND 2 Instead, if we had t o solv e question 1 OR 2 , we would'v e added . This is because, when considering Event 1 AND Event 2, we ar e talking about two independent e vents . Solving question 1 is independent fr om solving question 2 Hence, we need t o multiply t o consider their combined eff ect. Ther efore, we can solv e them in ways: True, True True, F alse False, True False, F alse2âˆ—2=4 What is a permutation?Permutation and CombinationîŒ“ When talking about permutations, we mean arrangement of",
    "source": "lec4.pdf::chunk0"
  },
  {
    "text": "objects . Ther efore, as with arr anging objects, the most impor tant thing is order is which the y are arranged. This means that Formal Denition: A permutation is an arrangement of items or elements in a specific order, where the order of the arrangement matters. The second aspect is Combinations What is a combination? Combination is Selection of objects . Over her e, the or der of objects does not matter . This means that Formal Denition: A combination is selection of items or elements where the order of the arrangement does not matter.(ğ‘–,ğ‘—)â‰ (ğ‘—,ğ‘–) (ğ‘–,ğ‘—)=(ğ‘—,ğ‘–) Q1. How would we arr ange N object, giv en that ther e only 3 slots? Since ther e are 3 slots for N objects, the no. of wa ys in which we can arr ange them is Permutation : Generic F ormula îŒ“ ğ‘ğ‘ƒ3 i.e. =ğ‘.(ğ‘âˆ’1).(ğ‘âˆ’2)ğ‘ğ‘ƒ3 Q2. How would we arr ange N object, giv en that ther e only 4 slots? =ğ‘.(ğ‘âˆ’1).(ğ‘âˆ’2).(ğ‘âˆ’3)ğ‘ğ‘ƒ4 We can obser ve a pattern between the no. of slots/blanks, and the last term of the abo ve expr essions Q3. Then how would we arr ange N object, giv en that ther e are k slots a",
    "source": "lec4.pdf::chunk1"
  },
  {
    "text": "vailable? This can be found using: Let's re-write this equation b y multiplying and dividing b y same expr ession, as: As we know , we can write this in the form of fact orial as: =ğ‘(ğ‘âˆ’1)(ğ‘âˆ’2)(ğ‘âˆ’3)....(ğ‘âˆ’(ğ‘˜âˆ’1))=ğ‘(ğ‘âˆ’1)(ğ‘âˆ’2)(ğ‘âˆ’3)....(ğ‘ğ‘ƒğ‘˜ =ğ‘(ğ‘âˆ’1)(ğ‘âˆ’2)(ğ‘âˆ’3)....(ğ‘âˆ’(ğ‘˜âˆ’1))=ğ‘(ğ‘âˆ’1)(ğ‘âˆ’2)(ğ‘âˆ’3)....(ğ‘ğ‘ƒğ‘˜ =ğ‘ğ‘ƒğ‘˜ğ‘! (ğ‘âˆ’ğ‘˜)! CombinationsîŒ“ Combinations, in simple terms, ar e all the diff erent wa ys you can choose a cer tain number of items fr om a gr oup, wher e the or der in which y ou pick them doesn 't matter . It's like making a sandwich with diff erent ingr edients â€“ the combination is the unique mix of ingr edients y ou choose, r egar dless of the or der y ou add them. In the language of combinat orics, this number of wa ys of selecting is known as Combination . Similarly , we can write the gener al formula for combinations in terms of permutations as: We can fur ther expand it as: =ğ‘›ğ¶ğ‘˜ğ‘›ğ‘ƒğ‘˜ ğ‘˜! =ğ‘›ğ¶ğ‘˜ğ‘›! ğ‘˜!(ğ‘›âˆ’ğ‘˜)!",
    "source": "lec4.pdf::chunk2"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Descriptiv e Statistics Measur es of Centr al Tendency Mean Median Mode Measur es of V ariability Range Variance Standar d De viation Inferential Statistics Weighted A verage Inter Quar tile Range Quar tile Percentile Box Plot IQR implementation on r eal lif e dataset Random V ariables Discr ete R V Continuous R VContent Ther e are 2 types of Statistics: The wor d descriptiv e means \" DESCRIBE \" Descriptiv e statistics inv olve summarizing and pr esenting data in a meaningful wa y, providing a clear and concise o verview of a dataset.1. Descriptiv e Statistics îŒ“ Example: Let sa y you ar e driving a car and y ou look at y our dashboar d. The speedometer shows the speed of y our car at the moment is 65 km/hr . So, it is simply describing speed. This Speedometer simply describes an e vent that a v ehicle is mo ving at a cer tain speed so it is an example of descriptiv e statistics. Inferential statistics, on the",
    "source": "lec5.pdf::chunk0"
  },
  {
    "text": "other hand, inv olve making pr edictions, inf erences, or dr awing conclusions about a lar ger population based on a sample of data.2. Inf erential Statistics îŒ“ Continuing the example: The car 's speedometer displa ys the curr ent speed but doesn 't predict y our arriv al time because it depends on v arious fact ors lik e distance and tr ac. What Google Maps will do her e, is estimate arriv al time based on data and assumptions, but it' s only sometimes 100% accur ate. This pr ediction is an example of inf erential statistics, as it dr aws conclusions fr om r eal-world scenarios It is tr ying t o \"infer\" something. It is concluding out of it. So, it is inf erential statistics. Conclusion: Descriptiv e statistics summariz es data Inferential statistics draws conclusions based on the obser vations. These two ar e the essential br anches of statistics. Let's explor e descriptiv e statistics In statistics, we often use measur es to understand and describe a set of data. Three common measur es ar e: 1. Mean The Mean is the a verage of all data points 2. Median The Median is the",
    "source": "lec5.pdf::chunk1"
  },
  {
    "text": "middle v alue when the data is sor ted. 3. Mode It is the obser vation with the highest fr equencyMeasur es of Centr al Tendency îŒ“ Suppose we are looking for a data scientist job at FAANG. The sample of salaries is taken and recorded as [30L, 30L, 35L, 40L, 40L]. What will be the salary we would be expecting?Example-1: Data Scientist' s Salaries Approach: Mean will be (30 + 30 + 35 + 40 + 40)/5 = 35 lakhs Wher e, = population mean = sum of each v alue in the population = number of v alues in the population So, the mean salar y in this sample is 35 lakhs. W e might negotiate our expected salar y around this gur e.1) MeanîŒ“ Î¼=âˆ‘ğ‘‹ ğ‘ Î¼ âˆ‘ğ‘‹ ğ‘ Suppose, a new candidate comes in the context and his salar y is 3 cr ores. New mean will become = (30 + 30 + 35 + 40 + 40 + 300)/6 = 79 lakhs The mean salar y dramatically incr eased to 79 lakhs because of the new candidate 's exceptionally high salar y. We can obser ve that this new candidate is an outlier in the",
    "source": "lec5.pdf::chunk2"
  },
  {
    "text": "data which is aff ecting the mean v alue. 2) Median Here comes the concept of \"Median \" to measur e centr al tendency instead of measuring it using Mean . Befor e the new candidate joined, the Median was 35L . This means that 35L was the center v alue when the salaries wer e sor ted in ascending order: Original Salaries: [30L, 30L, 35L, 40L, 40L] Sorted: [30L, 30L, 35L, 40L, 40L] Median = (the middle v alue) After the new candidate with a signicantly higher salar y arriv ed (300L), the new Median became 37.5 lakhs: New Salaries : [30L, 30L, 35L, 40L, 40L, 300L] Sorted: [30L, 30L, 35L, 40L, 40L, 300L] New Median = (35L + 40L) / 2 = 75L / 2 = . Formula: The median would be: obser vation 's value For the even number of obser vations the median would be: So, it would be suitable t o negotiate at 37.5 lakhs. Ther e is a huge diff erence in the new mean and new median . Conclusion: The outliers dr amatically aff ect the Mean but the Median r emains mor e robust and closer t o the typical v alue",
    "source": "lec5.pdf::chunk3"
  },
  {
    "text": "of the dataset. Which concludes that Median is mor e robust t o outliers35ğ¿ 37.5ğ¿ ( )ğ‘¡â„ğ‘›+1 2 ()ğ‘¡â„ğ‘œğ‘ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›+(+1)ğ‘¡â„ğ‘œğ‘ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘› 2ğ‘› 2 2 It is the obser vation with the highest fr equency . It is most occurring data point in the dataset. Suppose the data points ar e recor ded as - [90, 90, 90, 80, 90, 70, 95, 90] The mode will be 90. Remember , sometimes if ther e are no data points that r epeat, then we can implies that ther e is no mode Ther e can also be more than one mode in the dataset. Suppose the data points ar e recor ded as - [2, 2, 3, 3, 4] We can call this Bi-modal with 2 and 3 as the modes3) Mode In W eighted A verage, each data point is assigned a weight that r epresents its impor tance or relevance. We multiply each data point b y its corr esponding weight , sum these pr oducts , and then divide b y the t otal weight .Weighted A verage: Reecting Impor tance îŒ“ In real lif e, a common application of weighted a verage is calculating Gr ade P oint A verage",
    "source": "lec5.pdf::chunk4"
  },
  {
    "text": "(GP A) for students. Consider a student' s course list for a semester:Example: Calculating GP A îŒ“ To calculate the GP A: 1. Calculate the weighted scor e for each course b y multiplying the cr edit b y the numerical gr ade. 2. Sum up all the weighted scor es. 3. Divide the t otal weighted scor e by the t otal cr edits. Weighted A verage will be: For Math: For Hist ory: For Chemistr y: For English: Conclusion : So, the student' s GP A for this semester is 3.053(ğ¶ğ‘…ğ¸ğ·ğ¼ğ‘‡)âˆ—5(ğºğ‘…ğ´ğ·ğ¸)=15 4âˆ—4=16 3âˆ—5=15 2âˆ—3=6 ğºğ‘ƒğ´=ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘Šğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘’ğ‘‘ ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ¶ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘¡ğ‘  = =3.0552 17 Three common measur es of v ariability ar e 1. Range 2. Variance 3. Standar d De viationMeasur es of V ariability îŒ“ Let's discuss Range Range is nothing but Maximum v alue - Minimum v alue Suppose the Salaries of some emplo yees in a company ar e : [30, 30, 35, 40, 40] Here, the r ange of the salar y will be 40-30 = 10 It describes the o verall spr ead of the data that the diff erence between maximum and minimum v alues is 10.RangeîŒ“ Q1. What will happen if ther",
    "source": "lec5.pdf::chunk5"
  },
  {
    "text": "e is an \"Outlier \" in the data? Let the salaries be: [30, 30, 35, 40, 40, 300] New r ange will be 300 - 30 = 270 As we can see one outlier can destr oy the r ange of the dataset. We can conclude that Range of the data is also not r obust t o the outliers lik e the Mean To solv e this issue, statisticians came up with the metric called \" Inter Quar tile Range \". IQR is the metric that pr ovides a r obust wa y to measur e the spr ead of a dataset. The IQR is the r ange between the rst quar tile (Q1) and the thir d quar tile (Q3) of a dataset. Means, What is Quar tiles?Inter Quar tile RangeîŒ“ ğ¼ğ‘„ğ‘…=ğ‘„3âˆ’ğ‘„1 It is the v alue which divides the dataset int o four equal par ts. Ther e are thr ee quar tiles, Q1, Q2, and Q3 . Q1 represents the 25th per centile , meaning that 25% of the data falls below this v alue. Q2 is the median and r epresents the 50th per centile , dividing the data int o two equal halv es.",
    "source": "lec5.pdf::chunk6"
  },
  {
    "text": "Q3 represents the 75th per centile , meaning that 75% of the data falls below this v alue.Quar tilesîŒ“ Suppose we ha ve this data with us, What each v alues ar e representing her e? 0.25 r epresents Q1 or 25th per centile: It means that 0.25% of people ar e shor ter than this lady 0.5 r epresents Q2 or 50th per centile: It means that 0.5% or half of the people in the dataset ar e shor ter than this guy 0.75 r epresents Q3 or 75th P ercentile: It means that 0.75% of people ar e shor ter than this guy Maximum or 1: It means that 100% of people ar e shor ter than this lady or she is the tallest person in the dataset. Q.What is per centile? A value that tells us that some \"p%\" obser vations ar e less than that v alue Let's say the v alue occurring at 50 P ercentile is 68. W e can conclude that 50% of the data is less than 68 One mor e example: Suppose y ou scor ed 99 per centile in y our 10th boar ds, what does this mean? It indicates",
    "source": "lec5.pdf::chunk7"
  },
  {
    "text": "that 99% of students scor ed less marks than y ou.Percentile The gr aphical r epresentation of a dataset' s summar y statistics, including the median, quar tiles, and potential outliers. Bo x plot comes int o the pictur e It provides a visual wa y to understand the distribution and spr ead of data. Box: The bo x itself r epresents the inter quar tile r ange (IQR), It is divided int o two par ts, the lower (bott om) quar tile (Q1) and the upper (t op) quar tile (Q3). The length of the bo x is determined b y the r ange between Q1 and Q3. Line (Median): Inside the bo x, a line or bar is dr awn that r epresents the median, which is the middle v alue of the dataset when it' s ordered. Whisk ers: Two lines, or \" whisk ers,\" extend fr om the bo x in both dir ections. The V alue of Lower whisk ers is determined b y Q1 - 1.5(IQR). It is the minimum v alue of the r ange The V alue of Upper whisk ers is determined b y Q3 + 1.5(IQR). It is the maximum",
    "source": "lec5.pdf::chunk8"
  },
  {
    "text": "v alue of the r ange Outliers: Data points that fall outside the whisk ers ar e consider ed outliers.Box PlotîŒ“ Example We ha ve a sor ted data, the bo x plot of the data will look lik e this Variance, measur es the spr ead or dispersion of the v alues of a r andom v ariable ar ound its mean. It quanties how much individual v alues de viate fr om the mean . A higher v ariance indicates that the values ar e mor e spr ead out fr om the mean . While a lower v ariance suggests that the values ar e closer t o the mean . We can plot the hist ogram t o visualise the spr ead or distribution of the dataVarianceîŒ“ import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt !wget --no-check-certificate https://drive.google.c om/uc?id= 1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo -O weight-height. csv --2024-01-18 09:39:16-- https://drive.google.com/uc?id=1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo Resolving drive.google.com (drive.google.com)... 172.253.123.100, 172.253.123.101, 172.253.123.138, ... Connecting to drive.google.com (drive.google.com)|172.253.123.100|:443... connected. HTTP request sent, awaiting response... 303 See Other Location: https://drive.usercontent.google.com/download?id=1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo [following] --2024-01-18 09:39:16-- https://drive.usercontent.google.com/download?id=1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.196.132, 2607:f8b0:400c:c36::84 Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.196.132|:443... connected. HTTP request sent, awaiting response... 200",
    "source": "lec5.pdf::chunk9"
  },
  {
    "text": "OK Length: 428120 (418K) [application/octet-stream] Saving to: 'weight-height.csv' weight-height.csv 100%[===================>] 418.09K --.-KB/s in 0.004s 2024-01-18 09:39:16 (91.3 MB/s) - 'weight-height.csv' saved [428120/428120] df_hw = pd.read_csv( \"weight-height.csv\" ) Gender Height Weight 0 Male 73.847017 241.893563 1 Male 68.781904 162.310473 2 Male 74.1 10105 212.740856 3 Male 71.730978 220.042470 4 Male 69.881796 206.349801df_hw.head() Height Weight count 10000.000000 10000.000000 mean 66.367560 161.440357 std 3.847528 32.108439 min 54.263133 64.700127 25% 63.505620 135.818051 50% 66.318070 161.212928 75% 69.174262 187.169525 max 78.998742 269.989699df_hw.describe() We will going t o work on the single column for now df_height = df_hw[ \"Height\" ] df_height.head() 0 73.847017 1 68.781904 2 74.110105 3 71.730978 4 69.881796 Name: Height, dtype: float64 sns.histplot(df_height) <Axes: xlabel='Height', ylabel='Count'> Let's explor e another wa y to measur e err or Dening Err or: Q1. Now , to minimiz e this err or, what' s the best appr oach? In our Height Guessing Game, we 've seen that aiming for the mean ( Î¼ ) height is the k ey. Means, Guessed height should be the mean v alue. (guessing for 1 time) It is also known as Mean Squar ed Err or Imagine we 're pla ying the game 10 times, guessing the mean height each",
    "source": "lec5.pdf::chunk10"
  },
  {
    "text": "time: Error1 = Error2 = Error3 = ... Error10 = To nd the o verall err or, we can sum up these individual err ors and then divide b y the number of guesses, which giv es us the v ariance: Variance Calculation: Variance = (Err or1 + Err or2 + Err or3 + ... + Err or10) / 10 Q2. So, if the v ariance is low , what does that mean? It implies that most of our guesses ar e incr edibly accur ate. In gener al, variance quanties how spr ead out, the data v alues ar e from the a verage (mean) v alue. It assesses the a verage squar ed diff erence between data points and the mean. The formula for calculating v ariance for n data points is:ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ=(ğ´ğ‘ğ‘¡ğ‘¢ğ‘ğ‘™ ğ»ğ‘’ğ‘–ğ‘”â„ğ‘¡âˆ’ğºğ‘¢ğ‘’ğ‘ ğ‘ ğ‘’ğ‘‘ ğ»ğ‘’ğ‘–ğ‘”â„ğ‘¡)2 ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ=(âˆ’Î¼ ğ»1 )2 (ğ»1âˆ’Î¼)2 (ğ»2âˆ’Î¼)2 (ğ»3âˆ’Î¼)2 (ğ»10âˆ’Î¼)2 ğ‘‰ğ‘ğ‘Ÿğ‘–ğ‘ğ‘›ğ‘ğ‘’=(âˆ’Î¼+(âˆ’Î¼+(âˆ’Î¼+.....+(âˆ’Î¼) ğ»1 )2ğ»2 )2ğ»3 )2ğ»10 102 = Ïƒ2 is the population v ariance. is the ith data point. Âµ is the population mean. n is the number of data points in the population.Variance Calculation F ormula:îŒ“ ğ‘£ğ‘ğ‘Ÿğ‘–ğ‘ğ‘›ğ‘ğ‘’ =ğœ2(âˆ’ğœ‡âˆ‘ ğ‘–=1ğ‘› ğ»ğ‘– )2 ğ‘› ğ»ğ‘– Now that we ha ve a clear understanding of v ariance and how it",
    "source": "lec5.pdf::chunk11"
  },
  {
    "text": "measur es the spr ead or dispersion of data points, Let's look int o another essential concept closely r elated t o variance. It' s called \" Standar d De viation \" Let's intr oduce an e ven mor e practical and commonly used statistic - the \"Standar d De viation. \" While v ariance quanties the dispersion of data, standar d de viation is deriv ed fr om v ariance and off ers a mor e interpr etable measur e. The standar d de viation r epresents how much individual data points de viate fr om the mean or a verage v alue . It giv es us a clear sense of the typical or expected amount of v ariation in our dataset. In simple wor ds, it r epresents that how far is our data point fr om the mean ( Î¼ ) Standar d De viation F ormula: The standar d de viation, can be calculated b y taking the squar e root of the v ariance:Standar d De viation îŒ“ ğ‘†ğ·=ğ‘£ğ‘ğ‘Ÿğ‘–ğ‘ğ‘›ğ‘ğ‘’ â€¾ â€¾ â€¾â€¾â€¾â€¾â€¾â€¾ âˆš Interpr etation: A lower standar d de viation signies that data points tend t o be close t o the mean",
    "source": "lec5.pdf::chunk12"
  },
  {
    "text": ", indicating less v ariability . Conv ersely , a higher standar d de viation indicates gr eater data dispersion , suggesting more variability within the dataset. IQR implementation on a r eal-lif e dataset îŒ“ When we talk about these two pla yers: 1. Sehwag 2. Rahul Dr avid We all know that Sehwag has aggr essiv e batting style While Rahul Dr avid plays patiently , with no risk and stands on the cr ease lik e a \"W all\" Let's analyse both of their matches and tr y to nd some insights about their r ange of scor es.Problem Statement : îŒ“ We will use IQR her e to calculate the r ange of their scor es accur ately and will also tr y to nd if the y have any \"Outlier \" scor es in their careers. We will conclude that out of these two batsman, who is the mor e consistent batsman?. Let's star t with Sehwag' s matches import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt !wget --no-check-certificate https://drive.google.c om/uc?id= 1JYyGv7QSb_GkVGan5rnHNrtOg2ewJB_f -O sehwag.csv --2024-01-18 09:39:17-- https://drive.google.com/uc?id=1JYyGv7QSb_GkVGan5rnHNrtOg2ewJB_f Resolving drive.google.com (drive.google.com)... 172.253.123.100, 172.253.123.101, 172.253.123.138, ... Connecting to drive.google.com",
    "source": "lec5.pdf::chunk13"
  },
  {
    "text": "(drive.google.com)|172.253.123.100|:443... connected. HTTP request sent, awaiting response... 303 See Other Location: https://drive.usercontent.google.com/download?id=1JYyGv7QSb_GkVGan5rnHNrtOg2ewJB_f [following] --2024-01-18 09:39:17-- https://drive.usercontent.google.com/download?id=1JYyGv7QSb_GkVGan5rnHNrtOg2ewJB_f Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.196.132, 2607:f8b0:400c:c36::84 Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.196.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 18584 (18K) [application/octet-stream] Saving to: 'sehwag.csv' sehwag.csv 100%[===================>] 18.15K --.-KB/s in 0s 2024-01-18 09:39:18 (73.8 MB/s) - 'sehwag.csv' saved [18584/18584] RunsMinsBF4s6sSRPosDismissal InnsUnnamed: 9 Opposition Ground Start Date Unnamed: 13 0 1 5 2 0 0 50.00 7 lbw 1 NaN v Pakistan Mohali 1 Apr 1999 ODI # 1427 1 19 18 24 0 1 79.16 6 caught 1 NaN v Zimbabwe Rajkot 14 Dec 2000 ODI # 1660 2 58 62 54 8 0107.40 6 bowled 1 NaN v Australia Bengaluru 25 Mar 2001 ODI # 1696 3 2 7 7 0 0 28.57 6 caught 2 NaN v Zimbabwe Bulawayo 27 Jun 2001 ODI # 1730 4 11 19 16 1 0 68.75 6 not out 2 NaN v West Indies Bulawayo 30 Jun 2001 ODI # 1731sehwag = pd.read_csv( \"sehwag.csv\" ) sehwag.head() sehwag[\"Runs\"].describe() count 245.000000 mean 33.767347 std 34.809419 min 0.000000 25% 8.000000 50% 23.000000 75% 46.000000 max 219.000000 Name: Runs, dtype: float64 We want t o nd the r ange of his",
    "source": "lec5.pdf::chunk14"
  },
  {
    "text": "scor es Let's nd Quar tiles rst on the \"Runs\" column. So Q1, Q2 and Q3 will be # 25th percentile or Q1 p_25 = np.percentile(sehwag[ \"Runs\"], 25) p_25 8.0 This v alue indicates that 25% of all the v alues pr esent in the dataset for Sehwag' s run is less than 8 We can also sa y, Out of all the matches that Shewag pla yed, in 25% of those matches, he scor ed less than 8 runs. #50th percentile or Q2, also \"Median\" p_50 = np.percentile(sehwag[ \"Runs\"], 50) p_50 23.0 This indicates that in 50% of the matches, he scor ed less than 23 runs #75th percentile or Q3 p_75 = np.percentile(sehwag[ \"Runs\"], 75) p_75 46.0 This indicates that in 75% of the matches, he scor ed less than 46 runs So, IQR will be? We know IQR = Q3 - Q1 # Inter Quartile Range iqr_sehwag = p_75 - p_25 iqr_sehwag 38.0 normal_range = (sehwag[ \"Runs\"].max() - sehwag[ \"Runs\"].min()) normal_range 219 We can obser ve the diff erence her e, IQR is 38 which means that middle 50% of the data lies in the r ange of 38. So mor e than 50% of the time,",
    "source": "lec5.pdf::chunk15"
  },
  {
    "text": "Sehwag scor es in the r ange of 38 runs On the other hand, the normal r ange is v ery high i.e. 219 which is cer tainly not a good r ange t o consider . We can obser ve one thing that there in an Outlier pr esent in the data means in some matches he has scor ed so many runs lik e mor e than 300 in a single match This is why the r ange is getting aff ected b y the outlier Let's plot the bo x plot t o visualise the spr ead of the data <Axes: xlabel='Runs'> sns.boxplot(data=sehwag[ \"Runs\"], orient= \"h\") We can see that Q1, Q2, and Q3 v alues lie within the bo x and we can also see whisk ers on both the sides of bo x which is the limit. We alr eady saw how t o calculate the lower whisk er and upper whisk er All the v alues outside the limit ar e consider ed \"Outlier \" # upper limit = Q3 + 1.5 * IQR upper = 46 + 1.5*(iqr_sehwag) upper 103.0 Here, we cannot ha ve values on the left side of the lower",
    "source": "lec5.pdf::chunk16"
  },
  {
    "text": "whisk er as the batsman cannot scor e less than 0 runs. So all the outliers will be pr esent on the right side of the upper whisk er # all the values greater than upper is outlier outliers_sehwag = sehwag[sehwag[ \"Runs\"]>upper] len(outliers_sehwag) 14 14/245 0.05714285714285714 Conclusion : Here we can obser ve that 5.7% v alues fr om the dataset ar e outliers . This means we can conclude that 5.7 or ~6% times Sehwag has scor ed mor e than the IQR which is 38 runs Now let' s have a same pr ocess int o Dravid's stats Crick et - Dr avid !wget --no-check-certificate https://drive.google.c om/uc?id= 1nrKmOYQNiTqFhMIoAwE00ULKhGhMEVMZ -O dravid.csv --2024-01-18 09:39:18-- https://drive.google.com/uc?id=1nrKmOYQNiTqFhMIoAwE00ULKhGhMEVMZ Resolving drive.google.com (drive.google.com)... 172.253.123.100, 172.253.123.101, 172.253.123.138, ... Connecting to drive.google.com (drive.google.com)|172.253.123.100|:443... connected. HTTP request sent, awaiting response... 303 See Other Location: https://drive.usercontent.google.com/download?id=1nrKmOYQNiTqFhMIoAwE00ULKhGhMEVMZ [following] --2024-01-18 09:39:18-- https://drive.usercontent.google.com/download?id=1nrKmOYQNiTqFhMIoAwE00ULKhGhMEVMZ Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.196.132, 2607:f8b0:400c:c36::84 Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.196.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 24177 (24K) [application/octet-stream] Saving to: 'dravid.csv' dravid.csv 100%[===================>] 23.61K --.-KB/s in 0s 2024-01-18 09:39:19 (106 MB/s) - 'dravid.csv' saved [24177/24177] dravid = pd.read_csv( \"dravid.csv\" ) dravid[\"Runs\"].describe() count 318.000000 mean 34.242138 std 29.681822 min 0.000000 25% 10.000000 50% 26.000000 75% 54.000000 max",
    "source": "lec5.pdf::chunk17"
  },
  {
    "text": "153.000000 Name: Runs, dtype: float64 #25th percentile or Q1 per_25 = np.percentile(dravid[ \"Runs\"], 25) per_25 10.0 This indicates that in 25% of the matches, he scor ed less than 10 runs #50th percentile or Q2 , also \"Median\" per_50 = np.percentile(dravid[ \"Runs\"], 50) per_50 26.0 This indicates that in 50% of the matches, he scor ed less than 26 runs #75th percentile or Q3 per_75 = np.percentile(dravid[ \"Runs\"], 75) per_75 54.0 This indicates that in 75% of the matches, he scor ed less than 54 runs # Inter Quartile Range iqr_dravid = per_75 - per_25 iqr_dravid 44.0 normal_range = (dravid[ \"Runs\"].max() - dravid[ \"Runs\"].min()) normal_range 153 <Axes: xlabel='Runs'> sns.boxplot(data=dravid[ \"Runs\"], orient= \"h\") # upper limit = Q3 + 1.5 * IQR upper_dravid = per_75 + 1.5*(iqr_dravid) upper_dravid 120.0 # all the values greater than upper is outlier outliers_dravid = dravid[dravid[ \"Runs\"]>upper_dravid] len(outliers_dravid)/ len(dravid) 0.009433962264150943 outliers_dravid[ 'Runs'].shape (3,) dravid.shape (318, 14) Here we can obser ve that 0.9% v alues fr om the dataset ar e outliers . This means we can conclude that 0.9% times Dr avid has scor ed mor e than the IQR which is 44 runs So we can conclude that in Sehwag case ther e is",
    "source": "lec5.pdf::chunk18"
  },
  {
    "text": "6% outliers and in Dr avid's case ther e are only 0.9% outliers which shows that \" Dravid was mor e consistent than Sehwag \" Now let' s calculate the standar d de viation thr ough which we can measur e the amount of v ariation or dispersion in runs scor ed b y Sachin and Dravid.ConclusionîŒ“ std_dev_sehwag = np.std(sehwag[ \"Runs\"]) print(\"The amount of variations in runs scored by sehwag is:\",std_dev_sehwag) The amount of variations in runs scored by sehwag is: 34.73830672594385 std_dev_dravid = np.std(dravid[ \"Runs\"]) print(\"The amount of variations in runs scored by dravid is:\",std_dev_dravid) The amount of variations in runs scored by dravid is: 29.635116182506632 Lower standar d de viation indicates less v ariability in the batsman 's per formance. For Sehwag: Standar d De viation of Runs: 34.74. For Dr avid: Standar d De viation of Runs: 29.64 Conclusion: Dravid has a lower standar d de viation compar ed to Sehwag. This suggests that Dravid's run scor es ar e mor e consistent or less v ariable than Sehwag' s. In other wor ds, Dr avid tends t o ha ve a mor e stable per formance in terms of runs compar ed to Sehwag, who shows",
    "source": "lec5.pdf::chunk19"
  },
  {
    "text": "mor e variability in his run scor es. So, fr om both IQR method and measuring Standar d De viation we can conclude that Dravid is mor e consitent then Sehwag Random V ariable (R V): îŒ“ A random v ariable is a situation/e vent/experiment, for which we ar e not cer tain about the outcome. It is a wa y to assign numbers t o the outcomes of such e vents. They can fur ther be divided int o 2 types: Discr ete Random V ariable Continuous Random V ariable Here, we can count the number of possible outcomes.Examples of Discr ete Random V ariable îŒ“ 1. Coin Toss Let's consider a coin t oss. What ar e its possible outcomes? Heads and Tails. Ther e is no other possible other than this. Hence, we can r epresent its outcomes as a r andom v ariable, that can tak e values: {ğ»,ğ‘‡} 2. Throw of a dice Let's assign a r andom v ariable, \"X, \" to represent the outcome of the die r oll. So, a thr ow of dice can be r epresented as: , depending on the outcome of the r oll. It can not ha",
    "source": "lec5.pdf::chunk20"
  },
  {
    "text": "ve an outcome lesser than 1, or gr eater than 6 Or even, any decimal v alue between 1 and 2 Hence it is also discr ete R Vğ‘‹={1,2,3,4,5,6} Here, we cannot count the number of possible outcomes. They are innite.Examples of Continuous Random V ariable îŒ“ 1. Height of students in a class Suppose the lowest student height in the class is: 4.5 f eet Suppose the highest student height is: 5.9 f eet Now , we can ha ve students that ha ve height as 4.511 f eet 4.92 f eet 5.8555 f eet So, we ha ve an innite number of possible height v alues between 4.5 and 5.9 f eet. W e cannot count them Wher eas, we could count the number of possibilities in a coin t oss or dice thr ow. Other examples of Continuous R V can be: Temper ature of a r oom Time tak en to complete a task Distance tr avelled ...etc",
    "source": "lec5.pdf::chunk21"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Empirical vs Theor etical Pr obability Expectations Binomial Distribution Bernoulli DistributionContent Probability Density F unction (PDF) : The PDF is a function that describes the pr obability density of a continuous r andom v ariable o ver its r ange. The term \" density \" her e is similar t o how tightly data is pack ed ar ound a specic point, lik e cars on a r oad. Probability Mass F unction (PMF) : The PMF is a function that describes the pr obability of a discr ete r andom v ariable taking on a specic v alue. Cumulativ e Distribution F unction (CDF) : The CDF is a function that giv es the pr obability that a r andom v ariable is less than or equal t o a specied v alue.Distribution F unctions îŒ“ Let's implement this using a height dataset We will going t o work on the height datafr ame that we saw abo ve for now df_height = df_hw[ \"Height\" ] df_height.head() 0 73.847017 1 68.781904 2",
    "source": "lec6.pdf::chunk0"
  },
  {
    "text": "74.110105 3 71.730978 4 69.881796 Name: Height, dtype: float64 # minimum height min_height = df_height. min() min_height 54.2631333250971 # maximum height max_height = df_height. max() max_height 78.9987423463896 total = len(df_height) total 10000 To plot this type of distribution we gener ally use Hist ograms or Distribution plots It is a gr aphical r epresentation of a dataset' s distribution, showing the fr equency or pr obability of diff erent v alues within the data.Histogram îŒ“ sns.displot(df_height) <seaborn.axisgrid.FacetGrid at 0x7ed0633c3670> Q.What we can understand fr om this distribution? Each bar in the hist ogram r epresents one of the inter vals or r anges, The height of the bar indicates the fr equency or number of data points falling within that inter val. Count : It indicates the \" frequency \", which means in the par ticular bar or r ange of height, how many v alues ar e ther e. We can asser t this lik e, around 500 people ha ve their height in the r ange of 63 - 65 (that on bar) This is what hist ograms or distribution plots tell about the data Now let' s have a look int o some distribution functions The PMF",
    "source": "lec6.pdf::chunk1"
  },
  {
    "text": "is a function that describes the pr obability of a discr ete r andom v ariable taking on a specic v alue. It associates each possible v alue of the r andom v ariable with its pr obability of occurr ence. Example: Rolling a F air Six-Sided Die For example, if we ha ve a discr ete r andom v ariable representing the outcome of r olling a fair six-sided die, the PMF might look lik e , , and so on.Probability Mass F unction (PMF) îŒ“ ğ‘‹ ğ‘ƒ(ğ‘‹=1)=1 6ğ‘ƒ(ğ‘‹=2)=1 6 PDF is used for continuous r andom v ariables , as opposed t o PMF , which is for discr ete v ariables. PDF does not pr ovide the pr obability of a specic v alue but giv es the probability of the r andom v ariable falling within a cer tain inter val For instance, it answers questions lik e \"What ar e the chances that the next height chosen will fall between 62 and 65 inches?\" We can visualiz e a PDF b y using distribution plots lik e hist ograms or KDE (K ernel Density Estimation ) plots.Probability Density F unction (PDF) îŒ“ <Axes: xlabel='Height', ylabel='Density'>",
    "source": "lec6.pdf::chunk2"
  },
  {
    "text": "sns.kdeplot(df_height) Example: If we ha ve a continuous r andom v ariable Y r epresenting the height of people in a population, The PDF might r epresent the pr obability that a r andomly chosen person has a height within a cer tain r ange, such as between 65 and 70 . We will nd out the ar ea under that inter val to nd the pr obability Next up we ha ve: The Cumulativ e Distribution F unction (CDF) describes the probability that a r andom v ariable tak es on a v alue less than or equal t o a giv en value . In the context of this dataset, in CDF , we talk about fr actions of people who ar e less than the giv en height Let's say you tak e 60 inches, then what fr action of the people ha ve less than or equal t o this v alue? This fr action is calculated using CDF It giv es you the cumulativ e probability up t o a cer tain point. Example: If you ha ve a r andom v ariable Z r epresenting the number of heads in thr ee coin t",
    "source": "lec6.pdf::chunk3"
  },
  {
    "text": "osses, The CDF would tell y ou the probability that Z is less than or equal t o a cer tain number , like P(Z â‰¤ 2). How t o calculate CDF ? The CDF is calculated b y accumulating the pr obabilities for each height v alue . As y ou mo ve along the X -axis (height v alues) on the CDF gr aph, y ou're essentially adding up the pr obabilities It shows how lik ely it is t o nd someone with a height less than or equal t o that v alue.Cumulativ e Distribution F unction (CDF) îŒ“ The CDF gr aph typically star ts at 0% on the Y -axis (pr obability) when height is at its minimum (in our dataset) It ends at 100% when height is at its maximum . The cur ve star ts at the left and gr adually climbs t owar ds the right. The steepness of the cur ve at a par ticular point r epresents how quickly the pr obability is accumulating Conclusion So, the PDF shows y ou the pr obability of a specic height, while the CDF shows y ou the pr obability of heights",
    "source": "lec6.pdf::chunk4"
  },
  {
    "text": "up t o a cer tain v alue in y our dataset. In summar y, the r elationships ar e as follows: The PMF is used for discr ete r andom v ariables . The PDF is used for continuous r andom v ariables . The CDF is used for both discr ete and continuous r andom v ariables t o provide cumulativ e probabilities. These functions ar e essential t ools in pr obability and statistics for understanding the beha viour of diff erent pr obability distributions.Conclusion : Case study on Empirical vs Theor etical Pr obability îŒ“ Casino Case StudyîŒ“ A bag has 3 Red and 2 Blue balls. You pick a ball, write its colour , and put it back in the bag. This is done 4 times in total. If all 4 times, the Red balls was dr awn, y ou win Rs 150 . Other wise y ou lose Rs 10 . Question : W ould engaging in this game r esult in a pr ot or loss for y ou? Discuss: Problem mentions that once y ou've noted the color , you put it back in the bag What does this mean in the",
    "source": "lec6.pdf::chunk5"
  },
  {
    "text": "pr obabillity language? It means that the balls ar e drawn with r eplacement The step of taking out the ball is r epeated 4 times Whether y ou end up gaining or losing will depend on how many r ed balls ar e drawn. Ther efore, let' s dene a r andom v ariable to denote the number of r ed balls dr awn. Hence, will be a discr ete r andom v ariable. Possible outcomes of : or ğ‘‹ ğ‘‹ ğ‘‹0,1,2,3 4 Empirical A pproach We know that it is possible t o get 7 heads on 10 coin t osses, when using a fair coin. So how would one go about pr oving that P(Heads) = 0.5 for a fair coin? How many of y ou ha ve hear d about the scientist who wanted t o prove this? In or der t o do so, he t ossed a fair coin 10,000 times r epeatedly , and noted down his obser vation on each t oss. The idea was Though 7 heads is pr obable for 10 t osses, when a coin is t ossed for 10,000 times, the number of heads should be appr oximately",
    "source": "lec6.pdf::chunk6"
  },
  {
    "text": "5,000 This pr ocess of simulating the experiment, and r epeating it multiple times, is done in an effor t to calculate pr obability v alue (of getting heads in this example) . This v alue is known as Empirical Pr obability . The idea is mak e estimates using r eal-world data/obser vationsMotiv ation for Empirical A pproach îŒ“ Let's try to estimate whether we will ha ve a pr ot or loss after pla ying this game, using pr obabilities caluclated b y empirical appr oach. For this, we will simulate this situation in P ython code. import math as m import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt Let's simulate the giv en Casino pr oblem using np.random.choice() Since we ha ve, 3 red balls and 2 blue balls We can r epresent the possible outcomes as a list [\"R\", \"R\", \"R\", \"B\", \"B\"] Since the ball is being dr awn 4 times, we set size = 4 Notice that e very time we ex ecute the following code, we will get a diff erent r esult, and the y're being chosen r andomly each time. #Code to be",
    "source": "lec6.pdf::chunk7"
  },
  {
    "text": "shared to learners rolls=np.random.choice([ \"R\",\"R\",\"R\",\"B\",\"B\"],size=4) rolls array(['R', 'B', 'B', 'R'], dtype='<U1') Recall that represents the number of r ed balls dr awn in a simulation. 1. Create a Boolean mask ha ving all obser ved \"R\" as True and \"B\" as False 2. Use np.count_nonzero() to count number of True in the mask.ğ‘‹ How t o evaluate from a simulation? îŒ“ ğ‘‹ # rolls==\"R\" creates a Boolean mask # count_nonzero() counts the number of non-zero OR True elements in the passed list. np.count_nonzero(rolls== \"R\") 2 Let's tak e inspir ation fr om the scientist and per form this simulation 10,000 times using a code, and note our obser vations. Discuss: We alr eady know how t o simulate a ball dr aw Let's store the no of r eds obser ved in a v ariable num_red And st ore this v alue for all 10,000 simulations int o a list red_values red_values=[] for person in range(10000): rolls=np.random.choice([ \"R\",\"R\",\"R\",\"B\",\"B\"],size=4) num_red=np.count_nonzero(rolls== \"R\") red_values.append(num_red) pd.value_counts(red_values) 3 3552 2 3394 1 1496 4 1281 0 277 dtype: int64 # red_values Let's do a .value_counts() to see the fr equency of v alues v alues it contains. pd.value_counts(red_values,normalize= True) 3 0.3552 2 0.3394 1 0.1496",
    "source": "lec6.pdf::chunk8"
  },
  {
    "text": "4 0.1281 0 0.0277 dtype: float64 We are awar e that passing normalize=True in value_counts() gives us the r esult in per centage of their occur ence. We can see that the pr obability of dr awing 3 r ed balls is 0.3552, 2 r ed balls is 0.3394 and so on.. Based on this data, how many r ed balls we will get on an a verage based on simulations we ha ve done 10,000 times? # This is empirical value np.mean(red_values) 2.4064 Expectation using Empirical A pproach îŒ“ How do y ou think, this mean was calculated fr om these fr equency v alues? As y ou learnt in the last class, this was calculated as a r esult of Weighted A verage So, for the giv en fr equency count, we can see that this is calculated as: ğ‘€ğ‘’ğ‘ğ‘›= =4(1281)+3(3552)+2(3394)+1(1496)+0(277) 1281+3552+3394+1496+2774(1281)+3(3552)+2(3394)+1(1496)+0(277) 10000 (4*(1281) + 3*(3552) + 2*(3394) + 1*(1496) + 0*(277)) / (10000) 2.4064 Now that we 've veried this, Let's represent the same equation in a slightly diff erent format. If you closely look at the v alue counts table, y ou will see that this can be r epresented as the following formula: wher e",
    "source": "lec6.pdf::chunk9"
  },
  {
    "text": "was our r andom v ariable that denotes the no of r ed balls dr awn. represents the pr obability of X getting a v alue of is known as the Expected v alue of the r andom v ariable Let's dene it formally: Expectation of a random variable X, is the weighted average of the values that X takes, with the weights being the probabilities.ğ‘€ğ‘’ğ‘ğ‘›=4 +3 +2 +1 +01281 100003552 100003394 100001496 10000277 10000 ğ¸(ğ‘‹)= âˆ—ğ‘ƒ(ğ‘‹= ) Î£ğ‘–ğ‘‹ğ‘– ğ‘‹ğ‘– ğ‘‹ ğ‘ƒ(ğ‘‹= )ğ‘‹ğ‘– ğ‘‹ğ‘– ğ¸(ğ‘‹) ğ‘‹ Until now , we simulated the e vent 10,000 times, and found an expected v alue of r andom v ariable X using the data obser ved. This is known as the Empirical A pproach of solving the pr oblem. Now , let's solv e this case study using theor etical appr oach and obser ve the diff erence in the r esult Now let' s discuss the theor etical appr oach t o this Casino case study Let's look at the pr oblem statement once mor e.Theor etical Appr oach îŒ“ A bag has 3 Red and 2 Blue balls. You pick a ball, write its colour , and put it back in",
    "source": "lec6.pdf::chunk10"
  },
  {
    "text": "the bag. This is done 4 Times in total. If all 4 times, the Red balls was dr awn, y ou win Rs 150 . Other wise y ou lose Rs 10 . Question: W ould engaging in this game r esult in a pr ot or loss for y ou? Let's dene 2 e vents: : Drawing a r ed ball : Drawing a blue ball What would be the pr obability of obtaining a r ed ball once?ğ‘… ğµ ğ‘ƒ(ğ‘…)=3 5 Similarly , we know that ğ‘ƒ(ğµ)=2 5 What is the pr obability of dr awing a r ed ball twice? What is the pr obability of dr awing a r ed ball followed b y a blue ball? These v alues ar e easy t o evaluate when we ar e drawing the balls just twice.ğ‘ƒ(ğ‘…ğ‘…)= âˆ—3 53 5 ğ‘ƒ(ğ‘…ğµ)= âˆ—3 52 5 In our case study , we ar e drawing it 4 times . Let' s consider that case. Like befor e, we dene as a r andom v ariable that denotes the no of r ed balls dr awn. What would be the pr obability of obtaining 1 r ed ball? For , we",
    "source": "lec6.pdf::chunk11"
  },
  {
    "text": "can ha ve 4 possible cases as dr awn below: BBBR BBRB BRBB RBBB Let's look at the pr obability v alue of each of these individual cases: Case 1: Case 2: and so on So we can see that for all these 4 cases, we can write their probability as: Since ther e are 4 such cases, we write the t otal pr obability of as: = case 1 OR case 2 OR case 3 OR case 4ğ‘‹ ğ‘‹=1 âˆ—âˆ—âˆ—2 52 52 53 5 âˆ—âˆ—âˆ—2 52 53 52 5 ( âˆ—(2 5)3 3 5)1 ğ‘‹=1 ğ‘ƒ(ğ‘‹=1) ğ‘ƒ(ğ‘‹=1)=4âˆ—( âˆ—(2 5)3 3 5)1 What would be the pr obability of getting 2 r ed balls out of the 4 balls dr awn? Let's look at the diff erent orientations possible for . We ha ve 6 possibilities.ğ‘‹=2 Let's look at the pr obability of each of these orientations: Case 1: ... and so on So, at the end of the da y, we know that pr obability for each of these individual cases would be: Since either of these 6 cases ar e possible, the t otal pr obability becomes:âˆ—âˆ—âˆ—2 52 53 53 5 ( âˆ—(2 5)2 3 5)2 ğ‘ƒ(ğ‘‹=2)=6âˆ—( âˆ—(2",
    "source": "lec6.pdf::chunk12"
  },
  {
    "text": "5)2 3 5)2 Can we write this 4 and 6 in a diff erent format? Recall the combinat orics lectur e. We know that With this in mind, when we tak e a look at the r esults of and , can we deriv e some gener al expr ession? Notice that her e, 4 is nothing but the no of times a ball was dr awn fr om the bag, i.e. no of trials We can use this deriv ed equation t o nd pr obability for all v alid v alues of the r andom v ariable :ConclusionîŒ“ 4= 4ğ¶1 6= 4ğ¶2 ğ‘ƒ(ğ‘‹=1) ğ‘ƒ(ğ‘‹=2) ğ‘ƒ(ğ‘‹=ğ‘˜)= ( ( 4ğ¶ğ‘˜3 5)ğ‘˜2 5)4âˆ’ğ‘˜ ğ‘‹ ğ‘ƒ(ğ‘‹=0)= ( ( 4ğ¶03 5)02 5)4 ğ‘ƒ(ğ‘‹=1)= ( ( 4ğ¶13 5)12 5)3 ğ‘ƒ(ğ‘‹=2)= ( ( 4ğ¶23 5)22 5)2 ğ‘ƒ(ğ‘‹=3)= ( ( 4ğ¶33 5)32 5)1 ğ‘ƒ(ğ‘‹=4)= ( ( 4ğ¶43 5)42 5)0 Now we 've underst ood this in theor y, but How can we compute this in code? We will use built-in functions of the math.comb() library. import math How will we nd the v alue of ?4ğ¶0 math.comb( 4, 0) 1 As y ou can see this ga ve us the r esult of Similarly , we",
    "source": "lec6.pdf::chunk13"
  },
  {
    "text": "can nd as:4! 0!âˆ—(4âˆ’0)! 4ğ¶1 math.comb( 4, 1) 4 Let's evaluate the pr obability v alues for all possible v alues of ğ‘ƒ(ğ‘‹) ğ‘‹={0,1,2,3,4} # P(X=0) math.comb( 4,0)* (3/5)**0 * (2/5)**4 0.025600000000000005 # P(X=1) math.comb( 4,1)* (3/5)**1 * (2/5)**3 0.15360000000000004 # P(X=2) math.comb( 4,2)* (3/5)**2 * (2/5)**2 0.3456000000000001 # P(X=3) math.comb( 4,3)* (3/5)**3 * (2/5)**1 0.34559999999999996 # P(X=4) math.comb( 4,4)* (3/5)**4 * (2/5)**0 0.1296 Let's compar e these pr obability r esults t o what we e valuated thr ough the Empirical appr oach Notice that these v alues ar e very close. As discussed earlier , if we incr ease the no of simulations, the obser ved result would be mor e and mor e closer t o these theor etical v alues . Hence, pr oved. You might not be awar e, but while solving this Casino case study , we've also been deriving the equation for Binomial Distribution. Let's summariz e our ndings, and look at this distribution formally .Binomial DistributionîŒ“ Binomial distribution is a discr ete pr obability distribution of the number of successes in n independent experiments sequence. A Binomial trial will alwa ys ha ve two possible outcomes : Success / Win Failur e",
    "source": "lec6.pdf::chunk14"
  },
  {
    "text": "/ Loss We dened a discr ete r andom v ariable that denoted number of r ed balls dr awn. Note that the e vent of dr awing a ball is independent. will be called a Binomial R V Also, we wer e giv en some par ameters in our pr oblem, let' s dene them: : No of independent trials In our example, we dr aw balls 4 times, hence : Probability of success in one trial In our example, this denotes the pr obability of dr awing a r ed ball, hence Ther efore, becomes the pr obability of failur e in each trial (i.e. dr awing a blue ball, in this example) Using these par ameters, we can r e-write the equation we deriv ed in gener al form: ğ‘‹ ğ‘‹ ğ‘› ğ‘›=4 ğ‘ ğ‘=3 5 (1âˆ’ğ‘) ğ‘ƒ(ğ‘‹=ğ‘˜)= (ğ‘ (1âˆ’ğ‘ ğ‘›ğ¶ğ‘˜)ğ‘˜)ğ‘›âˆ’ğ‘˜ Let's plot our calculated v alues t o see what Binomial distribution looks lik e. x = pd.value_counts(red_values, normalize= True) x 3 0.3552 2 0.3394 1 0.1496 4 0.1281 0 0.0277 dtype: float64 ax = sns.barplot(x = x.index, y = x.values) for i in ax.containers: ax.bar_label(i,) This is the Probabillity Mass F unction (PMF) of our",
    "source": "lec6.pdf::chunk15"
  },
  {
    "text": "giv en Binomial experiment, which is called as Binomial Pr obability Distribution The gr aph shows the pr obability of obtaining each possible number of successes (k) in n trials. The height of each bar r epresents the pr obability of that par ticular outcome. The sum of all the pr obabilities equals 1. The scipy.stats.binom library giv es us a built in function that eases the calculation of PMF v alues (i.e. v alue of for specic v alues of ). Instead of using the formula , we can dir ectly use this function t o calculate the PMF v alue. We just need t o specify the 3 par ameters: n k pğ‘ƒ(ğ‘‹) ğ‘‹ ğ‘ƒ(ğ‘‹=ğ‘˜)= (ğ‘ (1âˆ’ğ‘ ğ‘›ğ¶ğ‘˜)ğ‘˜)ğ‘›âˆ’ğ‘˜ from scipy.stats import binom prob_0_red = binom.pmf(n= 4,p=3/5,k=0) prob_0_red 0.025599999999999994 prob_1_red = binom.pmf(n= 4,p=3/5,k=1) prob_1_red 0.15359999999999996 prob_2_red = binom.pmf(n= 4,p=3/5,k=2) prob_2_red 0.3456 prob_3_red = binom.pmf(n= 4,p=3/5,k=3) prob_3_red 0.3456000000000001 prob_4_red = binom.pmf(n= 4,p=3/5,k=4) prob_4_red 0.1296 Notice that these v alues ar e the same as what we calculated using math.comb How will we calculate the theor etical expectation v alue? We know the formula: Here, we saw that we can calculate the pr obability v alues using scipy.stats.binom And that r",
    "source": "lec6.pdf::chunk16"
  },
  {
    "text": "andom v ariable Expectation using theor etical appr oach îŒ“ ğ¸(ğ‘‹)= ğ‘ƒ(ğ‘‹= ) Î£ğ‘–ğ‘‹ğ‘– ğ‘‹ğ‘– ğ‘‹={0,1,2,3,4} expectation_theoretical= ( 0*prob_0_red) + ( 1*prob_1_red) + ( 2*prob_2_red) + ( 3*prob_3_red) + ( 4*prob_4_red) expectation_theoretical 2.4000000000000004 Note that this is close t o the Empirical Expected v alue we calculated. Alternately , ther e is a built-in function t o nd this expected v alue in stats.binom Here, we need t o pass the following ar guments t o args: n, and p binom.expect(args=( 4,3/5)) 2.4000000000000004 Recall that v ariance tells y ou how much the actual r esults might v ary from the expected a verage (mean), helping y ou understand whether y our obser vations ar e likely due t o chance or if ther e's something mor e going on, lik e bias in the coin. Formula for V ariance in Binomial Distribution : The formula for v ariance in a binomial distribution is: Wher e: is the number of trials (or coin ips in our example). is the pr obability of success on each trial (the pr obability of getting heads in our coin ip example). represents the pr obability of failur e on each trial (the pr obability",
    "source": "lec6.pdf::chunk17"
  },
  {
    "text": "of getting tails). is also denoted as also, so orVariance in Binomial Distribution =ğ‘›âˆ—ğ‘âˆ—(1âˆ’ğ‘) Ïƒ2 ğ‘› ğ‘ (1âˆ’ğ‘) (1âˆ’ğ‘) ğ‘ =ğ‘›âˆ—ğ‘âˆ—(1âˆ’ğ‘) Ïƒ2 =ğ‘›ğ‘ğ‘ Ïƒ2 We learnt about the concept of Binomial distribution. But we still ha ven't answer ed our question : Would engaging in this game r esult in a pr ot or loss for y ou? îŒ“ Let's dene another r andom v ariable that denotes the amount of mone y won/lost thr ough gambling. Ther efore, possible v alues of ğ‘Œ ğ‘Œ:{150,âˆ’10} Let's create a table for this r andom v ariable , with it' s posibble v alues and corr esponding pr obabilities. ğ‘Œ Case of winning Rs 150 ( ) would be the same as Case of loosing Rs 10 ( )ğ‘Œ=150 ğ‘ƒ(ğ‘Œ=150) ğ‘ƒ(ğ‘‹=4) ğ‘Œ=âˆ’10 ğ‘ƒ(ğ‘Œ=âˆ’10)=ğ‘ƒ(ğ‘‹=0)+ğ‘ƒ(ğ‘‹=1)+ğ‘ƒ(ğ‘‹=2)+ğ‘ƒ(ğ‘‹=3)=1âˆ’ğ‘ƒ(ğ‘‹=4) # P(Y=150) prob_4_red 0.1296 #P(Y = -10) 1 - prob_4_red 0.8704000000000001 What would be expected v alue of ?ğ‘Œ ğ¸(ğ‘Œ)= ğ‘ƒ(ğ‘Œ= )=(150âˆ—0.1296)+(âˆ’10âˆ—0.8704000000000001) Î£ğ‘–ğ‘Œğ‘– ğ‘Œğ‘– expected_y = ( 150*0.1296) + (-10*0.8704000000000001 ) expected_y 10.735999999999997 This v alue means that if we pla y many many times, at the end of the da y, we ar e expected t o ha ve prot of Rs 10.736Conclusion of the case study :",
    "source": "lec6.pdf::chunk18"
  },
  {
    "text": "îŒ“ 1. The experiment must consist of a xed number of trials (n) , with only 2 possible outcomes: Success or F ailur e Here, we had x ed So, we cannot incr ease or decr ease it in between We dened success as the e vent of dr awing a r ed ball: 2. Individual trials ar e identical and independent . This needs t o hold true, other wise, the pr obability v alues might change for diff erent trials.Conditions of Binomial ExperimentîŒ“ ğ‘›=4 ğ‘ƒ(ğ‘†ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘ )=3 5 In this example also, the trials of dr awing balls wer e identical and independent, as we wer e replacing the balls after each dr aw. Hence, it contained exactly same number of balls of each color . 3. The r andom v ariable denotes the number of success in n trials. Bernoulli Trials îŒ“ In the abo ve example, it was conv eyed clearly that we will dr aw a ball 4 times fr om the bag. But let' s consider the case when a ball is dr awn fr om the bag, only one, i.e. one trial . Like befor e, we still dene as the e vent of getting",
    "source": "lec6.pdf::chunk19"
  },
  {
    "text": "a r ed ball. Ther efore, on dr awing the ball, we get 2 possibilities: Getting a r ed ball (Success) We know that pr obability for this will be: Getting a blue ball (F ailur e) Probability: ğ‘‹ ğ‘ƒ(ğ‘†ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘ )=ğ‘=3 5 ğ‘ƒ(ğ¹ğ‘ğ‘–ğ‘™ğ‘¢ğ‘Ÿğ‘’)=1âˆ’ğ‘=2 5 This is known as a Bernoulli Trial. Essentially , it is the special case of Binomial trial, wher e n = 1 Hence, it must also follow the condition that ther e must be only 2 possible outcomes: Success, or Failur e Let's plot this, t o see what Bernoulli distribution looks lik e. Text(0, 0.5, 'P(X)') x = [0, 1] y = [2/5, 3/5] plt.bar(x, y, width= 0.6, tick_label=[ \"0\", \"1\"]) plt.xlabel( \"Random Variable (X)\" ) plt.ylabel( \"P(X)\") Another example of Bernoulli distribution Consider the situation of passing or failing an exam. Let's assume the pr obability t o pass the exam is 95%, Ther efore the pr obability t o fail will be 5%. In this case, if the e vent t o pass the exam is consider ed, then the Bernoulli e vent will contain the pr obability of passing the exam. Similarly , it goes for failing the exam. To summariz e, what",
    "source": "lec6.pdf::chunk20"
  },
  {
    "text": "is the diff erence between Binomial and Bernoulli distribution? Bernoulli deals with the outcome of the single trial of the e vent, wher eas Binomial deals with the outcome of the multiple trials of the single e vent. Hence, we can dene Binomial distribution in another wa y: It is the collection of Bernoulli trials for the same event, i.e., it contains more than 1 Bernoulli event for the same scenario for which the Bernoulli trial is calculated. Let's tak e a look at another example pr oblem Dice ExampleîŒ“ You toss 2 dice. If both dice are 6, you get Rs 2. Else, if one dice is 6, you get Rs 1. Otherwise, you do not get anything. Let's dene a r andom v ariable that r epresents the amount of mone y won. Hence, it can tak e the v alues: Answer the following questions. What is the pr obability of getting the following? Rs 0 Rs 1 Rs 2 Let's visualiz e the possible outcomes thr ough a table. Possible v alues of Dice 1 along the r ow Possible v alues of Dice 2 along the column Value corr esponding t o a r ow and",
    "source": "lec6.pdf::chunk21"
  },
  {
    "text": "col, r epresents the mone y won ( )ğ‘‹ ğ‘‹={0,1,2} ğ‘‹ Finding From the table we can see that we will get 0 Rs for 25 outcomes, hence Finding From the table, Finding From the table, ğ‘ƒ(ğ‘‹=0) ğ‘ƒ(ğ‘‹=0)=25 36 ğ‘ƒ(ğ‘‹=1) ğ‘ƒ(ğ‘‹=1)=10 36 ğ‘ƒ(ğ‘‹=2) ğ‘ƒ(ğ‘‹=2)=1 36 Now , lets see if we can obtain the same answers using the Binomial formula Befor e we get t o solving, let' s dene the par ameters: What will be the v alue of n? Since we ar e thr owing 2 dice, What will be the v alue of p? p is dened as the pr obability of succes in one trial So how do we dene success her e? Obtaining a 6 Ther efore, p = pr obability of getting a 6 in a single dice r oll, i.e. We know the Binomial formula is: Ther efore, These ar e the exact answers we got using the table abo ve!!ğ‘›=2 ğ‘=1 6 ğ‘ƒ(ğ‘‹=ğ‘˜)= (ğ‘ (1âˆ’ğ‘ ğ‘›ğ¶ğ‘˜)ğ‘˜)ğ‘›âˆ’ğ‘˜ ğ‘ƒ(ğ‘‹=0)= ( ( =1âˆ—1âˆ— = 2ğ¶01 6)05 6)2 25 3625 36 ğ‘ƒ(ğ‘‹=1)= ( ( =2âˆ—âˆ— = 2ğ¶11 6)15 6)1 1 65 610 36 ğ‘ƒ(ğ‘‹=2)= ( ( =1âˆ— âˆ—1= 2ğ¶21 6)25 6)0 1 361 36 Alternately ,",
    "source": "lec6.pdf::chunk22"
  },
  {
    "text": "we could'v e evaluated the binomial formula using code as: binom.pmf (n=2,p=1/6,k=0) 0.6944444444444443 Now answer the second question. What is the expected v alue of mone y won? We can nd this using the formula: Alternately , we can use the stats.binom.expect() functionğ¸(ğ‘‹)= ğ‘ƒ(ğ‘‹= ) Î£ğ‘–ğ‘‹ğ‘– ğ‘‹ğ‘– =(0âˆ— )+(1âˆ— )+(2âˆ— )25 3610 361 36 =1 3 binom.expect (args=(2,1/6)) 0.33333333333333326",
    "source": "lec6.pdf::chunk23"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Population vs Sample Sample Statistics Sample Mean Sample v ariance Sample Standar d De viation Point Estimates Standar d Err or Sampling techniques Random Sampling Uniform DistributionContent Population vs SampleîŒ“ Think of a population as the entir e set of items under study . This could be the entir e group of inter est, whether it' s people, objects, data points, or any other r elevant entities. We use populations t o draw conclusions. For example: If we wer e conducting a sur vey to understand the a verage income of all r esidents in a city , the population in this case would be e very single r esident in that city .Population: A sample is a smaller , manageable subset of the population. The sample is an unbiased subset of the population that best r epresents the whole data .Sample:îŒ“ To overcome the r estraints of a population, we can sometimes collect data fr om a subset of our population and then consider it as the gener al norm. Example: Suppose",
    "source": "lec7.pdf::chunk0"
  },
  {
    "text": "fr om an entir e city we ha ve selected and collected data fr om 500 r esidents fr om that city , this gr oup of 500 individuals would r epresent our sample . The idea her e is that the char acteristics of the sample should r esemble the char acteristics of the entir e population, allowing us t o mak e inferences or estimates about the population using the sample data. The pr ocess of collecting data fr om a small subsection of the population and then using it t o gener alize over the entir e set is called Sampling . Conclusion Why should we use samples instead of studying entir e populations? Practicality: Reduced Err or: In some cases, testing or studying an entir e population is destructiv e or impr actical. Sample StatisticsîŒ“ A parameter is a measur e that describes the whole population Population data has a f ew population par ameters lik e: 1. Population Mean 2. Population V ariance 3. Population SD A statistic is a measur e that describes the sample . Sample statistics ar e descriptiv e values calculated fr om sample data. Sample statistics include measur es lik",
    "source": "lec7.pdf::chunk1"
  },
  {
    "text": "e: The sample mean, denoted as , is the a verage v alue of a set of data points within a sample. Formula: Wher e, = Sample mean = sum of each v alue in the sample = number of v alues in the sample Difference fr om P opulation Mean ( Î¼ ): The sample mean is an estimate of the population mean and is calculated fr om sample data. It ma y vary from one sample t o another but is expected t o be close t o the population mean when using a suciently lar ge, random sample. Example: Suppose we want t o estimate the a verage income of people in a city . Instead of sur veying the entir e population, we randomly select 100 individuals and calculate their a verage income, which is the sample mean .1) Sample Mean ()ğ‘¥Â¯ ğ‘¥Â¯ =ğ‘¥Â¯âˆ‘ğ‘¥ğ‘– ğ‘› ğ‘¥Â¯ âˆ‘ğ‘¥ğ‘– ğ‘› The sample v ariance, denoted as , measur es the spr ead or dispersion of data within a sample. The sample v ariance is used t o mak e estimates or inf erences about the population v ariance.2) Sample V ariance ( )ğ‘ 2 ğ‘ 2 Formula: Wher e, =",
    "source": "lec7.pdf::chunk2"
  },
  {
    "text": "Sample v ariance = represents individual data points. = sample mean = number of data points in the sample How it is diff erent fr om population v ariance . The population v ariance is a par ameter that describes the v ariability in the entir e population. The sample v ariance is a statistic used t o estimate the population v ariance based on a sample.=ğ‘ 2(âˆ’âˆ‘ ğ‘–=1ğ‘› ğ‘¥ğ‘–ğ‘¥Â¯)2 ğ‘›âˆ’1 ğ‘ 2 ğ‘¥ğ‘– ğ‘¥Â¯ ğ‘› The sample standar d de viation, denoted as , is a measur e of how spr ead out the data in a sample is. FormulaSample Standar d De viation îŒ“ (ğ‘ ) ğ‘  How it is diff erent fr om P opulation Standar d De viation ( Ïƒ ): The sample standar d de viation estimates the population standar d de viation but ma y not match it exactly due t o the nite siz e of the sample. How it is diff erent fr om P opulation Standar d De viation ( Ïƒ ): The sample standar d de viation estimates the population standar d de viation but ma y not match it exactly due t o the nite siz e of the sample. Now ,",
    "source": "lec7.pdf::chunk3"
  },
  {
    "text": "we will use these sample statistics as a point estimate t o estimate population par ameters . It ser ves as the best guess for the true, but often unknown, population par ameters. For instance, the sample mean estimates the population mean, and the sample v ariance estimates the population v ariance. Imagine a scenario: We want to estimate the mean weight of a certain species of turtle in Florida. We opt t o select a random sample of 50 tur tles and use the mean weight of this sample t o estimate the true population meanPoint EstimatesîŒ“ Assume the sample mean is 150.4 pounds , Then our point estimate for the true population mean of the entir e species would be 150.4 pounds . Impor tance of r epresentativ e samples To get accur ate insights about a whole gr oup, we need a sample that r eects the gr oup's main traits. If our sample closely r esembles the population, we can trust that estimates dr awn fr om it ar e reliable and unbiased r eections of the entir e population. Sampling methods/techniques r efer to how we select members fr om the population t o be",
    "source": "lec7.pdf::chunk4"
  },
  {
    "text": "in the study . Ther e are two primar y types of sampling methods that we can use in our r esear ch: 1. Probability sampling In this e very member of the population has a chance of being selected, allowing us to mak e str ong statistical inf erences about the whole gr oup. 2. Non-pr obability sampling In this method, individuals ar e selected based on non-r andom criteria, and not e very individual has a chance of being included. This type of sample is easier and cheaper t o access, but it has a higher risk of sampling bias. Ideally , a sample should be r andomly selected and r epresentativ e of the population. In this module, we ar e going t o study about pr obability sampling and that t oo Random Sampling and in the ML module we will see other sampling techniques.Sampling Techniques îŒ“ Simple Random SamplingîŒ“ A simple r andom sample is a randomly selected subset of a population . In this sampling method, each member of the population has an exactly equal chance of being selected which tends t o produce r epresentativ e, unbiased samples. For instance , If we",
    "source": "lec7.pdf::chunk5"
  },
  {
    "text": "want t o pick 1000 individuals fr om a t own with 100,000 r esidents, each person has a 0.01 probability of being selected . This str aightfor ward calculation doesn 't requir e in-depth knowledge of the population 's composition, Hence, simple r andom sampling. Q1. What ar e some pr erequisites befor e using this method? We ha ve a complete list of e very member of the population. We can contact or access each member of the population if the y are selected. We ha ve the time and r esour ces t o collect data fr om the necessar y sample siz e Simple r andom sampling works best if we ha ve a lot of time and r esour ces t o conduct our study , Or if we ar e studying a limited population that can easily be sampled. Q2. How t o per form simple r andom sampling? Ther e are 4 k ey steps t o select a simple r andom sample. Step 1: Dene the population Imagine we 're conducting a sur vey to study the eating habits of people in a par ticular city . Our dened population is all",
    "source": "lec7.pdf::chunk6"
  },
  {
    "text": "the r esidents of that city who ar e aged 18 t o 60 . Let the siz e of the population be 100,000 in this case Step 2: Determine the Sample Siz e Now , we need t o decide on the siz e of our sample. Larger samples enhance statistical condence but the y also come with incr eased costs and effor t. The sample siz e is based on the fact ors lik e, The city 's population siz e (let sa y, 100,000), How sur e do we want t o be in our r esults? Let's say we 're aiming for 95% certainty . How pr ecise do we need t o be? Let's say we 're cool with a 5% margin of err or. An estimated standar d de viation. After crunching those numbers, it turns out we 'll need t o sur vey about 5000 people. Step 3: Randomly Select our Sample We ha ve two options for r andom selection: 1. The lotter y method In the lotter y method, think of it lik e picking names fr om a wheel. Imagine we ha ve a wheel/bowl with e veryone's name in",
    "source": "lec7.pdf::chunk7"
  },
  {
    "text": "the gr oup written on separ ate pieces of paper . To choose a r andom sample, mix the papers well and r oll the wheel, and get a f ew names. It's like randomly selecting people without any specic or der, just lik e how a lotter y randomly picks winners. 2. The r andom number method. We assign a unique number t o each potential par ticipant. Using a r andom number gener ator, we then select 500 numbers at r andom fr om the list of assigned numbers. Step 4: Collect Data fr om our Sample We proceed t o collect data fr om the 500 individuals in our sample. Through this r ange of methods, we can understand the eating habits of city r esidents eciently and r eliably . The standar d err or (SE) quanties this v ariability , indicating how much the sample mean is expected t o de viate fr om the population mean when diff erent samples ar e drawn. When we want t o assess the accur acy/r eliability of the estimates , the standar d err or helps us assess the r eliability of sample-based estimates. A smaller standar",
    "source": "lec7.pdf::chunk8"
  },
  {
    "text": "d err or suggests that the sample statistic is likely t o be close t o the population par ameter While a larger standar d err or indicates more variability and less pr ecision in the estimate.Standar d Err or îŒ“ The standar d err or of the mean is calculated using the standar d de viation and the sample siz e.Standar d Err or Formula: we can use it in the below formula t o calculate standar d err or pr ecisely . The standar d err or of an estimate can be calculated as the standar d de viation divided b y the squar e root of the sample siz e:When the population standar d de viation is known wher e: = The population standar d de viation =The squar e root of the sample siz eğ‘†ğ¸=Ïƒ ğ‘›âˆš Ïƒ âˆšğ‘› Here we can use sample standar d de viation as a point estimate for the population standar d deviation. wher e: = The sample standar d de viation =The squar e root of the sample siz e We can obser ve from the formula that SE is inv ersely pr opor tional t o the sample siz e.",
    "source": "lec7.pdf::chunk9"
  },
  {
    "text": "The Lar ger the sample siz e, the Samller the sample err or will be. As the sample siz e grows, the sample statistic will appr oach the actual v alue of the populationWhen the population standar d de viation is unknown îŒ“ ğ‘†ğ¸=ğ‘  ğ‘›âˆš ğ‘  âˆšğ‘› Q. What is sample mean distributions? When we collect samples from the population (let sa y 5 samples ), calculate it's mean and iterate this pr ocess numer ous times then it'll form a distribution of sample means . This is also known as sampling distributions . Let's tak e an example: Let's say ther e are 300 million people in the USA. To determine this population 's average age, the statistician tak es a sample of 1000 people . He determined the average age of the sample was 37.5 y ears . The actual a verage age of the entir e population is 36.9 which is diff erent fr om the determined a verage age of sample.ExampleîŒ“ The standar d err or is an estimate of the accur acy of the sample a verage. Here, If the statistician had tak en the sample of 5000 people instead of 1000, the standar d",
    "source": "lec7.pdf::chunk10"
  },
  {
    "text": "err or would ha ve been smaller and the a verage age of the sample would ha ve been closer t o the actual population 's average age . As we saw if the statistician would ha ve tak en the sample of 5000 people instead of 1000, the sample mean age would ha ve been closer t o the true population a verage. This concept is known as Law of Lar ge Numbers. The Law of Lar ge Numbers states that as the sample siz e of a r andom experiment incr eases, the a verage v alue of the outcomes will conv erge to the expected v alue or true pr obability . In simple terms: It states that as the sample siz e incr eases, the sample mean gets closer and closer t o the population mean .Law of Lar ge Numbers îŒ“ Standar d de viation measur es the v ariability of individual data points within a single sample or a population, Standar d err or measur es the v ariability of sample means when multiple samples ar e drawn fr om a population.Difference between standar d de viation and standar d err or. îŒ“ A",
    "source": "lec7.pdf::chunk11"
  },
  {
    "text": "Uniform Distribution is a pr obability distribution wher e all possible outcomes ar e equally lik ely to occur . In this distribution, each v alue within a specied r ange has the same pr obability of occurring. Example A deck of car ds has within it uniform distributions because the lik elihood of dr awing a hear t, a club, a diamond, or a spade is equally lik ely. A coin also has a uniform distribution because the pr obability of getting either heads or tails in a coin t oss is the same.Uniform DistributionîŒ“ 1. Discr ete Uniform Distributions : The possible r esults of r olling a die pr ovide an example of a discr ete uniform distribution In discr ete uniform distribution: . Wher e, P(x) = Pr obability of a discr ete v ariable, n = Number of v alues in the r ange It is possible t o roll a 1, 2, 3, 4, 5, or 6, but it is not possible t o roll a 2.3, 4.7, or 5.5.Types of uniform distribution ğ‘ƒ(ğ‘¥)=1/ğ‘› Ther efore, the r oll of a die gener ates a discr ete distribution with p = 1/6 for each",
    "source": "lec7.pdf::chunk12"
  },
  {
    "text": "outcome. 2. Continuous Uniform Distributions : A random number gener ator would be consider ed a continuous uniform distribution. Suppose we gener ate r andom numbers between 0 .0and 1.0, With this type of distribution, e very point in the continuous r ange has an equal oppor tunity of appearing, y et ther e is an innite number of points between 0.0 and 1.0 In a discr ete uniform distribution, the pr obability is calculated using the pr obability mass function (PMF) To calculate the pr obability of a specic v alue in a discr ete uniform distribution: PMF(x) = P(X = x) = 1 / (b - a + 1) for a â‰¤ x â‰¤ b PMF(x) = P(X = x) = 0 other wise Wher e: PMF(x) is the pr obability mass function, r epresenting the pr obability of a r andom v ariable having a specic v alue within the r ange [a, b]. \"a\" and \"b \" are the minimum and maximum v alues within the r ange.1) The Distribution function of discr ete uniform distribution(PMF) îŒ“ In a continuous uniform distribution, the pr obability is calculated using pr obability density function (PDF) which is a",
    "source": "lec7.pdf::chunk13"
  },
  {
    "text": "constant v alue within a giv en range, and it' s dened as: PDF(x) = 1 / (b - a) for a â‰¤ x â‰¤ b PDF(x) = 0 other wise Wher e: PDF(x) is the pr obability density function, r epresenting the pr obability of a r andom v ariable falling within the r ange [a, b]. \"a\" and \"b \" are the minimum and maximum v alues within the r ange. Every value between \" a\" and \"b \" is equally lik ely to occur and any v alue outside of those bounds has a pr obability of z ero. It is also known as height of the gr aph If a r andom v ariable X follows a uniform distribution, then the pr obability that X tak es on a v alue between x1 and x2 can be found b y the following formula:2) The Distribution function of continuous uniform distribution(PDF)îŒ“ ğ‘ƒ( <ğ‘‹< )= ğ‘¥1 ğ‘¥2(â€“) ğ‘¥2ğ‘¥1 (ğ‘â€“ğ‘) Proper ties of the Uniform Distribution îŒ“ The uniform distribution has the following pr oper ties: Mean: Variance: , for Continuous uniform distributions Variance: , for Discr ete uniform distributions Standar d De viation: , for Continuous uniform distributions.",
    "source": "lec7.pdf::chunk14"
  },
  {
    "text": "Standar d De viation: , for Discr ete uniform distributions.(ğ‘+ğ‘) 2 (ğ‘â€“ğ‘)2 12 (ğ‘â€“ğ‘+1âˆ’1)2 12 (ğ‘â€“ğ‘)2 12â€¾ â€¾â€¾â€¾â€¾âˆš (ğ‘â€“ğ‘+1âˆ’1)2 12â€¾ â€¾ â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆš",
    "source": "lec7.pdf::chunk15"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Gaussian Distribution (\"Normal\" Distribution) 68/85/99 rule (Empirical Rule) Z-Scor e Percent P oint F unction (PPF) Standar d Normal Distribution Standar dizationContent Gaussian DistributionîŒ“ In fact, let' s represent these v alues with a r andom v ariable . Q1. What kind of r andom v ariable would be? Discr ete or Continuous? Continuous. Q2. Do y ou expect any kind of pattern in the height v alues? Assuming that this college is in India, we can asser t On a verage, the height v alues should be something lik e 5.5 f eet t o 5.75 f eet (These v alues ar e not impor tant) Though, ther e would also be people that ar e shor ter or taller than this r ange, we know that the y will be compar atively less in number . So, if we want t o plot a hist ogram t o visualiz e the fr equency/count of these height v alues, Would y ou agr ee that we get a plot that looks something",
    "source": "lec8.pdf::chunk0"
  },
  {
    "text": "lik e as shown below? Since is continuous, we will ha ve to count the fr equency for v alues belonging t o a cer tain r ange (bin the data v alues) Suppose we ha ve 2 gr oups of people ha ving height 5 f eet and 5.1 f eet This does not mean ther e can 't be an individual with height 5.005 f eet Hence in or der t o include e veryone, we bin the data while plotting.Imagine y ou ar e a Data Scientist and ar e collecting data about the heights of a college 's students . îŒ“ ğ‘‹ ğ‘‹ ğ‘‹ 3. What Can we estimate this hist ogram with a cur ve as shown in the image It co vers the same information about the fr equency of people belonging t o each bin/r ange. Ther e are also some additional adv antages t o estimating using such a cur ve: 1. Drawing insights about unseen data In the hist ogram, notice that we did not encounter any one whose height belonged t o the bin 6.25 t o 6.5 f eet. This does not mean that y ou will not nd",
    "source": "lec8.pdf::chunk1"
  },
  {
    "text": "any one belonging t o that r ange. It is a chance fact or, that no one of that height was pr esent in this college. From the hist ogram, y ou won 't be able t o calculate the pr obability of a person ha ving that height. But using this cur ve, you can calculate. 2. The Plot is not limited b y bin siz e Using the hist ogram, we could only calculate the pr obability of people ha ving height within the giv en bin siz e, i.e. P(X: 5.25 t o 5.5), P(X: 5.75 t o 6.0), etc. Howe ver, using the cur ve, we can nd the pr obability of people ha ving a height in a bin of any siz e: P(X: 5.13 t o 5.34), etc 3. Note: that the cur ve is symmetric, while the hist ogram was not This type of symmetric bell-shaped pr obability distribution cur ve is known as Gaussian / Normal / Bell shaped Cur ve Distribution In fact, this is a v ery special distribution that has its own set of pr oper ties, that can be le veraged t o draw insights and obser vations.",
    "source": "lec8.pdf::chunk2"
  },
  {
    "text": "Let's look at one of those pr oper ties. 68/95/99 rule (Empirical rule)îŒ“ Once y ou collected the data, y ou obser ved the following: Mean / A verage = 65 inches (Note: 1 f eet = 12 inches) Standar d De viation = 2.5 inches We know that the point corr esponding t o the peak her e would be the mean, i.e. Q1. What did the standar d de viation r epresent? We saw that SD is a measur e of the spr ead of the data A higher SD means a higher spr ead Since SD measur es the spr ead. Let's mark the points that ar e awa y from the mean b y a SD One SD t o the right would be: One SD t o the left would be: 65 65+2.5=67.5 65âˆ’2.5=62.5 Notice, on the r egion between 1 standar d de viation of the mean, i.e. between 62.5 & 67.5 (shaded y ellow) Q2. How much of the population do y ou think would be within this r egion? Since this r egion is ar ound the mean, fr equency of people is high. So the fr action should also be high,",
    "source": "lec8.pdf::chunk3"
  },
  {
    "text": "but how high? Gaussian distributions ha ve a pr oper ty that the fr action of population in this r egion is exactly 68% This means that the fr action of people whose height is between [62.5, 67.5] is 68% , i.e. We can also write this as: ğ‘ƒ(62.5<ğ‘‹<67.5)=0.68 ğ‘ƒ(Î¼âˆ’Ïƒ<ğ‘‹<Î¼+Ïƒ)=0.68 Two standar d de viations awa y: Let's mo ve far ther awa y from the mean, b y another standar d de viation . Ther efore the points become: on the left on the right The r egion enclosed between (shaded gr een) comprises 95% of the entir e population, i.e. Similarly , Three standar d de viations awa y: Let's mo ve far ther awa y from the mean, b y another standar d de viation . Ther efore the points become: on the left on the right The r egion enclosed between (shaded purple) comprises 99.7% of the entir e population, i.e.65âˆ’2(2.5)=60 65+2(2.5)=70 [Î¼âˆ’2Ïƒ,Î¼+2Ïƒ] ğ‘ƒ(Î¼âˆ’2Ïƒ<ğ‘‹<Î¼+2Ïƒ)=0.95 65âˆ’3(2.5)=57.5 65+3(2.5)=72.5 [Î¼âˆ’3Ïƒ,Î¼+3Ïƒ] ğ‘ƒ(Î¼âˆ’3Ïƒ<ğ‘‹<Î¼+3Ïƒ)=0.997 Ther e is a fancy name t o this pr oper ty. It is known as Gaussian Empirical Rule , mor e popularly known as the 68/95/99 Rule Z-scor e îŒ“ Q1. Is this empirical rule enough for",
    "source": "lec8.pdf::chunk4"
  },
  {
    "text": "us t o nd the fr action of population between any r andom v alue? Through the Empirical rule, we ar e only r estricted t o these numbers (68/95/99.7) This means that we won 't be able t o utiliz e this rule if we want t o know the fr action of people shor ter than 66, 69 or some other r andom value. This rule can only giv e us information if number is within the inter val enclosed b y points 1, 2 or 3 SD awa y. Consider the following question. Suppose The height of people is Gaussian with a mean of 65 inches and a standard deviation of 2.5 inches. What fraction of people are shorter than 69.1 inches? Solution A pproach: First things rst, let' s try to gur e out some r elation between the point and the mean & std de v. We know that 70 inches is 2 SD far awa y from the mean and 70 = 65 + 2(SD)69.1 67.5 is 1 SD far awa y from the mean 67.5 = 65 + 1(SD) Ther efore, 69.1 will be mor e than 1 SD and less than 2",
    "source": "lec8.pdf::chunk5"
  },
  {
    "text": "SD . Let's say 69.1 is \" \" standar d de viation awa y from the mean Hence, we can write: Conclusion: 69.1 inches is 1.64 Standard Deviation away from the mean This 1.64 is known as the Z-scor e of the point It represents the distance between a data point and the mean using standar d de viations.ğ‘§ 69.1=65+ğ‘§(2.5) ğ‘§= =1.6469.1âˆ’65 2.5 69.1 We can write in this wa y This is the formula of Z-scor e wher e x = number for which we need t o nd z-scor e = mean v alue = standar d de viation. Q1. What can be the possible v alues of this z-scor e value? It can be both positiv e and negativ e. A z-scor e = 0, r epresents that the data point is the mean itself A positiv e z-scor e represents that the data point is t o the right of mean . A negativ e z-scor e represents the data point is t o the left of mean .FormulaîŒ“ ğ‘§=ğ‘¥âˆ’Î¼ Ïƒ Î¼ Ïƒ Coming back t o the question at hand. Q2. How can we nd the fr action of people shor ter than z-scor e",
    "source": "lec8.pdf::chunk6"
  },
  {
    "text": "= 1.64? For that, we will ha ve to refer to a Z-table : https:/ /www .math.ariz ona.edu/~rsims/ma464/standar dnormaltable.pdf From the table, we nd that 94.95% people ha ve a shor ter height than 69.1 Q3. Alternately , can we solv e this pr oblem using code? First, let' s calculate the z-scor e # importing libraries import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from scipy.stats import norm z = (69.1 - 65) / 2.5 z 1.6399999999999977 First, let' s visualiz e what we ar e trying t o calculate. In or der t o nd the fr action/pr obability , we want t o calculate the ar ea under the normal distribution cur ve, up t o the point of or Q4. What exactly is this v alue? How can we calculate this? PDF/PMF/CDF? This can be found using the CDF v alue. Since this is in r elation t o Normal distribution, we will use the scipy.stats.norm.cdf(Z-score) to nd the per centage of people.ğ‘¥=69.1 ğ‘§âˆ’ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’=1.64 # calculate fraction who are shorter than 69.1 norm.cdf(z) 0.949497416525896 Hence, we can conclude that 94.95% of people ar e shor ter than 69.1",
    "source": "lec8.pdf::chunk7"
  },
  {
    "text": "inches This is exactly what we found using the Z-table. Verication of Empirical RuleîŒ“ Now that we know how t o calculate CDF using norm.cdf(z), let's also v erify the Empirical rule we learned. Verify 68 Rule For this, we will need t o calculate the ar ea enclosed between and What will be the z-scor e for these points? : -1 : +1Î¼âˆ’Ïƒ Î¼+Ïƒ Î¼âˆ’Ïƒ Î¼+Ïƒ norm.cdf( 1) - norm.cdf( -1) 0.6826894921370859 Similarly , we can check for 95 and 99.7 Rule. norm.cdf( 2) - norm.cdf( -2) 0.9544997361036416 norm.cdf( 3) - norm.cdf( -3) 0.9973002039367398 Now let' s look at some other pr oblems Balls produced by manufacturer have a mean diameter of 50 mm and a std dev of 2 mm. What would be the diameter corresponding to the z-score of 1.5? Example on z-scor e îŒ“ Solution: Here we ha ve giv en the z-scor e of a specic number with the mean and SD v alues t oo. So we can easily get the number fr om the z-scor e formula Given: Z-Scor e (z) = 1.5 Mean ( Î¼) = 50 mm std de v ( Ïƒ) = 2 mm We know: x = (1.5 *",
    "source": "lec8.pdf::chunk8"
  },
  {
    "text": "2) + 50 x = 53mm Conclusion: The Diameter corresponding to the z-score of 1.5 would be 53mmğ‘§=ğ‘¥âˆ’ğœ‡ ğœ Let's revisit the height examplePPF (P ercent P oint F unction) îŒ“ Consider the following question. The height of people is Gaussian with mean 65 inches and standard deviation 2.5 inches. One person says: 96% people are shorter than me. What is my height? Solution A pproach: We are giv en that this person is taller than 96% of the population Hence, we can nd the z-scor e corr esponding t o his height fr om the Z-table So, we see that his height should be assigned a z-scor e value between 1.75 and 1.76 Now consider the z-scor e formula: We can calculate the v alue of , by plugging in the other v alues.ğ‘§=ğ‘¥âˆ’Î¼ Ïƒ ğ‘¥ If you think about it, the appr oach we followed was the inverse of norm.cdf(), wher e We rst calculated the z-scor e Then the fr action of population up t o this scor e was look ed up on Z-table (or computed using code) This inv erse method of nding the z-scor e from giv en per cent/fr action is termed as",
    "source": "lec8.pdf::chunk9"
  },
  {
    "text": "the Percent P oint F unction (PPF) . We can calculate this dir ectly using norm.ppf() function norm.ppf(percentile) will giv e the Z-scor e corr esponding t o the per centile. From that, we can get the height. Here 96% people ar e shor ter than me basically indicating 96 per centile. # what is the height such that 96% people are shor ter? z = norm.ppf( 0.96) z 1.7506860712521692 # we know z = (x-mu)/sigma so from this we can get x x = (z*2.5) + 65 x 69.37671517813042 The special case, when a normal distribution has , and Ïƒ It is known as The Standar d Normal Distribution , also called the z-distribution And, it is denoted b y We can tak e any Normal Distribution and conv ert it to The Standar d Normal Distribution, using Standar dizationStandar d Normal Distribution Î¼=0 =1 ğ‘(0,1)",
    "source": "lec8.pdf::chunk10"
  },
  {
    "text": "Disclaimer: Please note that any t opics that ar e not co vered in t oday's lectur e will be co vered in the next lectur e. Centr al Limit Theor em Application of CL T on r eal lif e dataset Condence Inter vals Using CL T Using Bootstr apping With r eplacementContent Centr al Limit Theor em îŒ“ The centr al limit theor em r elies on the concept of a sampling distribution , which is the pr obability distribution of a statistic for a lar ge number of samples tak en fr om a population. Let's recall the sampling distribution Draw r andom samples fr om a population, calculate means for each sample, and r epeat. The collection of these sample means forms a sampling distribution. Imagine a scenario: Imagine you have a big jar filled with jellybeans. Each jellybean represents a piece of data in your population. The color and weight of the jellybeans can be different, representing the diversity in your data. Now, grab a handful of jellybeans from the jar and calculate the average weight of those jellybeans. Put those jellybeans back, shake the jar, and grab another handful, calculate the average again. Repeat",
    "source": "lec9.pdf::chunk0"
  },
  {
    "text": "this process many times. Accor ding t o the Centr al Limit Theor em: 1. No matter how the weight of the jellybeans ar e distributed originally , as y ou tak e mor e and mor e samples and calculate the a verage each time, the distribution of those a verages will star t to look lik e a bell cur ve. 2. The mor e handfuls of jellybeans y ou tak e, the closer the distribution gets t o a per fect bell cur ve, even if the original distribution of jellybeans was not bell-shaped at all. This is power ful because it allows us t o mak e cer tain assumptions and pr edictions about the a verages of lar ge samples, e ven if the y don 't know much about the original population. So, The centr al limit states that \"the mean of a r andom sample will r esemble e ven closer t o the population mean as the sample siz e incr eases and it will appr oximate a normal distribution r egar dless of the shape of the population distribution \" Means, if y ou tak e suciently lar ge samples fr",
    "source": "lec9.pdf::chunk1"
  },
  {
    "text": "om a population, the samples' means will be normally distributed , even if the population isn't normally distributed.CLT for a verages of r andom v ariables: îŒ“ Similarlly , If you tak e suciently lar ge number of Independent and Identically Distributed (i.i.d.) r andom v ariables, fr om a giv en population, and sum them up , the distribution of the sum will tend t o be appr oximately normal , regar dless of the shape of the original distribution. This is called CLT for sums of r andom v ariables In summar y both v ersions essentially state that as y ou sum or a verage a suciently lar ge number of i.i.d. r andom v ariables , the r esulting distribution tends t o appr oach normality .CLT for sums of r andom v ariables Sample siz e (n) pla ys a vital r ole in the context of the Centr al Limit Theor em (CL T) and its impact can be summariz ed as follows: A larger sample siz e leads to a sampling distribution that closely r esembles a normal distribution . The CL T tends t o work well when the sample siz e",
    "source": "lec9.pdf::chunk2"
  },
  {
    "text": "is suciently lar ge, typically consider ed as . Howe ver, it is not a strict rule but a r ough guideline. For moder ately sk ewed distributions, e ven smaller sample siz es can sometimes be sucient . For Small n the CL T can still be useful, especially if the population distribution is close t o normal. Howe ver, for smaller sample sizes, the normality assumption becomes mor e critical .Sample Siz e and Normality: îŒ“ (ğ‘›) ğ‘›â‰¥30 (ğ‘›<30) Here, We star ted b y taking 2 samples (n=2) from the population, calculated their mean, and r epeated this many times t o form a distribution. This distribution tends t o look mor e like a normal distribution. When we increased the sample siz e, the distribution r esembled a normal distribution e ven mor e closely . As y ou can see in the image abo ve, sample siz e also aff ects the spr ead of the sampling distribution. A smaller n (n = 2), will ha ve a high standar d de viation because sample means ar e less pr ecise estimates of the population mean, resulting in mor e spr ead. A larger n",
    "source": "lec9.pdf::chunk3"
  },
  {
    "text": "( n >= 30) will ha ve a low standar d de viation since sample means become mor e precise estimates of the population mean, leading t o less spr ead. Conclusion The sample siz e not only inuences how closely the sampling distribution appr oximates a normal cur ve but also impacts the spr ead or precision of sample means . As the sample siz e incr eases, the CL T becomes mor e applicable, and the standar d de viation decr eases, making the estimates of population parameters mor e reliable.Sample Siz e and Standar d De viations : If we summariz e the CL T, To apply the centr al limit theor em, the following conditions must be met: 1. Randomization : Data should be r andomly sampled, ensuring e very population member has an equal chance of being included. 2. Independence : Each sample v alue should be independent, with one e vent's occurr ence not aff ecting another . Commonly met in pr obability sampling methods, which independently select obser vations. 3. Large Sample Condition : A sample siz e of 30 or mor e is gener ally consider ed \"suciently lar ge.\" This thr",
    "source": "lec9.pdf::chunk4"
  },
  {
    "text": "eshold can v ary slightly based on the population distribution 's shape. These conditions ensur e the applicability of the centr al limit theor em.Conditions of the CL T will be Let's apply the centr al limit theor em t o real distribution t o see if the distribution of the sample means tends t o follow normal distribution or not. We'll tak e the height dataset on which we ha ve been working fr om f ew lectur es. As we know it is alr eady normally distributed, so let' s tak e the sample means and see if the y follow normal distribution.Application of CL T on r eal lif e dataset îŒ“ !wget --no-check-certificate https://drive.google.c om/uc?id= 1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo -O weight-height. csv --2024-01-18 10:05:52-- https://drive.google.com/uc?id=1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo Resolving drive.google.com (drive.google.com)... 74.125.31.139, 74.125.31.102, 74.125.31.101, ... Connecting to drive.google.com (drive.google.com)|74.125.31.139|:443... connected. HTTP request sent, awaiting response... 303 See Other Location: https://drive.usercontent.google.com/download?id=1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo [following] --2024-01-18 10:05:52-- https://drive.usercontent.google.com/download?id=1Mrt008vkE4nVb1zE4f06_rtq70QPfkIo Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.13.132, 2607:f8b0:400c:c09::84 Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.13.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 428120 (418K) [application/octet-stream] Saving to: 'weight-height.csv' weight-height.csv 100%[===================>] 418.09K --.-KB/s in 0.005s 2024-01-18 10:05:52 (86.3 MB/s) - 'weight-height.csv' saved [428120/428120] import numpy as np import pandas as pd import seaborn",
    "source": "lec9.pdf::chunk5"
  },
  {
    "text": "as sns import matplotlib.pyplot as plt from scipy.stats import norm Gender Height Weight 0 Male 73.847017 241.893563 1 Male 68.781904 162.310473 2 Male 74.1 10105 212.740856 3 Male 71.730978 220.042470 4 Male 69.881796 206.349801df_hw = pd.read_csv( 'weight-height.csv' ) df_hw.head() We are going t o work on height column so let' s store it in a diff erent datafr ame. df_height = df_hw[ \"Height\" ] <Axes: xlabel='Height', ylabel='Count'> sns.histplot(df_height) # mean of the entire population mu = df_height.mean() mu 66.36755975482124 sigma = df_height.std() sigma 3.8475281207732293 We will now r andomly select v e samples and determine the a verage height of these samples Sample siz e = 5 îŒ“ df_height.sample( 5) 6370 60.568529 944 70.811262 5038 63.407290 3876 69.322317 3754 72.442899 Name: Height, dtype: float64 np.mean(df_height.sample( 5)) 65.30073828576094 Obser vation We can notice that on running the abo ve code, it is gener ating 5 diff erent samples e very time and the sample mean is also changing with that. Let's repeat this pr ocess 10,000 times so we will get sample means of 10,000 unique samples (siz e = 5). We will plot the distributions of these 10,000 sample means t o see if the y follow the normal distribution.",
    "source": "lec9.pdf::chunk6"
  },
  {
    "text": "sample_5 = [np.mean(df_height.sample( 5)) for i in range(10000) ] <Axes: ylabel='Count'> sns.histplot(sample_5, kde= True) np.mean(sample_5) 66.37463912527758 np.std(sample_5) 1.7112978334301363 Obser vation We can conclude that the distribution of those 10000 samples means is normally distributed and most of the v alues lies between 62 and 72. Ther e might be some cases wher e the samples contain only shor t peoples that is why we can see some v alues between 60 and 62 Similarly , ther e might be some cases wher e the samples contain only tall people that is why we can see some v alues between 70 and 72. Q1. What would happen If we incr ease the siz e of our sample? We studied earlier in the lectur e that as we incr ease the siz e of the sample, the spr ead of data will be less. This means, as we incr ease the siz e of the sample, the sample mean will come closer and closer t o the population meanSample siz e = 20 îŒ“ Let's try this out. Let's incr ease the sample siz e to 20. We will again per form 10,00 iter ations and plot the distributions of the sample",
    "source": "lec9.pdf::chunk7"
  },
  {
    "text": "means sample_20 = [np.mean(df_height.sample( 20)) for i in range(10000) ] <Axes: ylabel='Count'> sns.histplot(sample_20, kde= True) np.mean(sample_20) 66.35931508817528 np.std(sample_20) 0.86147661644173 Obser vation We can clearly see that as we incr ease the number of samples fr om 5 t o 20, the sample means come closer t o the actual mean and the standar d de viation becomes less . Previously the majority of the v alues wer e between 62 and 72. Now the spr ead of the data has decr eased and v alues lie between 64 and 69 So we can asser t that b y increasing the siz e of the sample, the v ariability or SD of the sample distributions decr eases and the sample mean tends t o be much closer t o the population mean . Let's compar e the statistics of population data and sample data t o obser ve some patternsComparison of StatisticsîŒ“ # population mean mu = df_height.mean() # population SD sigma = df_height.std() # mean of sample distributions having sample size = 5 mu_5 = np.mean(sample_5) # SD of sample distributions having sample size = 5 sigma_5 = np.std(sample_5) # mean of sample distributions having sample size = 20 mu_20",
    "source": "lec9.pdf::chunk8"
  },
  {
    "text": "= np.mean(sample_20) # SD of sample distributions having sample size = 20 sigma_20 = np.std(sample_20) print(mu, mu_5, mu_20) print(sigma, sigma_5, sigma_20) 66.36755975482124 66.37463912527758 66.35931508817528 3.8475281207732293 1.7112978334301363 0.86147661644173 Obser vation Here, Population Statistics: = population mean = population standar d de viation Sample Statistics: = mean of sample means (fr om samples of siz e 5) = standar d de viation of the sample means (fr om samples of siz e 5) = mean of sample means (fr om samples of siz e 20) = standar d de viation of the sample means (fr om samples of siz e 20) Obser vations: 1. Mean of the sampling distribution is equal t o the mean of the population 2. As we incr ease the sample siz e, the SD of sample means decr eases . The SD of sampling distribution ( ) is less than the population SD ( ). This aligns with the CL T, which states that the standar d de viation of the sampling distribution ( ) is the standar d de viation of the population ( ) divided b y the squar e root of the sample siz e: We ha ve alr eady studied it, it is",
    "source": "lec9.pdf::chunk9"
  },
  {
    "text": "known as Standar d Err or. It indicates that how far my sample mean is fr om the actual mean.Î¼ Ïƒ Î¼5 Ïƒ5 Î¼20 Ïƒ20 =Î¼ Î¼ğ‘¥Â¯ Ïƒğ‘¥Â¯ Ïƒ Ïƒ> >Ïƒ5 Ïƒ20 Ïƒğ‘¥Â¯ Ïƒ =Ïƒğ‘¥Â¯Ïƒ ğ‘›âˆš How can we mathematically r epresent it? We can describe the sampling distribution of the mean using this notation: Wher e: is the sampling distribution of the sample means means \"follows the distribution \" is the normal distribution is the mean of the population is the standar d de viation of sample means distributionSummarizing CL T îŒ“ âˆ½ğ‘(Î¼ , ) ğ‘‹Â¯ Ïƒ ğ‘›âˆš ğ‘‹Â¯ âˆ½ ğ‘ Âµ Ïƒ/ğ‘›âˆš Now , let's solv e some examples Systolic blood pressure of a group of people is known to have an average of 122 mmHg and a standard deviation of 10 mmHg. Calculate the probability that the average blood pressure of 16 people will be greater than 125 mmHg. Example 1:îŒ“ Given, For the entir e population = 122 = 10 We need t o calculate the pr obability that a verage BP of 16 people will be > 125 Sample siz e n = 16 and b y CLT, the = = 122 The standar d",
    "source": "lec9.pdf::chunk10"
  },
  {
    "text": "de viation will beÎ¼ Ïƒ ğ‘‹Â¯Î¼ # SE = Ïƒ/sqrt(n) sigma = 10/np.sqrt( 16) sigma 2.5 So, the pr obability of nding people ha ving gr eater than 125 a verage BP will be we know , How can we nd P[X < 125]? by calculating \" norm.cdf(zscor e)\"ğ‘ƒ[ğ‘‹>125]=1âˆ’ğ‘ƒ[ğ‘‹<125] # zscore = (X - mu)/Ïƒ z_score = ( 125 - 122)/sigma z_score 1.2 # P[X>125]=1âˆ’P[X<125] probability = 1 - norm.cdf(z_score) probability 0.11506967022170822 The pr obability that the a verage blood pr essur e of 16 people will be gr eater than 125 mmHg is 0.115 Now , let's jump int o the next impor tant concept in statistics, Condence Inter val. Condence Inter valîŒ“ We solv ed an example of tur tles in our pr evious lectur es to discuss point estimates. Let' s recall it. Example: We wanted t o estimate the mean weight of a cer tain species of tur tle in Florida b y taking a single r andom sample () of 50 turtles and using the sample mean t o estimate the true population mean.ğ‘† But as we know ther e is one pr oblem her e. Problem: The mean weight of tur tles in the",
    "source": "lec9.pdf::chunk11"
  },
  {
    "text": "sample is not guar anteed t o exactly match the mean weight of tur tles in the whole population. Solution: In or der t o captur e this uncer tainty , we will sa y that the population mean will lie in the range of the sample mean (point estimates) some errors her e and ther e. So, whate ver sample mean I will get fr om the sample, I will tr y to provide a r ange and the population mean will lie within that r ange. This inter val or r ange is called Condence Inter val. In summar y, A condence inter val is the mean of y our estimate plus and minus the v ariation in that estimate . This is the r ange of v alues y ou expect y our estimate t o fall within a cer tain le vel of condence. Q. What is condence? If you construct a condence inter val with a 95% condence le vel, you ar e condent that 95 out of 100 times the estimate will fall between the upper and lower v alues specied b y the condence inter val. is the lower bound and is the",
    "source": "lec9.pdf::chunk12"
  },
  {
    "text": "upper bound .+/âˆ’ ğ‘¥1 ğ‘¥2 Ther e are 2 wa ys to nd condence inter val 1. Using CL T This is for mean v alues. If we ha ve mean as a statistic then we will calculate CI using the centr al limit theor em (CL T) 2. Using Bootstr apping If you ha ve statistics other than mean lik e median then we ar e not allowed t o use CL T. We can use bootstr ap method t o calculate condence inter vals in those scenarios . Let's calculate the condence inter val using CL T rst, Using CL T, we will get these v alues and r ange between these v alues will be our condence inter val.Q. How t o calculate the condence inter val? îŒ“ Here is the mean of sample ( ). ğ‘‹Â¯ğ‘  ğ‘† To get a 95% condence inter val, we need t o nd the ar ea that co vers 95% of the data Let's say we ha ve 2 points ar ound mean one on the left and one on the right. These points will be upper bound and lower bound. We can calculate the data points for these z",
    "source": "lec9.pdf::chunk13"
  },
  {
    "text": "scor es (z1 and z2) which will be the condence inter val. We know that between z1 and z2, 95% of the population lies. So, on the left hand side of z1 ther e is 2.5% population and on the right side of z2 ther e is 2.5% populationCompute a 95% Condence Inter val îŒ“ So, t o nd the v alue below this per centage of data falls, we will use the PPF . Q1. How do we nd z1 and z2 as we ha ve 2.5% data till z1 Similarly t o calculate z2 will use as we ha ve 2.5% data r emaining after z2 We can also r epresent the z1 points as 2.5th per centile and z2 as 97.5th per centile (1-0.025)ğ‘§1=ğ‘›ğ‘œğ‘Ÿğ‘š.ğ‘ğ‘ğ‘“(0.025) ğ‘§2=ğ‘›ğ‘œğ‘Ÿğ‘š.ğ‘ğ‘ğ‘“(1âˆ’0.025) # z1 will be z1 = norm.ppf( 0.025) z1 -1.9599639845400545 # z2 will be z2 = norm.ppf( 1 - 0.025) # we can also use norm.ppf(0.975) z2 1.959963984540054 Q. What is the formula for the z scor e? The Z-scor e is a measur e of how many standar d de viations a data point (in this case, the sample mean) is fr om the population mean In the case of sample",
    "source": "lec9.pdf::chunk14"
  },
  {
    "text": "we consider standar d err or so Hence, the Z scor e formula will be: Wher e, = sample mean - population mean = standar d err orÏƒ=Ïƒ ğ‘›âˆš ğ‘=âˆ’ğœ‡ğ‘‹Â¯ ğœ ğ‘›âˆš ğ‘‹Â¯ ğœ‡ ğœ/ğ‘›âˆš Here in the abo ve example our sample , the population mean will lie between z scor es i.e. z1 and z2 which is -1.96 and 1.96 . Between these two points, we will ha ve our 95% condence inter val.ğ‘† Q. So, what will be the r ange wher e original is lying? Condence Inter val = OR wher e: : sample meanÎ¼ Â±ğ‘( )ğ‘‹Â¯ Ïƒ ğ‘›âˆš [âˆ’ğ‘âˆ—() , +ğ‘âˆ—()] ğ‘‹Â¯ Ïƒ ğ‘›âˆšğ‘‹Â¯ Ïƒ ğ‘›âˆš ğ‘‹Â¯ : is the z-scor e corr esponding t o the desir ed condence le vel. : standar d err or If you tak e , it is r eferred as the the margin of err or in the context of condence inter vals.ğ‘§ Ïƒ/ğ‘›âˆš (ğ‘âˆ— )Ïƒ ğ‘›âˆš Now let' s try to solv e one example The mean height of a sample of 100 adults was found to be 65 inches, with a standard deviation of 2.5 inches. Compute 95% confidence interval Solution: Given, Sample siz e \"n\"",
    "source": "lec9.pdf::chunk15"
  },
  {
    "text": "= 100 Sample mean = 65 Standar d de viation = 2.5 First, let' s calculate the standar d err or:Example on condence inter val îŒ“ # std deviation sigma/sqrt(n) std_error = 2.5/np.sqrt( 100) std_error 0.25 Now the v alues of Z for 95% condence will be, we ha ve calculated abo ve # z1 will be z1 = norm.ppf( 0.025) z1 -1.9599639845400545 # z2 will be z2 = norm.ppf( 1 - 0.025) # we can also use norm.ppf(0.975) z2 1.959963984540054 Now , How t o get the data points for z1 which is on left side and z2 which is on right side, and, =Î¼+ğ‘1âˆ—Ïƒ/ ğ‘‹1 ğ‘›âˆš =Î¼+ğ‘2âˆ—Ïƒ/ ğ‘‹2 ğ‘›âˆš x1 = 65 + z1 * std_error x1 64.51000900386498 x2 = 65 + z2 * std_error x2 65.48999099613502 So the range of 95% confidence interval --> [64.51, 65.48] Conclusion: We can claim that the population mean will lie between the v alue 64.51 and 65.48 with 95% condence. Ther e is dir ectly one function a vailable which will calculate inter val by using just a single formula Using norm.inter val() You ha ve to pass thr ee attributes : norm.inter val(condence, loc=0, scale=1) condence: how much condence y",
    "source": "lec9.pdf::chunk16"
  },
  {
    "text": "ou want loc: pass the mean value her e (by default it is 0) scale: pass the standar d err or here (by default it is 1) norm.interval( 0.95, loc=65, scale=std_error) (64.51000900386498, 65.48999099613502) Suppose y ou ha ve very little data and y ou want t o compute a condence inter val for some other statistics lik e median then the most common technique is bootstr apping. Let's star t with one example:Condence inter val using Bootstr ap îŒ“ Imagine we want to analyse and learn about the data scientist salaries at Google. We ha ve 2 sur veys,Example: Salar y Sur vey îŒ“ We don 't have a population mean her e but we ha ve 2 samples, so, we can calculate the sample means. survey_1 = [ 35, 36, 33, 37, 34, 35] np.mean(survey_1) 35.0 survey_2 = [ 20, 37, 17, 50, 53, 33] np.mean(survey_2) 35.0 Q1. Which of the two sur veys is better for estimating the population par ameter or which sur vey is mor e reliable? By obser ving the samples we can conclude that v alues in sur vey 1 is much closer t o the mean v alues so sur vey 1 will",
    "source": "lec9.pdf::chunk17"
  },
  {
    "text": "be mor e accur ate for estimation Q2. Now , can we simulate mor e and mor e sets of samples lik e the ones abo ve? For this statisticians come up with something which has r easonable amount of accur acy. Statistician suggested that tak e your sur vey and then cr eate mor e samples fr om the same sur vey only using replacement . Bootstr apping is a statistical pr ocedur e that r esamples a single dataset t o create many simulated samples.Sample With ReplacementîŒ“ n = 6 bootstrapped_samples = np.random.choice(survey_1, size=n) bootstrapped_samples array([35, 35, 34, 34, 35, 35]) Here we will get an arr ay of length 6 wher e each element is one of the original data points fr om sur vey 1 which is r andomly chosen. Every time we run this code, we will get a diff erent arr ay so we can obser ve that the mean of this newly constructed arr ay will also be diff erent. np.mean(bootstrapped_samples) 34.666666666666664 bootstrapped_samples = np.random.choice(survey_2, size=n) np.mean(bootstrapped_samples) 31.0 Let's obser ve the diff erence between sur vey_1 and sur vey_2 b y running the code se veral times. We can obser ve that",
    "source": "lec9.pdf::chunk18"
  },
  {
    "text": "in sur vey 1, the mean v alue is alwa ys close t o 35 But in sur vey 2, it sometimes comes t o 35, sometimes 40, sometimes 39 so ther e is mor e variance in sur vey 2. So we will go with sur vey_1 as it has the higher condence because the v ariance in sur vey_1 is less. Let's draw a hist ogram of this sur vey bootstrapped_means_survey_1 = [] for reps in range(10000): bootstrapped_samples = np.random.choice(survey _1, size=n) bootstrapped_mean = np.mean(bootstrapped_sampl es) bootstrapped_means_survey_1.append(bootstrappe d_mean) sns.histplot(bootstrapped_means_survey_1) <Axes: ylabel='Count'> bootstrapped_means_survey_2 = [] for reps in range(10000): bootstrapped_samples = np.random.choice(survey _2, size=n) bootstrapped_mean = np.mean(bootstrapped_sampl es) # Replace by any statistic (median, percentile) bootstrapped_means_survey_2.append(bootstrappe d_mean) <Axes: ylabel='Count'> sns.histplot(bootstrapped_means_survey_2) Let's compar e these two hist ograms, what can we obser ve? We can obser ve that in sur vey_2, the inter val or r ange is somewher e between 20-50 While in sur vey_1, it is between 33-36 which is v ery close t o the actual mean So we can conclude that survey 1 is mor e accur ate than sur vey 2 We can calculate the per centile of bootstr apped mean 2.5th per centile will",
    "source": "lec9.pdf::chunk19"
  },
  {
    "text": "giv e me lower bound (x1) 97.5th per centile will giv e me upper bound (x2) Then, condence inte val will be [x1, x2]How t o compute the condidence inter val? îŒ“ len(bootstrapped_means_survey_1) 10000 x1 = np.percentile(bootstrapped_means_survey_1, 2.5) x1 34.0 x2 = np.percentile(bootstrapped_means_survey_1, 97.5) x2 36.0 We can obser ve that 95% of the numbers lies between 34 & 36 so Condence Inter val: (ğ‘¥1,ğ‘¥2) AS this pr ocess is r andom, this will be slight change in CI e verytime len(bootstrapped_means_survey_2) 10000 x1 = np.percentile (bootstrapped_means_survey_2, 2.5) x1 24.0 x2 = np.percentile (bootstrapped_means_survey_2, 97.5) x2 45.83749999999994 Here also CI will be Condence Inter val = , this is how we can calcular e Condence Inter val using bootstr ap (ğ‘¥1,ğ‘¥2)",
    "source": "lec9.pdf::chunk20"
  }
]